{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Welcome to the High Performance Computing (HPC) documentation of Memorial Sloan Kettering Cancer Center Introduction This is the official documentation site of the high performance computing at MSK and all related information. Basic Concepts and Glossary: HPC terms to know Check out the Glossary Information Sources Searching the Documentation Please use the search bar at the top of the page to search through the documentation for specific terms/subjects. News and Updates Stay updated with new updates and information via Announcements . Cluster Status (Grafana) See what is currently running on the clusters on Grafana . Code of Conduct Please read over the Code of Conduct to get an understanding of expectations and best practices. Acknowledging Lilac When you present results generated using our clusters, we kindly ask you to acknowledge the usage of the cluster. We would also highly appreciate if you could send us a copy of your papers, posters and presentations mentioning the cluster. Public visibility of our cluster and documenting results are important for us to ensure long-term funding of the clusters Whenever the Lilac infrastructure has been used to produce results used in a publication or poster, we kindly request citing the service in the acknowledgements: \"Calculations were performed on Lilac, the HPC cluster at Memorial Sloan Kettering Cancer Center.\" Press Kit Occasionally we are asked for images like diagrams illustrating the structure of Lilac or even pictures of machines/storage or the like. Often this is due to the need to describe Lilac within a research proposal. To support you with this, we provide a short text about Lilac and some files to download. You can use all of this within your research proposal. Support Visit the MSKCC HPC Slack Channel Contact by email: Visit The Spot for more help Quick Start COMING SOON","title":"Welcome to the High Performance Computing (HPC) documentation of Memorial Sloan Kettering Cancer Center"},{"location":"index.html#welcome-to-the-high-performance-computing-hpc-documentation-of-memorial-sloan-kettering-cancer-center","text":"","title":"Welcome to the High Performance Computing (HPC) documentation of Memorial Sloan Kettering Cancer Center"},{"location":"index.html#introduction","text":"This is the official documentation site of the high performance computing at MSK and all related information.","title":"Introduction"},{"location":"index.html#basic-concepts-and-glossary-hpc-terms-to-know","text":"Check out the Glossary","title":"Basic Concepts and Glossary: HPC terms to know"},{"location":"index.html#information-sources","text":"Searching the Documentation Please use the search bar at the top of the page to search through the documentation for specific terms/subjects. News and Updates Stay updated with new updates and information via Announcements . Cluster Status (Grafana) See what is currently running on the clusters on Grafana .","title":"Information Sources"},{"location":"index.html#code-of-conduct","text":"Please read over the Code of Conduct to get an understanding of expectations and best practices.","title":"Code of Conduct"},{"location":"index.html#acknowledging-lilac","text":"When you present results generated using our clusters, we kindly ask you to acknowledge the usage of the cluster. We would also highly appreciate if you could send us a copy of your papers, posters and presentations mentioning the cluster. Public visibility of our cluster and documenting results are important for us to ensure long-term funding of the clusters Whenever the Lilac infrastructure has been used to produce results used in a publication or poster, we kindly request citing the service in the acknowledgements: \"Calculations were performed on Lilac, the HPC cluster at Memorial Sloan Kettering Cancer Center.\"","title":"Acknowledging Lilac"},{"location":"index.html#press-kit","text":"Occasionally we are asked for images like diagrams illustrating the structure of Lilac or even pictures of machines/storage or the like. Often this is due to the need to describe Lilac within a research proposal. To support you with this, we provide a short text about Lilac and some files to download. You can use all of this within your research proposal.","title":"Press Kit"},{"location":"index.html#support","text":"Visit the MSKCC HPC Slack Channel Contact by email: Visit The Spot for more help","title":"Support"},{"location":"index.html#quick-start","text":"COMING SOON","title":"Quick Start"},{"location":"code-of-conduct.html","text":"Code of Conduct On this page we list some expectations from our side and recommended practice that is crucial for maintaining a good and professional working relationship between the user and the system administrators. Most of those contents are quite self-explanatory while others help to reduce the amount of support time needed to allocate. General We assume that you are familiar with some basic knowledge about Linux command line (shell) navigation and shell scripting. If you never worked on the command line, consider some Linux tutorials on the subject first. We expect you to exploit this valuable documentation before asking for help. All that is needed to get some simple jobs done on UBELIX is documented here. Account Staff accounts are preferred over student accounts! If you currently use your student Campus Account to access UBELIX, but you also possess a staff Campus Account, get in contact with us so we can activate your staff Campus Account, migrate all your user data to the new account and deactivate your student account for UBELIX. Mailing List We communicate upcoming events (e.g. maintenance downtimes) on our mailing list. Make sure that you are subscribed to this list, otherwise you will miss important announcements. Security Do not share your account If using public key authentication, do not share your private key General Communication with the Cluster Administrators Use the Service Portal for questions, issues or comments regarding UBELIX. Do not use the personal email address of a cluster administrator. This is important because it keeps all administrators informed about the ongoing problem-solving process, and if one administrator is on vacation, another administrator can help you with your question For each new problem start a new conversation with a new subject. Avoid to write to us by replying to an old answer mail from the last problem that you received from us or even worse by replying to mailing list email you received from us. The point here is that though it looks like an ordinary email, you actually are opening a new ticket in our ticket system (or reopening an old ticket if replying to an old email). Problem-Solving Process Exploit resources provided by your institute/research group before asking the UBELIX staff about domain-specific problems. We make an effort to help you, but we are no experts in your field, hence a colleague from your group who uses the cluster to solve a similar problem like you do might be a better first contact Ask Google for help before contacting us. We often also just \u201cgoogle\u201d for an answer, and then forward the outcome to you. Do not ask for/expect step-by-step solutions to a problem. Sometimes we give step-by-step instructions, but generally you should use our answers to do some refined research on the problem. If you still stuck, we are happy to provide further support Always give an exact as possible description of the problem. Provide your username, error messages, the path to the job script, the id of the job, and other hints that make the problem-solving process as economic as possible. Housekeeping Clean up your home directory frequently, in particular before asking for an increase of your quota limit Do not save thousands of files in a single directory. Distribute the files to subdirectories Job Submission Before submitting the same job a hundred times, please verify that the job finishes successfully. We often experience that hundreds of jobs getting killed due to an invalid path referenced in the job script, which generates hundreds of notification mails in our system. Cluster Performance DO NOT run resource-intensive computations directly on the login node AKA submit node. This will have a negative impact on the performance of the whole cluster. Instead, generate a job script that carries out the computations and submit this job script to the cluster using sbatch. DO NOT run server applications (PostgreSQL server, web server, \u2026) on the front-end server (submit hosts). Such a program usually run as a background process (daemon) rather than being under the direct control of an interactive user. We will immediately kill such processes.","title":"Code of Conduct"},{"location":"code-of-conduct.html#code-of-conduct","text":"On this page we list some expectations from our side and recommended practice that is crucial for maintaining a good and professional working relationship between the user and the system administrators. Most of those contents are quite self-explanatory while others help to reduce the amount of support time needed to allocate.","title":"Code of Conduct"},{"location":"code-of-conduct.html#general","text":"We assume that you are familiar with some basic knowledge about Linux command line (shell) navigation and shell scripting. If you never worked on the command line, consider some Linux tutorials on the subject first. We expect you to exploit this valuable documentation before asking for help. All that is needed to get some simple jobs done on UBELIX is documented here.","title":"General"},{"location":"code-of-conduct.html#account","text":"Staff accounts are preferred over student accounts! If you currently use your student Campus Account to access UBELIX, but you also possess a staff Campus Account, get in contact with us so we can activate your staff Campus Account, migrate all your user data to the new account and deactivate your student account for UBELIX.","title":"Account"},{"location":"code-of-conduct.html#mailing-list","text":"We communicate upcoming events (e.g. maintenance downtimes) on our mailing list. Make sure that you are subscribed to this list, otherwise you will miss important announcements.","title":"Mailing List"},{"location":"code-of-conduct.html#security","text":"Do not share your account If using public key authentication, do not share your private key","title":"Security"},{"location":"code-of-conduct.html#general-communication-with-the-cluster-administrators","text":"Use the Service Portal for questions, issues or comments regarding UBELIX. Do not use the personal email address of a cluster administrator. This is important because it keeps all administrators informed about the ongoing problem-solving process, and if one administrator is on vacation, another administrator can help you with your question For each new problem start a new conversation with a new subject. Avoid to write to us by replying to an old answer mail from the last problem that you received from us or even worse by replying to mailing list email you received from us. The point here is that though it looks like an ordinary email, you actually are opening a new ticket in our ticket system (or reopening an old ticket if replying to an old email).","title":"General Communication with the Cluster Administrators"},{"location":"code-of-conduct.html#problem-solving-process","text":"Exploit resources provided by your institute/research group before asking the UBELIX staff about domain-specific problems. We make an effort to help you, but we are no experts in your field, hence a colleague from your group who uses the cluster to solve a similar problem like you do might be a better first contact Ask Google for help before contacting us. We often also just \u201cgoogle\u201d for an answer, and then forward the outcome to you. Do not ask for/expect step-by-step solutions to a problem. Sometimes we give step-by-step instructions, but generally you should use our answers to do some refined research on the problem. If you still stuck, we are happy to provide further support Always give an exact as possible description of the problem. Provide your username, error messages, the path to the job script, the id of the job, and other hints that make the problem-solving process as economic as possible.","title":"Problem-Solving Process"},{"location":"code-of-conduct.html#housekeeping","text":"Clean up your home directory frequently, in particular before asking for an increase of your quota limit Do not save thousands of files in a single directory. Distribute the files to subdirectories","title":"Housekeeping"},{"location":"code-of-conduct.html#job-submission","text":"Before submitting the same job a hundred times, please verify that the job finishes successfully. We often experience that hundreds of jobs getting killed due to an invalid path referenced in the job script, which generates hundreds of notification mails in our system.","title":"Job Submission"},{"location":"code-of-conduct.html#cluster-performance","text":"DO NOT run resource-intensive computations directly on the login node AKA submit node. This will have a negative impact on the performance of the whole cluster. Instead, generate a job script that carries out the computations and submit this job script to the cluster using sbatch. DO NOT run server applications (PostgreSQL server, web server, \u2026) on the front-end server (submit hosts). Such a program usually run as a background process (daemon) rather than being under the direct control of an interactive user. We will immediately kill such processes.","title":"Cluster Performance"},{"location":"contributing.html","text":"Contributing You can support the UBELIX cluster in different ways: Investments Documentation Improvements Investments Some text about money\u2026 Documentation Improvements Some text aboutn contirbuting to the user guide.","title":"Contributing"},{"location":"contributing.html#contributing","text":"You can support the UBELIX cluster in different ways: Investments Documentation Improvements","title":"Contributing"},{"location":"contributing.html#investments","text":"Some text about money\u2026","title":"Investments"},{"location":"contributing.html#documentation-improvements","text":"Some text aboutn contirbuting to the user guide.","title":"Documentation Improvements"},{"location":"halloffame.html","text":"Hall of Fame If you previously used UBELIX to do your computational work and you acknowledged this in your publication and want to your publication listed here, please drop us a note via https://serviceportal.unibe.ch/hpc . If you are wondering how you can acknowledge the usage of UBELIX in your publication, have a look at the homepage of this documentation, where you will find a text recommendation acknoowledging the use of our cluster. Papers and Articles Authors Title Journal Boris DOI 2021 Deng S., Zhu J., Aschauer U. Critical Role of Sc Substitution in Modulating Ferroelectricity in Multiferroic LuFeO 3 Nano Lett. 2021,21 Direct Link Stober G., Weryk R. J. Triple-frequency meteor radar full wave scattering - Measurements and comparison to theory A&A 654 A108 Direct Link Bertone S, J\u00e4ggi A Assessing reduced-dynamic parametrizations for GRAIL orbit determination and the recovery of independent lunar gravity field solutions Earth and Space Science Direct Link 2020 Riou J, Hauser A et al. Estimation of SARS-CoV-2 mortality during the early stages of an epidemic: A modeling study in Hubei, China, and six regions in Europe PLOS Medicine Direct Link Ricca C, Aschauer U Local polarization in oxygen-deficient LaMnO 3 induced by charge localization in the Jahn-Teller distorted structure Phys. Rev. Res. Details Direct Link Burns E, Lippert T et al. LaTiO 2 N crystallographic orientation control significantly increases visible-light induced charge extraction J. Mat. Chem. A Details Direct Link Ninova S, Aschauer U, et al. Suitability of Cu-substituted \u03b2-Mn 2 V 2 O 7 and Mn-substituted \u03b2-Cu 2 V 2 O 7 for photocatalytic water-splitting J. Chem Phys. 153 Details Direct Link Vonr\u00fcti N, Aschauer U Catalysis on oxidized ferroelectric surfaces\u2014Epitaxially strained LaTiO 2 N and BaTiO 3 for photocatalytic water splitting Chem. Mater. Details Direct Link Bouri M, Aschauer U Suitability of Different Sr 2 TaO 3 N Surface Orientations for Photocatalytic Water Oxidation Chem. Mater Details Direct Link Flores E, Berg E, et al. Cation Ordering and Redox Chemistry of Layered Ni-Rich Li x Ni 1\u20132y Co y Mn y O 2 : An Operando Raman Spectroscopy Study Chem. Mater. Details Direct Link Pawlak R, Meyer E, et al. Bottom-up Synthesis of Nitrogen-Doped Porous Graphene Nanoribbons J.Am.Chem.Soc. Details Direct Link Ricca C, Aschauer U, et al. Self-consistent DFT + U + V study of oxygen vacancies in SrTiO 3 Phys. Rev. Research 2 Details Direct Link Ninova S, Aschauer U, et al. Surface Orientation and Structure of LaTiO 2 N Nanoparticles ACS Appl. Energy Mater Details Direct Link Primasov\u00e1 H, Furrer J, et al. Dinuclear thiolato-bridged arene ruthenium complexes: from reaction conditions and mechanism to synthesis of new complexes RSC Advances Details Direct Link Pfister J-P, Gontier C Identifiability of a Binomial Synapse Front. Comput. Neurosci. Details Direct Link Riou J, Althaus C Pattern of early human-to-human transmission of Wuhan 2019 novel coronavirus (2019-nCoV), December 2019 to January 2020 Euro Surveillance Direct Link 2019 Vonr\u00fcti N, Aschauer U The role of metastability in enhancing water-oxidation activity Phys.Chem.Chem.Phys. Details Bizzotto F, Arenz M, et al. Examining the Structure Sensitivity of the Oxygen Evolution Reaction on Pt Single\u2010Crystal Electrodes: A Combined Experimental and Theoretical Study ChemPhysChem Details Direct Link Vonr\u00fcti N, Aschauer U Band-gap engineering in AB(O x S 1\u2212x ) 3 perovskite oxysulfides: a route to strongly polar materials for photocatalytic water splitting J.Mat. Chem. A Details Direct Link Ouhbi H, Aschauer U Nitrogen Loss and Oxygen Evolution Reaction Activity of Perovskite Oxynitrides ACS Materials Lett. Details Direct Link Hussain H, Thornton G, et al. Water-Induced Reversal of the TiO 2 (011)-(2 \u00d7 1) Surface Reconstruction: Observed with in Situ Surface X-ray Diffraction J.Phys. Chem C Details Direct Link Mantella V, Buonsanti R, et al. Synthesis and Size-Dependent Optical Properties of Intermediate Band Gap Cu 3 VS 4 Nanocrystals Chem. Mater Details Direct Link Aschauer U, Spaldin N, et al. Strain-induced heteronuclear charge disproportionation in EuMnO 3 Phys. Rev. Materials 3 Details Direct Link Ninova S, Aschauer U Anion-order driven polar interfaces at LaTiO 2 N surfaces Journal of Materials Chemistry A Details Direct Link Ricca C, Aschauer U et al. Self-consistent site-dependent DFT+U study of stoichiometric and defective SrMnO 3 Physical Review B Details Direct Link Ouhbia H, Aschauer U Water oxidation catalysis on reconstructed NaTaO 3 (001) surfaces Journal of Materials Chemistry A Details Direct Link Counotte M, Althaus C et al. Impact of age-specific immunity on the timing and burden of the next Zika virus outbreak PLOS NeglectedTropical Diseases Details Direct Link Brugger J, Althaus C Transmission of and susceptibility to seasonal influenza in Switzerland from 2003 to 2015 Epidemics, Elsevier Details Direct Link 2018 Horton P, Br\u00f6nnimann S Impact of global atmospheric reanalyses on statistical precipitation downscaling Climate Dynamics Details Direct Link Vonr\u00fcti N, Aschauer U Epitaxial strain dependence of band gaps in perovskite oxynitrides compared to perovskite oxides American Physical Society Details Direct Link Aschauer U Ultrafast Relaxation Dynamics of the Antiferrodistortive Phase in Ca Doped SrTiO\u2083 American Physical Society Details Direct Link Vonr\u00fcti N, Aschauer U, et al. Elucidation of Li x Ni 0.8 Co 0.15 Al 0.05 O 2 Redox Chemistry by Operando Raman Spectroscopy American Chemical Society Details Direct Link Ouhbi H, Aschauer U Water oxidation chemistry of oxynitrides and oxides: Comparing NaTaO 3 and SrTaO 2 N Surface Science Details Direct Link Aschauer U Surface and Defect Chemistry of Oxide Material CHIMIA Details Direct Link Kasper, C, Hebert, F, Aubin-Horth N, Taborsky B Divergent brain gene expression profiles between alternative behavioural helper types in a cooperative breeder Wiley Molecular Ecology Direct Link Panyasantisuk J, Dall'Ara E, Pretterklieber M, Pahr D.H., Zysset P.K. | Mapping anisotropy improves QCT-based finite element estimation of hip strength in pooled stance and side-fall load configurations | Medical Engineering & Physics, Elsevier | | Direct Link Vonr\u00fcti, N, Aschauer U | Anion Order and Spontaneous Polarization in LaTiO 2 N Oxynitride Thin Films | American Physical Society | Details | Direct Link Bouri M, Aschauer U | Bulk and surface properties of the Ruddlesden-Popper oxynitride Sr 2 TaO 3 N | Physical Chemistry Chemical Physics | Details | Direct Link 2017 Aschauer, U et al. | Surface Structure of TiO2 Rutile (011) Exposed to Liquid Water | Journal of Physical Chemistry | Details | Direct Link Kasper, C, K\u00f6lliker, M, Pstma, E, Taborsky B | Consistent cooperation in a cichlid fish is caused by maternal and developmental effects rather than heritable genetic variation | Proceedings of the Royal Society, Biological Sciences | | Direct Link Riesen M, Garcia V, Low N, Althaus C | Modeling the consequences of regional heterogeneity in human papillomavirus (HPV) vaccination uptake on transmission in Switzerland | Vaccine, Elsevier | Details | Direct Link Kilic C, Raible C, Stocker T | Multiple climate States of Habitable Exoplanets: The Rolf of Obliquity and Irradiance | The Astrophysical Journal | Details | Direct Link Kilic C, Raible C, Kirk | Impact of variations of gravitational acceleration on the general circulation of the planetary atmosphere | Planetary and Space Science | Details | Direct Link Mueller S, Fix M et al. | Simultaneous optimization of photons and electrons for mixed beam radiotherapy al. | Physics in Medicine & Biology | | Direct Link Ninova S, Aschauer U | Surface structure and anion order of the oynitride LaTiO 2 N | Journal of Materials Chemistry A | Details | Direct Link Ninova S, Aschauer U et al. | LaTiOxNy Thin Film Model Systems for Photocatalytic Water Splitting: Physicochemical Evolution of the Solid-Liquid Interface and the Role of the Crystallographic Orientation | Advanced functional materials | Details | Direct Link Struchen R, Vial F, Andersson M. G. | Value of evidence from syndromic surveillance with cumulative evidence from multiple data stream with delayed reporting | Scientific Reports | | Direct Link 2013 Leichtle A, Fiedler G et al. | Pancreatic carcinoma, pancreatitis, and healthy controls: metabolite models in a three-class diagnostic dilemma | Metabolomics, Springer | Details | Direct Link Posters Newspapers Title Newspaper Year of Publication Link Berner Forscher entdecken neue Klimazust\u00e4nde, in denen Leben m\u00f6glich ist. Der Bund Direct Link Create an Entry If you used UBELIX for your publication please let your entry added to the list. Open a ticket or create a pull request, see Documentation Update . The format of the entry would be markdown: <first author>, <last author> | <title> | [Details](<Boris link>) | [Direct Link](<DOI link>) where the authors are lastname and first letter of first name. Subscripts can be created using <sub>2</sub> .","title":"Hall of Fame"},{"location":"halloffame.html#hall-of-fame","text":"If you previously used UBELIX to do your computational work and you acknowledged this in your publication and want to your publication listed here, please drop us a note via https://serviceportal.unibe.ch/hpc . If you are wondering how you can acknowledge the usage of UBELIX in your publication, have a look at the homepage of this documentation, where you will find a text recommendation acknoowledging the use of our cluster.","title":"Hall of Fame"},{"location":"halloffame.html#papers-and-articles","text":"Authors Title Journal Boris DOI 2021 Deng S., Zhu J., Aschauer U. Critical Role of Sc Substitution in Modulating Ferroelectricity in Multiferroic LuFeO 3 Nano Lett. 2021,21 Direct Link Stober G., Weryk R. J. Triple-frequency meteor radar full wave scattering - Measurements and comparison to theory A&A 654 A108 Direct Link Bertone S, J\u00e4ggi A Assessing reduced-dynamic parametrizations for GRAIL orbit determination and the recovery of independent lunar gravity field solutions Earth and Space Science Direct Link 2020 Riou J, Hauser A et al. Estimation of SARS-CoV-2 mortality during the early stages of an epidemic: A modeling study in Hubei, China, and six regions in Europe PLOS Medicine Direct Link Ricca C, Aschauer U Local polarization in oxygen-deficient LaMnO 3 induced by charge localization in the Jahn-Teller distorted structure Phys. Rev. Res. Details Direct Link Burns E, Lippert T et al. LaTiO 2 N crystallographic orientation control significantly increases visible-light induced charge extraction J. Mat. Chem. A Details Direct Link Ninova S, Aschauer U, et al. Suitability of Cu-substituted \u03b2-Mn 2 V 2 O 7 and Mn-substituted \u03b2-Cu 2 V 2 O 7 for photocatalytic water-splitting J. Chem Phys. 153 Details Direct Link Vonr\u00fcti N, Aschauer U Catalysis on oxidized ferroelectric surfaces\u2014Epitaxially strained LaTiO 2 N and BaTiO 3 for photocatalytic water splitting Chem. Mater. Details Direct Link Bouri M, Aschauer U Suitability of Different Sr 2 TaO 3 N Surface Orientations for Photocatalytic Water Oxidation Chem. Mater Details Direct Link Flores E, Berg E, et al. Cation Ordering and Redox Chemistry of Layered Ni-Rich Li x Ni 1\u20132y Co y Mn y O 2 : An Operando Raman Spectroscopy Study Chem. Mater. Details Direct Link Pawlak R, Meyer E, et al. Bottom-up Synthesis of Nitrogen-Doped Porous Graphene Nanoribbons J.Am.Chem.Soc. Details Direct Link Ricca C, Aschauer U, et al. Self-consistent DFT + U + V study of oxygen vacancies in SrTiO 3 Phys. Rev. Research 2 Details Direct Link Ninova S, Aschauer U, et al. Surface Orientation and Structure of LaTiO 2 N Nanoparticles ACS Appl. Energy Mater Details Direct Link Primasov\u00e1 H, Furrer J, et al. Dinuclear thiolato-bridged arene ruthenium complexes: from reaction conditions and mechanism to synthesis of new complexes RSC Advances Details Direct Link Pfister J-P, Gontier C Identifiability of a Binomial Synapse Front. Comput. Neurosci. Details Direct Link Riou J, Althaus C Pattern of early human-to-human transmission of Wuhan 2019 novel coronavirus (2019-nCoV), December 2019 to January 2020 Euro Surveillance Direct Link 2019 Vonr\u00fcti N, Aschauer U The role of metastability in enhancing water-oxidation activity Phys.Chem.Chem.Phys. Details Bizzotto F, Arenz M, et al. Examining the Structure Sensitivity of the Oxygen Evolution Reaction on Pt Single\u2010Crystal Electrodes: A Combined Experimental and Theoretical Study ChemPhysChem Details Direct Link Vonr\u00fcti N, Aschauer U Band-gap engineering in AB(O x S 1\u2212x ) 3 perovskite oxysulfides: a route to strongly polar materials for photocatalytic water splitting J.Mat. Chem. A Details Direct Link Ouhbi H, Aschauer U Nitrogen Loss and Oxygen Evolution Reaction Activity of Perovskite Oxynitrides ACS Materials Lett. Details Direct Link Hussain H, Thornton G, et al. Water-Induced Reversal of the TiO 2 (011)-(2 \u00d7 1) Surface Reconstruction: Observed with in Situ Surface X-ray Diffraction J.Phys. Chem C Details Direct Link Mantella V, Buonsanti R, et al. Synthesis and Size-Dependent Optical Properties of Intermediate Band Gap Cu 3 VS 4 Nanocrystals Chem. Mater Details Direct Link Aschauer U, Spaldin N, et al. Strain-induced heteronuclear charge disproportionation in EuMnO 3 Phys. Rev. Materials 3 Details Direct Link Ninova S, Aschauer U Anion-order driven polar interfaces at LaTiO 2 N surfaces Journal of Materials Chemistry A Details Direct Link Ricca C, Aschauer U et al. Self-consistent site-dependent DFT+U study of stoichiometric and defective SrMnO 3 Physical Review B Details Direct Link Ouhbia H, Aschauer U Water oxidation catalysis on reconstructed NaTaO 3 (001) surfaces Journal of Materials Chemistry A Details Direct Link Counotte M, Althaus C et al. Impact of age-specific immunity on the timing and burden of the next Zika virus outbreak PLOS NeglectedTropical Diseases Details Direct Link Brugger J, Althaus C Transmission of and susceptibility to seasonal influenza in Switzerland from 2003 to 2015 Epidemics, Elsevier Details Direct Link 2018 Horton P, Br\u00f6nnimann S Impact of global atmospheric reanalyses on statistical precipitation downscaling Climate Dynamics Details Direct Link Vonr\u00fcti N, Aschauer U Epitaxial strain dependence of band gaps in perovskite oxynitrides compared to perovskite oxides American Physical Society Details Direct Link Aschauer U Ultrafast Relaxation Dynamics of the Antiferrodistortive Phase in Ca Doped SrTiO\u2083 American Physical Society Details Direct Link Vonr\u00fcti N, Aschauer U, et al. Elucidation of Li x Ni 0.8 Co 0.15 Al 0.05 O 2 Redox Chemistry by Operando Raman Spectroscopy American Chemical Society Details Direct Link Ouhbi H, Aschauer U Water oxidation chemistry of oxynitrides and oxides: Comparing NaTaO 3 and SrTaO 2 N Surface Science Details Direct Link Aschauer U Surface and Defect Chemistry of Oxide Material CHIMIA Details Direct Link Kasper, C, Hebert, F, Aubin-Horth N, Taborsky B Divergent brain gene expression profiles between alternative behavioural helper types in a cooperative breeder Wiley Molecular Ecology Direct Link Panyasantisuk J, Dall'Ara E, Pretterklieber M, Pahr D.H., Zysset P.K. | Mapping anisotropy improves QCT-based finite element estimation of hip strength in pooled stance and side-fall load configurations | Medical Engineering & Physics, Elsevier | | Direct Link Vonr\u00fcti, N, Aschauer U | Anion Order and Spontaneous Polarization in LaTiO 2 N Oxynitride Thin Films | American Physical Society | Details | Direct Link Bouri M, Aschauer U | Bulk and surface properties of the Ruddlesden-Popper oxynitride Sr 2 TaO 3 N | Physical Chemistry Chemical Physics | Details | Direct Link 2017 Aschauer, U et al. | Surface Structure of TiO2 Rutile (011) Exposed to Liquid Water | Journal of Physical Chemistry | Details | Direct Link Kasper, C, K\u00f6lliker, M, Pstma, E, Taborsky B | Consistent cooperation in a cichlid fish is caused by maternal and developmental effects rather than heritable genetic variation | Proceedings of the Royal Society, Biological Sciences | | Direct Link Riesen M, Garcia V, Low N, Althaus C | Modeling the consequences of regional heterogeneity in human papillomavirus (HPV) vaccination uptake on transmission in Switzerland | Vaccine, Elsevier | Details | Direct Link Kilic C, Raible C, Stocker T | Multiple climate States of Habitable Exoplanets: The Rolf of Obliquity and Irradiance | The Astrophysical Journal | Details | Direct Link Kilic C, Raible C, Kirk | Impact of variations of gravitational acceleration on the general circulation of the planetary atmosphere | Planetary and Space Science | Details | Direct Link Mueller S, Fix M et al. | Simultaneous optimization of photons and electrons for mixed beam radiotherapy al. | Physics in Medicine & Biology | | Direct Link Ninova S, Aschauer U | Surface structure and anion order of the oynitride LaTiO 2 N | Journal of Materials Chemistry A | Details | Direct Link Ninova S, Aschauer U et al. | LaTiOxNy Thin Film Model Systems for Photocatalytic Water Splitting: Physicochemical Evolution of the Solid-Liquid Interface and the Role of the Crystallographic Orientation | Advanced functional materials | Details | Direct Link Struchen R, Vial F, Andersson M. G. | Value of evidence from syndromic surveillance with cumulative evidence from multiple data stream with delayed reporting | Scientific Reports | | Direct Link 2013 Leichtle A, Fiedler G et al. | Pancreatic carcinoma, pancreatitis, and healthy controls: metabolite models in a three-class diagnostic dilemma | Metabolomics, Springer | Details | Direct Link","title":"Papers and Articles"},{"location":"halloffame.html#posters","text":"","title":"Posters"},{"location":"halloffame.html#newspapers","text":"Title Newspaper Year of Publication Link Berner Forscher entdecken neue Klimazust\u00e4nde, in denen Leben m\u00f6glich ist. Der Bund Direct Link","title":"Newspapers"},{"location":"halloffame.html#create-an-entry","text":"If you used UBELIX for your publication please let your entry added to the list. Open a ticket or create a pull request, see Documentation Update . The format of the entry would be markdown: <first author>, <last author> | <title> | [Details](<Boris link>) | [Direct Link](<DOI link>) where the authors are lastname and first letter of first name. Subscripts can be created using <sub>2</sub> .","title":"Create an Entry"},{"location":"mdcheat.html","text":"Markdown Cheatsheet This page outlines all stuff available by installing the base Python-Markdown (comes with MkDocs) and the additional bundle PyMdown Extensions . Markdown Cheatsheet Headings The 3rd level The 4th level The 5th level The 6th level Headings with secondary text The 3rd level with secondary text The 4th level with secondary text The 5th level with secondary text The 6th level with secondary text Emphasis Lists Links Images Code and Syntax Highlighting !/bin/bash include Tables Blockquotes Inline HTML Horizontal Rule Line Breaks YouTube Videos Admonition Abbreviations Definition Lists Footnotes Headings ### The 3rd level #### The 4th level ##### The 5th level ###### The 6th level ## Headings <small>with secondary text</small> ### The 3rd level <small>with secondary text</small> #### The 4th level <small>with secondary text</small> ##### The 5th level <small>with secondary text</small> ###### The 6th level <small>with secondary text</small> The 3rd level The 4th level The 5th level The 6th level Headings with secondary text The 3rd level with secondary text The 4th level with secondary text The 5th level with secondary text The 6th level with secondary text Emphasis Emphasis, aka italics, with *asterisks* or _underscores_. Strong emphasis, aka bold, with **asterisks** or __underscores__. Combined emphasis with **asterisks and _underscores_**. Strikethrough uses two tildes. ~~Scratch this.~~ Emphasis, aka italics, with asterisks or underscores . Strong emphasis, aka bold, with asterisks or underscores . Combined emphasis with asterisks and underscores . Strikethrough uses two tildes. ~~Scratch this.~~ Lists (In this example, leading and trailing spaces are shown with with dots: \u22c5) 1. First ordered list item 2. Another item \u22c5\u22c5\u22c5\u22c5* Unordered sub-list. \u22c5\u22c5\u22c5\u22c5* Item 2 \u22c5\u22c5\u22c5\u22c5* Item 3 1. Actual numbers don't matter, just that it's a number \u22c5\u22c5\u22c5\u22c51. Ordered sub-list \u22c5\u22c5\u22c5\u22c5\u22c5\u22c5\u22c5\u22c51. Ordered subsub-list \u22c5\u22c5\u22c5\u22c5\u22c5\u22c5\u22c5\u22c51. Item 2 \u22c5\u22c5\u22c5\u22c5\u22c5\u22c5\u22c5\u22c51. Item 3 \u22c5\u22c5\u22c5\u22c51. Item 2 \u22c5\u22c5\u22c5\u22c51. Item 3 4. And another item. \u22c5\u22c5\u22c5\u22c5You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we'll use three here to also align the raw Markdown). \u22c5\u22c5\u22c5\u22c5To have a line break without a paragraph, you will need to use two trailing spaces.\u22c5\u22c5 \u22c5\u22c5\u22c5\u22c5Note that this line is separate, but within the same paragraph.\u22c5\u22c5 \u22c5\u22c5\u22c5\u22c5(This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.) * Unordered list can use asterisks - Or minuses + Or pluses First ordered list item Another item Unordered sub-list. Item 2 Item 3 Actual numbers don\u2019t matter, just that it\u2019s a number Ordered sub-list Ordered subsub-list Item 2 Item 3 Item 2 Item 3 And another item. You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we\u2019ll use three here to also align the raw Markdown). To have a line break without a paragraph, you will need to use two trailing spaces. Note that this line is separate, but within the same paragraph. (This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.) Unordered list can use asterisks Or minuses Or pluses Links There are two ways to create links. [I'm an inline-style link](https://www.google.com) [I'm an inline-style link with title](https://www.google.com \"Google's Homepage\") [I'm a reference-style link][Arbitrary case-insensitive reference text] [I'm a relative reference to a repository file](../blob/master/LICENSE) [You can use numbers for reference-style link definitions][1] Or leave it empty and use the [link text itself]. URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or <http://www.example.com> and sometimes example.com (but not on Github, for example). Some text to show that the reference links can follow later. [arbitrary case-insensitive reference text]: https://www.mozilla.org [1]: http://slashdot.org [link text itself]: http://www.reddit.com I\u2019m an inline-style link I\u2019m an inline-style link with title I\u2019m a reference-style link I\u2019m a relative reference to a repository file You can use numbers for reference-style link definitions Or leave it empty and use the link text itself . URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or http://www.example.com and sometimes example.com (but not on Github, for example). Some text to show that the reference links can follow later. Images Here's our logo (hover to see the title text): Inline-style: ![alt text](https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png \"Logo Title Text 1\") Reference-style: ![alt text][logo] [logo]: https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png \"Logo Title Text 2\" Here\u2019s our logo (hover to see the title text): Inline-style: Reference-style: Code and Syntax Highlighting Code blocks are part of the Markdown spec, but syntax highlighting isn\u2019t. However, many renderers \u2013 like Github\u2019s and Markdown Here \u2013 support syntax highlighting. Which languages are supported and how those language names should be written will vary from renderer to renderer. Markdown Here supports highlighting for dozens of languages (and not-really-languages, like diffs and HTTP headers); to see the complete list, and how to write the language names, see the highlight.js demo page . Inline `code` has `back-ticks around` it. Inline code has back-ticks around it. Blocks of code are either fenced by lines with three back-ticks ``` , or are indented with four spaces. I recommend only using the fenced code blocks \u2013 they\u2019re easier and only they support syntax highlighting. var s = \"JavaScript syntax highlighting\" ; alert ( s ); s = \"Python syntax highlighting\" print s No language indicated, so no syntax highlighting in Markdown Here (varies on Github). But let's throw in a <b>tag</b>. Even tabbed code example for different language are possible: ```Bash tab= !/bin/bash STR=\u201dHello World!\u201d echo $STR ```C tab= #include int main(void) { printf(\"hello, world\\n\"); } ```C++ tab= include int main() { std::cout << \u201cHello, world!\\n\u201d; return 0; } ```C# tab= using System; class Program { static void Main(string[] args) { Console.WriteLine(\"Hello, world!\"); } } Tables Tables aren\u2019t part of the core Markdown spec, but they are part of GFM and Markdown Here supports them. They are an easy way of adding tables to your email \u2013 a task that would otherwise require copy-pasting from another application. Colons can be used to align columns. | Tables | Are | Cool | | ------------- |:-------------:| -----:| | col 3 is | right-aligned | $1600 | | col 2 is | centered | $12 | | zebra stripes | are neat | $1 | There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don't need to make the raw Markdown line up prettily. You can also use inline Markdown. Markdown | Less | Pretty --- | --- | --- *Still* | `renders` | **nicely** 1 | 2 | 3 Colons can be used to align columns. Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1 There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don\u2019t need to make the raw Markdown line up prettily. You can also use inline Markdown. Markdown Less Pretty Still renders nicely 1 2 3 Blockquotes > Blockquotes are very handy in email to emulate reply text. > This line is part of the same quote. Quote break. > This is a very long line that will still be quoted properly when it wraps. Oh boy let's keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can *put* **Markdown** into a blockquote. Blockquotes are very handy in email to emulate reply text. This line is part of the same quote. Quote break. This is a very long line that will still be quoted properly when it wraps. Oh boy let\u2019s keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can put Markdown into a blockquote. Blockquote nesting is possible: > **Sed aliquet**, neque at rutrum mollis, neque nisi tincidunt nibh, vitae faucibus lacus nunc at lacus. Nunc scelerisque, quam id cursus sodales, lorem [libero fermentum](#) urna, ut efficitur elit ligula et nunc. > > Mauris dictum mi lacus, sit amet pellentesque urna vehicula fringilla. Ut sit amet placerat ante. Proin sed **elementum** __nulla__. Nunc vitae sem odio. Suspendisse ac eros arcu. Vivamus orci erat, volutpat a tempor et, rutrum. eu odio. > > > `Suspendisse rutrum facilisis risus`, eu posuere neque commodo a. Interdum et malesuada fames ac ante ipsum primis in faucibus. Sed nec leo bibendum, sodales mauris ut, tincidunt massa. Sed aliquet , neque at rutrum mollis, neque nisi tincidunt nibh, vitae faucibus lacus nunc at lacus. Nunc scelerisque, quam id cursus sodales, lorem libero fermentum urna, ut efficitur elit ligula et nunc. Mauris dictum mi lacus, sit amet pellentesque urna vehicula fringilla. Ut sit amet placerat ante. Proin sed elementum nulla. Nunc vitae sem odio. Suspendisse ac eros arcu. Vivamus orci erat, volutpat a tempor et, rutrum. eu odio. Suspendisse rutrum facilisis risus , eu posuere neque commodo a. Interdum et malesuada fames ac ante ipsum primis in faucibus. Sed nec leo bibendum, sodales mauris ut, tincidunt massa. Other content blocks within a blockquote Vestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu lectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl, sit amet laoreet nibh. var _extends = function ( target ) { for ( var i = 1 ; i < arguments . length ; i ++ ) { var source = arguments [ i ]; for ( var key in source ) { target [ key ] = source [ key ]; } } return target ; }; Praesent at :::js return target , sodales nibh vel, tempor felis. Fusce vel lacinia lacus. Suspendisse rhoncus nunc non nisi iaculis ultrices. Donec consectetur mauris non neque imperdiet, eget volutpat libero. Inline HTML You can also use raw HTML in your Markdown, and it\u2019ll mostly work pretty well. Horizontal Rule Three or more... --- Hyphens *** Asterisks ___ Underscores Three or more\u2026 Hyphens Asterisks Underscores Line Breaks My basic recommendation for learning how line breaks work is to experiment and discover \u2013 hit <Enter> once (i.e., insert one newline), then hit it twice (i.e., insert two newlines), see what happens. You\u2019ll soon learn to get what you want. \u201cMarkdown Toggle\u201d is your friend. Here are some things to try out: Here's a line for us to start with. This line is separated from the one above by two newlines, so it will be a *separate paragraph*. This line is also a separate paragraph, but... This line is only separated by a single newline, so it's a separate line in the *same paragraph*. Here\u2019s a line for us to start with. This line is separated from the one above by two newlines, so it will be a separate paragraph . This line is also begins a separate paragraph, but\u2026 This line is only separated by a single newline, so it\u2019s a separate line in the same paragraph . YouTube Videos They can\u2019t be added directly but you can add an image with a link to the video like this: <a href=\"http://www.youtube.com/watch?feature=player_embedded&v=YOUTUBE_VIDEO_ID_HERE \" target=\"_blank\"><img src=\"http://img.youtube.com/vi/YOUTUBE_VIDEO_ID_HERE/0.jpg\" alt=\"IMAGE ALT TEXT HERE\" width=\"240\" height=\"180\" border=\"10\" /></a> Or, in pure Markdown, but losing the image sizing and border: [![IMAGE ALT TEXT HERE](http://img.youtube.com/vi/YOUTUBE_VIDEO_ID_HERE/0.jpg)](http://www.youtube.com/watch?v=YOUTUBE_VIDEO_ID_HERE) Referencing a bug by #bugID in your git commit links it to the slip. For example #1. Admonition !!! type \"optional explicit title within double quotes\" Any number of other indented markdown elements. This is the second paragraph. Some title Any number of other indented markdown elements. This is the second paragraph. And this is outside the admonition again. If you don\u2019t want a title, use a blank string \u201c\u201d. Don\u2019t do this at home! rST suggests the following \u201ctypes\u201d: attention, caution, danger, error, hint, important, note, tip, and warning: Some title This is type note Some title This is type hint Some title This is type tip Some title This is type important Some title This is type attention Some title This is type caution Some title This is type warning Some title This is type danger Some title This is type error Abbreviations The HTML specification is maintained by the W3C. *[HTML]: Hyper Text Markup Language *[W3C]: World Wide Web Consortium The HTML specification is maintained by the W3C . Definition Lists Apple : Pomaceous fruit of plants of the genus Malus in the family Rosaceae. Orange : The fruit of an evergreen tree of the genus Citrus. Apple Pomaceous fruit of plants of the genus Malus in the family Rosaceae. Orange The fruit of an evergreen tree of the genus Citrus. Footnotes Footnotes 1 have a label 2 and the footnote\u2019s content. Another Footnote 3 License: CC-BY This is a footnote content. \u21a9 A footnote on the label: \u201c@#$%\u201d. \u21a9 Another content \u21a9","title":"Markdown Cheatsheet"},{"location":"mdcheat.html#markdown-cheatsheet","text":"This page outlines all stuff available by installing the base Python-Markdown (comes with MkDocs) and the additional bundle PyMdown Extensions . Markdown Cheatsheet Headings The 3rd level The 4th level The 5th level The 6th level Headings with secondary text The 3rd level with secondary text The 4th level with secondary text The 5th level with secondary text The 6th level with secondary text Emphasis Lists Links Images Code and Syntax Highlighting !/bin/bash include Tables Blockquotes Inline HTML Horizontal Rule Line Breaks YouTube Videos Admonition Abbreviations Definition Lists Footnotes","title":"Markdown Cheatsheet"},{"location":"mdcheat.html#headings","text":"### The 3rd level #### The 4th level ##### The 5th level ###### The 6th level ## Headings <small>with secondary text</small> ### The 3rd level <small>with secondary text</small> #### The 4th level <small>with secondary text</small> ##### The 5th level <small>with secondary text</small> ###### The 6th level <small>with secondary text</small>","title":"Headings"},{"location":"mdcheat.html#the-3rd-level","text":"","title":"The 3rd level"},{"location":"mdcheat.html#the-4th-level","text":"","title":"The 4th level"},{"location":"mdcheat.html#the-5th-level","text":"","title":"The 5th level"},{"location":"mdcheat.html#the-6th-level","text":"","title":"The 6th level"},{"location":"mdcheat.html#headings-with-secondary-text","text":"","title":"Headings with secondary text"},{"location":"mdcheat.html#the-3rd-level-with-secondary-text","text":"","title":"The 3rd level with secondary text"},{"location":"mdcheat.html#the-4th-level-with-secondary-text","text":"","title":"The 4th level with secondary text"},{"location":"mdcheat.html#the-5th-level-with-secondary-text","text":"","title":"The 5th level with secondary text"},{"location":"mdcheat.html#the-6th-level-with-secondary-text","text":"","title":"The 6th level with secondary text"},{"location":"mdcheat.html#emphasis","text":"Emphasis, aka italics, with *asterisks* or _underscores_. Strong emphasis, aka bold, with **asterisks** or __underscores__. Combined emphasis with **asterisks and _underscores_**. Strikethrough uses two tildes. ~~Scratch this.~~ Emphasis, aka italics, with asterisks or underscores . Strong emphasis, aka bold, with asterisks or underscores . Combined emphasis with asterisks and underscores . Strikethrough uses two tildes. ~~Scratch this.~~","title":"Emphasis"},{"location":"mdcheat.html#lists","text":"(In this example, leading and trailing spaces are shown with with dots: \u22c5) 1. First ordered list item 2. Another item \u22c5\u22c5\u22c5\u22c5* Unordered sub-list. \u22c5\u22c5\u22c5\u22c5* Item 2 \u22c5\u22c5\u22c5\u22c5* Item 3 1. Actual numbers don't matter, just that it's a number \u22c5\u22c5\u22c5\u22c51. Ordered sub-list \u22c5\u22c5\u22c5\u22c5\u22c5\u22c5\u22c5\u22c51. Ordered subsub-list \u22c5\u22c5\u22c5\u22c5\u22c5\u22c5\u22c5\u22c51. Item 2 \u22c5\u22c5\u22c5\u22c5\u22c5\u22c5\u22c5\u22c51. Item 3 \u22c5\u22c5\u22c5\u22c51. Item 2 \u22c5\u22c5\u22c5\u22c51. Item 3 4. And another item. \u22c5\u22c5\u22c5\u22c5You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we'll use three here to also align the raw Markdown). \u22c5\u22c5\u22c5\u22c5To have a line break without a paragraph, you will need to use two trailing spaces.\u22c5\u22c5 \u22c5\u22c5\u22c5\u22c5Note that this line is separate, but within the same paragraph.\u22c5\u22c5 \u22c5\u22c5\u22c5\u22c5(This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.) * Unordered list can use asterisks - Or minuses + Or pluses First ordered list item Another item Unordered sub-list. Item 2 Item 3 Actual numbers don\u2019t matter, just that it\u2019s a number Ordered sub-list Ordered subsub-list Item 2 Item 3 Item 2 Item 3 And another item. You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we\u2019ll use three here to also align the raw Markdown). To have a line break without a paragraph, you will need to use two trailing spaces. Note that this line is separate, but within the same paragraph. (This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.) Unordered list can use asterisks Or minuses Or pluses","title":"Lists"},{"location":"mdcheat.html#links","text":"There are two ways to create links. [I'm an inline-style link](https://www.google.com) [I'm an inline-style link with title](https://www.google.com \"Google's Homepage\") [I'm a reference-style link][Arbitrary case-insensitive reference text] [I'm a relative reference to a repository file](../blob/master/LICENSE) [You can use numbers for reference-style link definitions][1] Or leave it empty and use the [link text itself]. URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or <http://www.example.com> and sometimes example.com (but not on Github, for example). Some text to show that the reference links can follow later. [arbitrary case-insensitive reference text]: https://www.mozilla.org [1]: http://slashdot.org [link text itself]: http://www.reddit.com I\u2019m an inline-style link I\u2019m an inline-style link with title I\u2019m a reference-style link I\u2019m a relative reference to a repository file You can use numbers for reference-style link definitions Or leave it empty and use the link text itself . URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or http://www.example.com and sometimes example.com (but not on Github, for example). Some text to show that the reference links can follow later.","title":"Links"},{"location":"mdcheat.html#images","text":"Here's our logo (hover to see the title text): Inline-style: ![alt text](https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png \"Logo Title Text 1\") Reference-style: ![alt text][logo] [logo]: https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png \"Logo Title Text 2\" Here\u2019s our logo (hover to see the title text): Inline-style: Reference-style:","title":"Images"},{"location":"mdcheat.html#code-and-syntax-highlighting","text":"Code blocks are part of the Markdown spec, but syntax highlighting isn\u2019t. However, many renderers \u2013 like Github\u2019s and Markdown Here \u2013 support syntax highlighting. Which languages are supported and how those language names should be written will vary from renderer to renderer. Markdown Here supports highlighting for dozens of languages (and not-really-languages, like diffs and HTTP headers); to see the complete list, and how to write the language names, see the highlight.js demo page . Inline `code` has `back-ticks around` it. Inline code has back-ticks around it. Blocks of code are either fenced by lines with three back-ticks ``` , or are indented with four spaces. I recommend only using the fenced code blocks \u2013 they\u2019re easier and only they support syntax highlighting. var s = \"JavaScript syntax highlighting\" ; alert ( s ); s = \"Python syntax highlighting\" print s No language indicated, so no syntax highlighting in Markdown Here (varies on Github). But let's throw in a <b>tag</b>. Even tabbed code example for different language are possible: ```Bash tab=","title":"Code and Syntax Highlighting"},{"location":"mdcheat.html#binbash","text":"STR=\u201dHello World!\u201d echo $STR ```C tab= #include int main(void) { printf(\"hello, world\\n\"); } ```C++ tab=","title":"!/bin/bash"},{"location":"mdcheat.html#include","text":"int main() { std::cout << \u201cHello, world!\\n\u201d; return 0; } ```C# tab= using System; class Program { static void Main(string[] args) { Console.WriteLine(\"Hello, world!\"); } }","title":"include "},{"location":"mdcheat.html#tables","text":"Tables aren\u2019t part of the core Markdown spec, but they are part of GFM and Markdown Here supports them. They are an easy way of adding tables to your email \u2013 a task that would otherwise require copy-pasting from another application. Colons can be used to align columns. | Tables | Are | Cool | | ------------- |:-------------:| -----:| | col 3 is | right-aligned | $1600 | | col 2 is | centered | $12 | | zebra stripes | are neat | $1 | There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don't need to make the raw Markdown line up prettily. You can also use inline Markdown. Markdown | Less | Pretty --- | --- | --- *Still* | `renders` | **nicely** 1 | 2 | 3 Colons can be used to align columns. Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1 There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don\u2019t need to make the raw Markdown line up prettily. You can also use inline Markdown. Markdown Less Pretty Still renders nicely 1 2 3","title":"Tables"},{"location":"mdcheat.html#blockquotes","text":"> Blockquotes are very handy in email to emulate reply text. > This line is part of the same quote. Quote break. > This is a very long line that will still be quoted properly when it wraps. Oh boy let's keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can *put* **Markdown** into a blockquote. Blockquotes are very handy in email to emulate reply text. This line is part of the same quote. Quote break. This is a very long line that will still be quoted properly when it wraps. Oh boy let\u2019s keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can put Markdown into a blockquote. Blockquote nesting is possible: > **Sed aliquet**, neque at rutrum mollis, neque nisi tincidunt nibh, vitae faucibus lacus nunc at lacus. Nunc scelerisque, quam id cursus sodales, lorem [libero fermentum](#) urna, ut efficitur elit ligula et nunc. > > Mauris dictum mi lacus, sit amet pellentesque urna vehicula fringilla. Ut sit amet placerat ante. Proin sed **elementum** __nulla__. Nunc vitae sem odio. Suspendisse ac eros arcu. Vivamus orci erat, volutpat a tempor et, rutrum. eu odio. > > > `Suspendisse rutrum facilisis risus`, eu posuere neque commodo a. Interdum et malesuada fames ac ante ipsum primis in faucibus. Sed nec leo bibendum, sodales mauris ut, tincidunt massa. Sed aliquet , neque at rutrum mollis, neque nisi tincidunt nibh, vitae faucibus lacus nunc at lacus. Nunc scelerisque, quam id cursus sodales, lorem libero fermentum urna, ut efficitur elit ligula et nunc. Mauris dictum mi lacus, sit amet pellentesque urna vehicula fringilla. Ut sit amet placerat ante. Proin sed elementum nulla. Nunc vitae sem odio. Suspendisse ac eros arcu. Vivamus orci erat, volutpat a tempor et, rutrum. eu odio. Suspendisse rutrum facilisis risus , eu posuere neque commodo a. Interdum et malesuada fames ac ante ipsum primis in faucibus. Sed nec leo bibendum, sodales mauris ut, tincidunt massa. Other content blocks within a blockquote Vestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu lectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl, sit amet laoreet nibh. var _extends = function ( target ) { for ( var i = 1 ; i < arguments . length ; i ++ ) { var source = arguments [ i ]; for ( var key in source ) { target [ key ] = source [ key ]; } } return target ; }; Praesent at :::js return target , sodales nibh vel, tempor felis. Fusce vel lacinia lacus. Suspendisse rhoncus nunc non nisi iaculis ultrices. Donec consectetur mauris non neque imperdiet, eget volutpat libero.","title":"Blockquotes"},{"location":"mdcheat.html#inline-html","text":"You can also use raw HTML in your Markdown, and it\u2019ll mostly work pretty well.","title":"Inline HTML"},{"location":"mdcheat.html#horizontal-rule","text":"Three or more... --- Hyphens *** Asterisks ___ Underscores Three or more\u2026 Hyphens Asterisks Underscores","title":"Horizontal Rule"},{"location":"mdcheat.html#line-breaks","text":"My basic recommendation for learning how line breaks work is to experiment and discover \u2013 hit <Enter> once (i.e., insert one newline), then hit it twice (i.e., insert two newlines), see what happens. You\u2019ll soon learn to get what you want. \u201cMarkdown Toggle\u201d is your friend. Here are some things to try out: Here's a line for us to start with. This line is separated from the one above by two newlines, so it will be a *separate paragraph*. This line is also a separate paragraph, but... This line is only separated by a single newline, so it's a separate line in the *same paragraph*. Here\u2019s a line for us to start with. This line is separated from the one above by two newlines, so it will be a separate paragraph . This line is also begins a separate paragraph, but\u2026 This line is only separated by a single newline, so it\u2019s a separate line in the same paragraph .","title":"Line Breaks"},{"location":"mdcheat.html#youtube-videos","text":"They can\u2019t be added directly but you can add an image with a link to the video like this: <a href=\"http://www.youtube.com/watch?feature=player_embedded&v=YOUTUBE_VIDEO_ID_HERE \" target=\"_blank\"><img src=\"http://img.youtube.com/vi/YOUTUBE_VIDEO_ID_HERE/0.jpg\" alt=\"IMAGE ALT TEXT HERE\" width=\"240\" height=\"180\" border=\"10\" /></a> Or, in pure Markdown, but losing the image sizing and border: [![IMAGE ALT TEXT HERE](http://img.youtube.com/vi/YOUTUBE_VIDEO_ID_HERE/0.jpg)](http://www.youtube.com/watch?v=YOUTUBE_VIDEO_ID_HERE) Referencing a bug by #bugID in your git commit links it to the slip. For example #1.","title":"YouTube Videos"},{"location":"mdcheat.html#admonition","text":"!!! type \"optional explicit title within double quotes\" Any number of other indented markdown elements. This is the second paragraph. Some title Any number of other indented markdown elements. This is the second paragraph. And this is outside the admonition again. If you don\u2019t want a title, use a blank string \u201c\u201d. Don\u2019t do this at home! rST suggests the following \u201ctypes\u201d: attention, caution, danger, error, hint, important, note, tip, and warning: Some title This is type note Some title This is type hint Some title This is type tip Some title This is type important Some title This is type attention Some title This is type caution Some title This is type warning Some title This is type danger Some title This is type error","title":"Admonition"},{"location":"mdcheat.html#abbreviations","text":"The HTML specification is maintained by the W3C. *[HTML]: Hyper Text Markup Language *[W3C]: World Wide Web Consortium The HTML specification is maintained by the W3C .","title":"Abbreviations"},{"location":"mdcheat.html#definition-lists","text":"Apple : Pomaceous fruit of plants of the genus Malus in the family Rosaceae. Orange : The fruit of an evergreen tree of the genus Citrus. Apple Pomaceous fruit of plants of the genus Malus in the family Rosaceae. Orange The fruit of an evergreen tree of the genus Citrus.","title":"Definition Lists"},{"location":"mdcheat.html#footnotes","text":"Footnotes 1 have a label 2 and the footnote\u2019s content. Another Footnote 3 License: CC-BY This is a footnote content. \u21a9 A footnote on the label: \u201c@#$%\u201d. \u21a9 Another content \u21a9","title":"Footnotes"},{"location":"quick-start.html","text":"Quick Start This section is intended as a brief introduction into HPC, especially to the present system UBELIX. This page is an summary, a hands-on introduction, which targets primarily users without prior knowledge in high-performance computing. However, basic Linux knowledge is a prerequisite. If you are not familiar with basic Linux commands, there are many beginner tutorials available online. After reading this page you will have composed and submitted your first job successfully to the cluster. Links are provided throughout the text to point you to more in-depth information on the topic. Cluster Rules Before we start: as everywhere where people come together, a common sense is needed to allow for a good cooperation and to enable a positive HPC experience. Be always aware that you are working on a shared system where your behaviour could have a negative impact on the workflow of other users. Please find the list of the most important guidelines in our code of conduct . Request an Account Before you can start working on the HPCs, staff and students of the University of Bern must have their Campus Account (CA) registered for the HPCs. External researchers that collaborate with an institute of the University of Bern must apply for a CA through that institute. See Accounts and Activation for more information getting access to UBELIX. HPC Workspace Workspaces provide are a collaborative environment, including group based access to permanent and temporary storage, as well as group based compute resource accounting. Research group leaders need to apply for an workspace, see Workspace Management . For an introduction to HPC Workspaces see Workspace Overview Login To connect to the cluster, you must log in to the submit host from inside the university network (e.g. from a workstation on the campus). If you want to connect from a remote location (e.g. from your computer at home) you must first establish a VPN connection to get access to the university network. To connect from a UNIX-like system (Linux, Mac OS X, MobaXterm on Windows) simply use a secure shell (SSH) to log in to the submit host: ssh <username>@submit.unibe.ch # the following is equivalent ssh -l <username> submit.unibe.ch Welcome $HOME After successful login to the cluster, your will find yourself in the directory /storage/homefs/$USER , where $USER is your Campus Account username. This is your home directory and serves as the repository for your personal files, and configurations. You can reference your home directory by ~ or $HOME . Your home directory is located on a shared file system. Therefore, all files and directories are always available on all cluster nodes and must hence not be copied between those nodes. HOME directories have a daily snapshot and backup procedures. Disk space is managed by quotas . By default, each user has 1TB of disk space available. Keep your home directory clean by regularly deleting old data or by moving data to a private storage. You can always print the current working directory using the pwd (present working directory) command: pwd /storage/homefs/<username> Copy Data At some point, you will probably need to copy files between your local computer and the cluster. There are different ways to achieve this, depending on your local operating system (OS). To copy a file from your local computer running a UNIX-like OS use the secure copy command scp on your local workstation: scp /path/to/file <username>@submit.unibe.ch:/path/to/target_dir/ To copy a file from the cluster to your local computer running a UNIX-like OS also use the secure copy command scp on your local workstation: scp <username>@submit.unibe.ch:/path/to/file /path/to/target_dir/ More information about file transfer can be found on the page File Transfer to/from UBELIX . Use Software On our HPCs you can make use of already pre-installed software or you can compile and install your own software. We use a module system to manage software packages, even different versions of the same software. This allows you to focus on getting your work done instead of compiling software. E.g. to get a list of all provided packages: module avail A package name can be added to list all packages containing that string. The module spider command encountering also results from the VitalIT software stack. Workspace software stacks module spider or module avail will only find packages in a Workspace software stack if the Workspace module for that workspace is loaded Furthermore, we are suggesting to work with so called toolchains. These are collections of modules build on top of each other. E.g. setting the environment for compiling an scientific application with math. libraries, OpenMPI and GCC, load: $ module load foss $ module list module list Currently Loaded Modules: 1 ) GCCcore/9.3.0 4 ) GCC/9.3.0 7 ) libxml2/.2.9.10-GCCcore-9.3.0 ( H ) 10 ) UCX/1.8.0-GCCcore-9.3.0 13 ) gompi/2020a 16 ) foss/2020a 2 ) zlib/.1.2.11-GCCcore-9.3.0 ( H ) 5 ) numactl/2.0.13-GCCcore-9.3.0 8 ) libpciaccess/.0.16-GCCcore-9.3.0 ( H ) 11 ) OpenMPI/4.0.3-GCC-9.3.0 14 ) FFTW/3.3.8-gompi-2020a 3 ) binutils/.2.34-GCCcore-9.3.0 ( H ) 6 ) XZ/.5.2.5-GCCcore-9.3.0 ( H ) 9 ) hwloc/2.2.0-GCCcore-9.3.0 12 ) OpenBLAS/0.3.9-GCC-9.3.0 15 ) ScaLAPACK/2.1.0-gompi-2020a Where: H: Hidden Module You can also specify version numbers there. Scope The loaded version of a software is only active in your current session. If you open a new shell you are again using the default version of the software. Therefore, it is crucial to load the required modules from within your job script. But also keep in mind that the current environment will get forwarded into a job submitted from it. This may lead to conflicting versions of loaded modules and modules loaded in the script. With the module environment you can also easily install, maintain and provide software packages in your workspaces and share with your collaborators. The Software section is dedicated to this topic. More information can be found there. Managing different working environments can be done with \u201cMeta Modules\u201d or user collections, see Environment Definitions Hello World Doing useful computations consists of running commands that work on data and generate a result. These computations are resource-intensive. That is what the compute nodes are there for. These over 300 servers do the heavy lifting as soon as resources are free for you. Currently you are on a submit server also known as login server. This server is for preparing the computations, i.e. downloading data, writing a job script, prepare some data etc. But you mustn\u2019t run computations on submit nodes as the server is quite a weak machines that you are sharing with others. So, you have to bring the computations to the compute nodes - by generating a job script and sending it to the cluster. Working interactively on a compute node When developing stuff it\u2019s often useful to have short iterations of try-error. Therefore it\u2019s also possible to work interactively on a compute node for a certain amount of time without having to send jobs to the cluster and wait until they finish just to see it didn\u2019t work. See Interactive Jobs for more information about this topic. It\u2019s now time for your first job script. To do some work on the cluster, you require certain resources (e.g. CPUs and memory) and a description of the computations to be done. A job consists of instructions to the scheduler in the form of option flags, and statements that describe the actual tasks. Let\u2019s start with the instructions to the scheduler: #!/bin/bash #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=1GB # Put your code below this line ... The first line makes sure that the file is executed using the bash shell. The remaining lines are option flags used by the sbatch command. The page Jobs Submission outlines the most important options of sbatch . Now, let\u2019s write a simple \u201chello, world\u201d-task: ... # Put your code below this line module load Workspace_Home mkdir -p $SCRATCH /my_first_job cd $SCRATCH /my_first_job echo \"Hello, UBELIX from node $( hostname ) \" > hello.txt After loading the Workspace module, we create a new directory \u2018my_first_job\u2019 within our \u201cpersonal\u201d SCRATCH directory. The variable $SCRATCH expands to /storage/scratch/users/<your_username> . Then, we change directory to the newly created directory. In the third line we print the line Hello, Ubelix from node <hostname_of_the_executing_node> and redirect the output to a file named hello.txt . The expression $(hostname) means, run the command hostname and put its output here. Save the content to a file named first.sh . The complete job script looks like this: #!/bin/bash #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=1GB # Put your code below this line module load Workspace_Home mkdir -p $SCRATCH /my_first_job cd $SCRATCH /my_first_job echo \"Hello, UBELIX from node $( hostname ) \" > hello.txt Schedule Your Job We can now submit our first job to the scheduler. The scheduler will then provide the requested resources to the job. If all requested resources are already available, then your job can start immediately. Otherwise your job will wait until enough resources are available. We submit our job to the scheduler using the sbatch command: sbatch first.sh Submitted batch job 32490640 If the job is submitted successfully, the command outputs a job-ID with which you can refer to your job later on. There are various options for different types of jobs provided in the scheduler. See sections Array Jobs , GPUs , and Interactive Jobs for more information Monitor Your Job You can inspect the state of our active jobs (running or pending) with the squeue command: squeue --job = 32490640 JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 32490640 epyc2 job01 testuser R 0:22 1 bnode23 Here you can see that the job \u2018job01\u2019 with job-ID 32490640 is in state RUNNING (R). The job is running in the \u2018epyc2\u2019 partition (default partition) on bnode23 for 22 seconds. It is also possible that the job can not start immediately after submitting it to lsf because the requested resources are not yet available. In this case, the output could look like this: squeue --job = 32490640 JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 32490640 epyc2 job01 testuser PD 0:00 1 (Priority) Here you can see that the job is in state PENDING (PD) and a reason why the job is pending. In this example, the job has to wait for at least one other job with higher priority. See here for a list of other reasons why a job might be pending. You can always list all your active (pending or running) jobs with squeue: squeue --user = testuser JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 34651451 epyc2 lsf.sh testuser PD 0:00 2 (Priority) 34651453 epyc2 lsf.sh testuser PD 0:00 2 (Priority) 29143227 epyc2 Rjob testuser PD 0:00 4 (JobHeldUser) 37856328 bdw mpi.sh testuser R 4:38 2 anode[012-014] 32634559 bdw fast.sh testuser R 2:52:37 1 anode12 32634558 bdw fast.sh testuser R 3:00:54 1 anode14 32634554 bdw fast.sh testuser R 4:11:26 1 anode08 32633556 bdw fast.sh testuser R 4:36:10 1 anode08 Further information on on job monitoring you find on page Monitoring Jobs . Furthermore, in the Job handling section you find additional information about Investigating a Job Failure and Check-pointing . Training Courses Science IT Support (ScITS) regularly conducts introductory and advanced courses on Linux, UBELIX and other topics. Details outlined on their pages .","title":"Quick Start"},{"location":"quick-start.html#quick-start","text":"This section is intended as a brief introduction into HPC, especially to the present system UBELIX. This page is an summary, a hands-on introduction, which targets primarily users without prior knowledge in high-performance computing. However, basic Linux knowledge is a prerequisite. If you are not familiar with basic Linux commands, there are many beginner tutorials available online. After reading this page you will have composed and submitted your first job successfully to the cluster. Links are provided throughout the text to point you to more in-depth information on the topic.","title":"Quick Start"},{"location":"quick-start.html#cluster-rules","text":"Before we start: as everywhere where people come together, a common sense is needed to allow for a good cooperation and to enable a positive HPC experience. Be always aware that you are working on a shared system where your behaviour could have a negative impact on the workflow of other users. Please find the list of the most important guidelines in our code of conduct .","title":"Cluster Rules"},{"location":"quick-start.html#request-an-account","text":"Before you can start working on the HPCs, staff and students of the University of Bern must have their Campus Account (CA) registered for the HPCs. External researchers that collaborate with an institute of the University of Bern must apply for a CA through that institute. See Accounts and Activation for more information getting access to UBELIX.","title":"Request an Account"},{"location":"quick-start.html#hpc-workspace","text":"Workspaces provide are a collaborative environment, including group based access to permanent and temporary storage, as well as group based compute resource accounting. Research group leaders need to apply for an workspace, see Workspace Management . For an introduction to HPC Workspaces see Workspace Overview","title":"HPC Workspace"},{"location":"quick-start.html#login","text":"To connect to the cluster, you must log in to the submit host from inside the university network (e.g. from a workstation on the campus). If you want to connect from a remote location (e.g. from your computer at home) you must first establish a VPN connection to get access to the university network. To connect from a UNIX-like system (Linux, Mac OS X, MobaXterm on Windows) simply use a secure shell (SSH) to log in to the submit host: ssh <username>@submit.unibe.ch # the following is equivalent ssh -l <username> submit.unibe.ch","title":"Login"},{"location":"quick-start.html#welcome-home","text":"After successful login to the cluster, your will find yourself in the directory /storage/homefs/$USER , where $USER is your Campus Account username. This is your home directory and serves as the repository for your personal files, and configurations. You can reference your home directory by ~ or $HOME . Your home directory is located on a shared file system. Therefore, all files and directories are always available on all cluster nodes and must hence not be copied between those nodes. HOME directories have a daily snapshot and backup procedures. Disk space is managed by quotas . By default, each user has 1TB of disk space available. Keep your home directory clean by regularly deleting old data or by moving data to a private storage. You can always print the current working directory using the pwd (present working directory) command: pwd /storage/homefs/<username>","title":"Welcome $HOME"},{"location":"quick-start.html#copy-data","text":"At some point, you will probably need to copy files between your local computer and the cluster. There are different ways to achieve this, depending on your local operating system (OS). To copy a file from your local computer running a UNIX-like OS use the secure copy command scp on your local workstation: scp /path/to/file <username>@submit.unibe.ch:/path/to/target_dir/ To copy a file from the cluster to your local computer running a UNIX-like OS also use the secure copy command scp on your local workstation: scp <username>@submit.unibe.ch:/path/to/file /path/to/target_dir/ More information about file transfer can be found on the page File Transfer to/from UBELIX .","title":"Copy Data"},{"location":"quick-start.html#use-software","text":"On our HPCs you can make use of already pre-installed software or you can compile and install your own software. We use a module system to manage software packages, even different versions of the same software. This allows you to focus on getting your work done instead of compiling software. E.g. to get a list of all provided packages: module avail A package name can be added to list all packages containing that string. The module spider command encountering also results from the VitalIT software stack. Workspace software stacks module spider or module avail will only find packages in a Workspace software stack if the Workspace module for that workspace is loaded Furthermore, we are suggesting to work with so called toolchains. These are collections of modules build on top of each other. E.g. setting the environment for compiling an scientific application with math. libraries, OpenMPI and GCC, load: $ module load foss $ module list module list Currently Loaded Modules: 1 ) GCCcore/9.3.0 4 ) GCC/9.3.0 7 ) libxml2/.2.9.10-GCCcore-9.3.0 ( H ) 10 ) UCX/1.8.0-GCCcore-9.3.0 13 ) gompi/2020a 16 ) foss/2020a 2 ) zlib/.1.2.11-GCCcore-9.3.0 ( H ) 5 ) numactl/2.0.13-GCCcore-9.3.0 8 ) libpciaccess/.0.16-GCCcore-9.3.0 ( H ) 11 ) OpenMPI/4.0.3-GCC-9.3.0 14 ) FFTW/3.3.8-gompi-2020a 3 ) binutils/.2.34-GCCcore-9.3.0 ( H ) 6 ) XZ/.5.2.5-GCCcore-9.3.0 ( H ) 9 ) hwloc/2.2.0-GCCcore-9.3.0 12 ) OpenBLAS/0.3.9-GCC-9.3.0 15 ) ScaLAPACK/2.1.0-gompi-2020a Where: H: Hidden Module You can also specify version numbers there. Scope The loaded version of a software is only active in your current session. If you open a new shell you are again using the default version of the software. Therefore, it is crucial to load the required modules from within your job script. But also keep in mind that the current environment will get forwarded into a job submitted from it. This may lead to conflicting versions of loaded modules and modules loaded in the script. With the module environment you can also easily install, maintain and provide software packages in your workspaces and share with your collaborators. The Software section is dedicated to this topic. More information can be found there. Managing different working environments can be done with \u201cMeta Modules\u201d or user collections, see Environment Definitions","title":"Use Software"},{"location":"quick-start.html#hello-world","text":"Doing useful computations consists of running commands that work on data and generate a result. These computations are resource-intensive. That is what the compute nodes are there for. These over 300 servers do the heavy lifting as soon as resources are free for you. Currently you are on a submit server also known as login server. This server is for preparing the computations, i.e. downloading data, writing a job script, prepare some data etc. But you mustn\u2019t run computations on submit nodes as the server is quite a weak machines that you are sharing with others. So, you have to bring the computations to the compute nodes - by generating a job script and sending it to the cluster. Working interactively on a compute node When developing stuff it\u2019s often useful to have short iterations of try-error. Therefore it\u2019s also possible to work interactively on a compute node for a certain amount of time without having to send jobs to the cluster and wait until they finish just to see it didn\u2019t work. See Interactive Jobs for more information about this topic. It\u2019s now time for your first job script. To do some work on the cluster, you require certain resources (e.g. CPUs and memory) and a description of the computations to be done. A job consists of instructions to the scheduler in the form of option flags, and statements that describe the actual tasks. Let\u2019s start with the instructions to the scheduler: #!/bin/bash #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=1GB # Put your code below this line ... The first line makes sure that the file is executed using the bash shell. The remaining lines are option flags used by the sbatch command. The page Jobs Submission outlines the most important options of sbatch . Now, let\u2019s write a simple \u201chello, world\u201d-task: ... # Put your code below this line module load Workspace_Home mkdir -p $SCRATCH /my_first_job cd $SCRATCH /my_first_job echo \"Hello, UBELIX from node $( hostname ) \" > hello.txt After loading the Workspace module, we create a new directory \u2018my_first_job\u2019 within our \u201cpersonal\u201d SCRATCH directory. The variable $SCRATCH expands to /storage/scratch/users/<your_username> . Then, we change directory to the newly created directory. In the third line we print the line Hello, Ubelix from node <hostname_of_the_executing_node> and redirect the output to a file named hello.txt . The expression $(hostname) means, run the command hostname and put its output here. Save the content to a file named first.sh . The complete job script looks like this: #!/bin/bash #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=1GB # Put your code below this line module load Workspace_Home mkdir -p $SCRATCH /my_first_job cd $SCRATCH /my_first_job echo \"Hello, UBELIX from node $( hostname ) \" > hello.txt","title":"Hello World"},{"location":"quick-start.html#schedule-your-job","text":"We can now submit our first job to the scheduler. The scheduler will then provide the requested resources to the job. If all requested resources are already available, then your job can start immediately. Otherwise your job will wait until enough resources are available. We submit our job to the scheduler using the sbatch command: sbatch first.sh Submitted batch job 32490640 If the job is submitted successfully, the command outputs a job-ID with which you can refer to your job later on. There are various options for different types of jobs provided in the scheduler. See sections Array Jobs , GPUs , and Interactive Jobs for more information","title":"Schedule Your Job"},{"location":"quick-start.html#monitor-your-job","text":"You can inspect the state of our active jobs (running or pending) with the squeue command: squeue --job = 32490640 JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 32490640 epyc2 job01 testuser R 0:22 1 bnode23 Here you can see that the job \u2018job01\u2019 with job-ID 32490640 is in state RUNNING (R). The job is running in the \u2018epyc2\u2019 partition (default partition) on bnode23 for 22 seconds. It is also possible that the job can not start immediately after submitting it to lsf because the requested resources are not yet available. In this case, the output could look like this: squeue --job = 32490640 JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 32490640 epyc2 job01 testuser PD 0:00 1 (Priority) Here you can see that the job is in state PENDING (PD) and a reason why the job is pending. In this example, the job has to wait for at least one other job with higher priority. See here for a list of other reasons why a job might be pending. You can always list all your active (pending or running) jobs with squeue: squeue --user = testuser JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 34651451 epyc2 lsf.sh testuser PD 0:00 2 (Priority) 34651453 epyc2 lsf.sh testuser PD 0:00 2 (Priority) 29143227 epyc2 Rjob testuser PD 0:00 4 (JobHeldUser) 37856328 bdw mpi.sh testuser R 4:38 2 anode[012-014] 32634559 bdw fast.sh testuser R 2:52:37 1 anode12 32634558 bdw fast.sh testuser R 3:00:54 1 anode14 32634554 bdw fast.sh testuser R 4:11:26 1 anode08 32633556 bdw fast.sh testuser R 4:36:10 1 anode08 Further information on on job monitoring you find on page Monitoring Jobs . Furthermore, in the Job handling section you find additional information about Investigating a Job Failure and Check-pointing .","title":"Monitor Your Job"},{"location":"quick-start.html#training-courses","text":"Science IT Support (ScITS) regularly conducts introductory and advanced courses on Linux, UBELIX and other topics. Details outlined on their pages .","title":"Training Courses"},{"location":"file-system/file-transfer.html","text":"File Transfer from/to UBELIX Description This page contains some basic information about moving files between your local workstation and the cluster. Mac/Linux/Windows You can use different protocols/programs for transferring files from/to the cluster, depending on your need: Sftp, SCP, Rsync, Wget, and others. The following commands are from on your local workstation as indicated by \u201clocal$\u201d If you have customized your SSH environment as described here, you can substitute your host alias for @submit.unibe.ch in the following commands Secure Copy (SCP) - Mac/Linux Secure Copy is a program (also a protocol) that allows you to securely transfer files between local and remote hosts. SCP uses SSH for transferring data and managing authentication. SCP performs a plain linear copy of the specified files, while replacing already existing files with the same name. If you need more sophisticated control over your copy process, consider Rsync . Syntax scp [options] source destination Some common options -r : copy directories recursively (Note that SCP follows symbolic links encountered in the tree traversal) -p : preserve modification time, access time, and modes from the original file -v : verbose mode Copying Files from Your Local Workstation to UBELIX Copy the file ~/dir/file01 to your remote home directory: $ scp ~/dir/file01 <username>@submit.unibe.ch: Copy multiple files to the remote directory ~/bar : The destination directory must already exist. You can create a directory from remote with: ssh @submit.unibe.ch \u2018mkdir -p ~/bar\u2019 $ scp ~/dir/file01 ~/dir/file02 ~/dir/file03 <username>@submit.unibe.ch:bar Copy all files within directory ~/dir to the remote directory ~/bar : Add the -r option (recursive) to also copy all subdirectories of ~/dir $ scp -r ~/dir/* <username>@submit.unibe.ch:bar Copy the directory ~/dir to your remote home directory: This will create a new directory ~/dir on the remote host. If the directory ~/dir already exists, the following command adds the content of the source directory to the destination directory $ scp -r ~/dir <username>@submit.unibe.ch: Copying Files from UBELIX to Your Local Workstation Copy the remote file ~/bar/file01 to the current working directory on your local workstation: $ scp <username>@submit.unibe.ch:bar/file01 . Copy multiple remote files to the local directory ~/dir : The local directory ~/dir will be automatically created if it does not already exist $ scp <username>@submit.unibe.ch:bar/ \\{ file02,file03,file04 \\} ~/dir Copy the remote directory ~/bar to the current working directory on your local workstation: $ scp -r <username>@submit.unibe.ch:bar . Remote Sync (Rsync) - Mac/Linux Rsync implements a sophisticated algorithm that allows to transfer only missing/non-matching parts of a source file to update a target file. With this the process of transferring data may be significantly faster than simply replacing all data. Among other things, Rsync also allows you to specify complex filter rules to exclude certain files or directories located inside a directory that you want to sync. Syntax rsync [options] source destination Some common options -r : copy directories recursively (does not preserve timestamps and permissions) -a : archive mode (like -r, but also preserves timestamps, permissions, ownership, and copies symlinks as symlinks) -z : compress data -v : verbose mode (additional v\u2019s will increase verbosity level) -n : dry-run -h : output numbers in a human readable format Copying Files from Your Local Workstation to UBELIX Copy the file ~/dir/file01 to your remote home directory: $ rsync ~/dir/file01 <username>@submit.unibe.ch: Copy multiple files to your remote home directory: $ rsync file01 file02 file03 <username>@submit.unibe.ch: Copy the local directory ~/dir to the remote directory ~/bar: With a trailing slash (/) after the source directory only the content of the source directory is copied to the destination directory. Without a trailing slash both the source directory and the content of the directory are copied to the destination directory $ rsync -az ~/dir/ <username>@submit.unibe.ch:bar Copying Files from UBELIX to Your Local Workstation Copy the remote file ~/foo/file01 to your current working directory: $ rsync <username>@submit.unibe.ch:foo/file01 . Copy the remote files ~/foo/file01 and ~/bar/file02 to your the local directory ~/dir : $ rsync <username>@submit.unibe.ch: \\{ foo/file01,bar/file02 \\} ~/dir Copy the remote directory ~/foo to the local directory ~/dir : With a trailing slash (/) after the source directory only the content of the source directory is copied to the destination directory. Without a trailing slash both the source directory and the content of the directory are copied to the destination directory. $ rsync -az <username>@submit.unibe.ch:foo/ ~/dir Including/Excluding Files With the --include / --exclude options you can specify patterns, that describe which files are not excluded/excluded from the copy process. Use the -n option with the -v option to perform a dry-run while listing the files that would be copied Exclude a specific directory: rsync -av --exclude \"subdir1\" ~/dir/ <username>@submit.unibe.ch: Copy only files with suffix .txt and .m : rsync -av --include \"*.txt\" --include \"*.m\" --exclude \"*\" ~/dir/ <username>@submit.unibe.ch: Copy all files with suffix .m within the source directory ~/dir (including matching files within subdirectories) to the remote destination directory ~/foo : Use the --prune-empty-dirs option to omit copying empty directories $ rsync -av --prune-empty-dirs --include \"*/\" --include \"*.m\" --exclude \"*\" ~/dir/ <username>@submit.unibe.ch:foo Deleting Files None of the following commands will delete any files in your source folder This delete options can be dangerous if used incorrectly! Perform a dry-run ( -n option) first and verify that important files are not listed ( -v option) for deletion Use the --delete option to delete files/directories from the destination directory that are not/no more present in the source directory: $ rsync -av --delete ~/dir/ <username>@submit.unibe.ch:mfiles With the --delete-excluded option you can additionally delete files from the destination directory that are excluded from transferring/syncing (not in the generated file list): $ rsync -av --prune-empty-dirs --delete-excluded --include \"*/\" --include \"*.m\" --exclude \"*\" ~/dir/ <username>@submit.unibe.ch:foo MobaXterm - Windows In MobaXterm there are multiple ways to transfer files. After initializing/starting a session to UBELIX copied by \u201cdrag and drop\u201d in the File browser on the left hand side. Further the local terminal can be used to transfer files using commands described above.","title":"Moving files to and from the HPCs"},{"location":"file-system/file-transfer.html#file-transfer-fromto-ubelix","text":"","title":"File Transfer from/to UBELIX"},{"location":"file-system/file-transfer.html#description","text":"This page contains some basic information about moving files between your local workstation and the cluster.","title":"Description"},{"location":"file-system/file-transfer.html#maclinuxwindows","text":"You can use different protocols/programs for transferring files from/to the cluster, depending on your need: Sftp, SCP, Rsync, Wget, and others. The following commands are from on your local workstation as indicated by \u201clocal$\u201d If you have customized your SSH environment as described here, you can substitute your host alias for @submit.unibe.ch in the following commands","title":"Mac/Linux/Windows"},{"location":"file-system/file-transfer.html#secure-copy-scp-maclinux","text":"Secure Copy is a program (also a protocol) that allows you to securely transfer files between local and remote hosts. SCP uses SSH for transferring data and managing authentication. SCP performs a plain linear copy of the specified files, while replacing already existing files with the same name. If you need more sophisticated control over your copy process, consider Rsync . Syntax scp [options] source destination Some common options -r : copy directories recursively (Note that SCP follows symbolic links encountered in the tree traversal) -p : preserve modification time, access time, and modes from the original file -v : verbose mode","title":"Secure Copy (SCP) - Mac/Linux"},{"location":"file-system/file-transfer.html#copying-files-from-your-local-workstation-to-ubelix","text":"Copy the file ~/dir/file01 to your remote home directory: $ scp ~/dir/file01 <username>@submit.unibe.ch: Copy multiple files to the remote directory ~/bar : The destination directory must already exist. You can create a directory from remote with: ssh @submit.unibe.ch \u2018mkdir -p ~/bar\u2019 $ scp ~/dir/file01 ~/dir/file02 ~/dir/file03 <username>@submit.unibe.ch:bar Copy all files within directory ~/dir to the remote directory ~/bar : Add the -r option (recursive) to also copy all subdirectories of ~/dir $ scp -r ~/dir/* <username>@submit.unibe.ch:bar Copy the directory ~/dir to your remote home directory: This will create a new directory ~/dir on the remote host. If the directory ~/dir already exists, the following command adds the content of the source directory to the destination directory $ scp -r ~/dir <username>@submit.unibe.ch:","title":"Copying Files from Your Local Workstation to UBELIX"},{"location":"file-system/file-transfer.html#copying-files-from-ubelix-to-your-local-workstation","text":"Copy the remote file ~/bar/file01 to the current working directory on your local workstation: $ scp <username>@submit.unibe.ch:bar/file01 . Copy multiple remote files to the local directory ~/dir : The local directory ~/dir will be automatically created if it does not already exist $ scp <username>@submit.unibe.ch:bar/ \\{ file02,file03,file04 \\} ~/dir Copy the remote directory ~/bar to the current working directory on your local workstation: $ scp -r <username>@submit.unibe.ch:bar .","title":"Copying Files from UBELIX to Your Local Workstation"},{"location":"file-system/file-transfer.html#remote-sync-rsync-maclinux","text":"Rsync implements a sophisticated algorithm that allows to transfer only missing/non-matching parts of a source file to update a target file. With this the process of transferring data may be significantly faster than simply replacing all data. Among other things, Rsync also allows you to specify complex filter rules to exclude certain files or directories located inside a directory that you want to sync. Syntax rsync [options] source destination Some common options -r : copy directories recursively (does not preserve timestamps and permissions) -a : archive mode (like -r, but also preserves timestamps, permissions, ownership, and copies symlinks as symlinks) -z : compress data -v : verbose mode (additional v\u2019s will increase verbosity level) -n : dry-run -h : output numbers in a human readable format","title":"Remote Sync (Rsync) - Mac/Linux"},{"location":"file-system/file-transfer.html#copying-files-from-your-local-workstation-to-ubelix_1","text":"Copy the file ~/dir/file01 to your remote home directory: $ rsync ~/dir/file01 <username>@submit.unibe.ch: Copy multiple files to your remote home directory: $ rsync file01 file02 file03 <username>@submit.unibe.ch: Copy the local directory ~/dir to the remote directory ~/bar: With a trailing slash (/) after the source directory only the content of the source directory is copied to the destination directory. Without a trailing slash both the source directory and the content of the directory are copied to the destination directory $ rsync -az ~/dir/ <username>@submit.unibe.ch:bar","title":"Copying Files from Your Local Workstation to UBELIX"},{"location":"file-system/file-transfer.html#copying-files-from-ubelix-to-your-local-workstation_1","text":"Copy the remote file ~/foo/file01 to your current working directory: $ rsync <username>@submit.unibe.ch:foo/file01 . Copy the remote files ~/foo/file01 and ~/bar/file02 to your the local directory ~/dir : $ rsync <username>@submit.unibe.ch: \\{ foo/file01,bar/file02 \\} ~/dir Copy the remote directory ~/foo to the local directory ~/dir : With a trailing slash (/) after the source directory only the content of the source directory is copied to the destination directory. Without a trailing slash both the source directory and the content of the directory are copied to the destination directory. $ rsync -az <username>@submit.unibe.ch:foo/ ~/dir","title":"Copying Files from UBELIX to Your Local Workstation"},{"location":"file-system/file-transfer.html#includingexcluding-files","text":"With the --include / --exclude options you can specify patterns, that describe which files are not excluded/excluded from the copy process. Use the -n option with the -v option to perform a dry-run while listing the files that would be copied Exclude a specific directory: rsync -av --exclude \"subdir1\" ~/dir/ <username>@submit.unibe.ch: Copy only files with suffix .txt and .m : rsync -av --include \"*.txt\" --include \"*.m\" --exclude \"*\" ~/dir/ <username>@submit.unibe.ch: Copy all files with suffix .m within the source directory ~/dir (including matching files within subdirectories) to the remote destination directory ~/foo : Use the --prune-empty-dirs option to omit copying empty directories $ rsync -av --prune-empty-dirs --include \"*/\" --include \"*.m\" --exclude \"*\" ~/dir/ <username>@submit.unibe.ch:foo","title":"Including/Excluding Files"},{"location":"file-system/file-transfer.html#deleting-files","text":"None of the following commands will delete any files in your source folder This delete options can be dangerous if used incorrectly! Perform a dry-run ( -n option) first and verify that important files are not listed ( -v option) for deletion Use the --delete option to delete files/directories from the destination directory that are not/no more present in the source directory: $ rsync -av --delete ~/dir/ <username>@submit.unibe.ch:mfiles With the --delete-excluded option you can additionally delete files from the destination directory that are excluded from transferring/syncing (not in the generated file list): $ rsync -av --prune-empty-dirs --delete-excluded --include \"*/\" --include \"*.m\" --exclude \"*\" ~/dir/ <username>@submit.unibe.ch:foo","title":"Deleting Files"},{"location":"file-system/file-transfer.html#mobaxterm-windows","text":"In MobaXterm there are multiple ways to transfer files. After initializing/starting a session to UBELIX copied by \u201cdrag and drop\u201d in the File browser on the left hand side. Further the local terminal can be used to transfer files using commands described above.","title":"MobaXterm - Windows"},{"location":"file-system/filesystem-overview.html","text":"File Systems Overview HOME: $HOME directories are located under /home/$USER , where $USER is the campus account. $HOME is limited to maximum 1TB and is meant for private and configuration data. There is no data sharing workflow considerred for $HOME . If you want to share data with collaborators please ask your research group leader to request an HPC Workspace. Reqular Snapshots provide possibility to recover accidentally modified or deleted data. Some application, by default, use the $HOME file system even for larger amount of data, e.g. user packages in Python or R. Often this can be redirected, e.g. using --prefix option or in worse case using a symbolic link to a project directory. Get in touch with us if you need assistance. HPC Workspaces In HPC Workspaces access is defined in two user defined access groups. A primary read/write group is meant to be the data owner, while a secondary has only read access. The sizes of these spaces are managed by the Workspace owners. Beside a free of charge quota, the space can be extended with costs. For more details see Workspace management Research Storage shares The predecessor of HPC Workspaces are Research Storage Shares. These file spaces are located under /storage/research/... . These are fully managed by HPC support team. All modifications need to be requested via support request on the Service Portal. We aim to migrate these spaces and their data into HPC Workspaces. Therewith users can use all the tools and framework around HPC Workspaces and also the free of charge quota. SCRATCH SCRATCH is a temporary space with less restrictive limitations in size, but more restrictive limitation in time. There is no snapshot or backup service implemented in that space. Cleaning Policy under Construction detailed information will follow soon Quota For HOME and WORKSPACES total storage size and amount of files are limited. The current used amount and limits can be displayed using the quota tool, see File System Quota","title":"Overview"},{"location":"file-system/filesystem-overview.html#file-systems-overview","text":"","title":"File Systems Overview"},{"location":"file-system/filesystem-overview.html#home","text":"$HOME directories are located under /home/$USER , where $USER is the campus account. $HOME is limited to maximum 1TB and is meant for private and configuration data. There is no data sharing workflow considerred for $HOME . If you want to share data with collaborators please ask your research group leader to request an HPC Workspace. Reqular Snapshots provide possibility to recover accidentally modified or deleted data. Some application, by default, use the $HOME file system even for larger amount of data, e.g. user packages in Python or R. Often this can be redirected, e.g. using --prefix option or in worse case using a symbolic link to a project directory. Get in touch with us if you need assistance.","title":"HOME:"},{"location":"file-system/filesystem-overview.html#hpc-workspaces","text":"In HPC Workspaces access is defined in two user defined access groups. A primary read/write group is meant to be the data owner, while a secondary has only read access. The sizes of these spaces are managed by the Workspace owners. Beside a free of charge quota, the space can be extended with costs. For more details see Workspace management","title":"HPC Workspaces"},{"location":"file-system/filesystem-overview.html#research-storage-shares","text":"The predecessor of HPC Workspaces are Research Storage Shares. These file spaces are located under /storage/research/... . These are fully managed by HPC support team. All modifications need to be requested via support request on the Service Portal. We aim to migrate these spaces and their data into HPC Workspaces. Therewith users can use all the tools and framework around HPC Workspaces and also the free of charge quota.","title":"Research Storage shares"},{"location":"file-system/filesystem-overview.html#scratch","text":"SCRATCH is a temporary space with less restrictive limitations in size, but more restrictive limitation in time. There is no snapshot or backup service implemented in that space.","title":"SCRATCH"},{"location":"file-system/filesystem-overview.html#cleaning-policy","text":"under Construction detailed information will follow soon","title":"Cleaning Policy"},{"location":"file-system/filesystem-overview.html#quota","text":"For HOME and WORKSPACES total storage size and amount of files are limited. The current used amount and limits can be displayed using the quota tool, see File System Quota","title":"Quota"},{"location":"file-system/quota.html","text":"File System Quota Description This page contains information about quota limits on the parallel file system. Quotas are enabled to control the file system usage. Job abortion Jobs will fail if no more disk space can be allocated, or if no more files can be created because the respective quota hard limit is exceeded Quotas space quota file quota backup expiration HOME 1TB 1M yes - WORKSPACE free: up to 10TB per research group 1 1M per TB yes 1 year 2 SCRATCH 30TB 3 10M 3 no 1 month 4 Display quota information A quota tool is delivered with the Workspace module: $ quota UniBE Workspace Quota report ============================ : used ( GB )( % ) , quota ( GB ) | files used ( % ) , quota ================================================================================== HOME : 420 ( 41 % ) , 1024 | 773425 ( 77 % ) , 1000000 Workspace1 : 101 ( 1 % ) , 10240 | 3 ( 0 % ) , 10000000 Furthermore, there is a more detailed version using the -l or --long option $ quota -l UniBE Workspace Quota report ============================ : free quota, used ( GB )( % ) , quota ( GB ) | files used ( % ) , quota | start date ( 1 ) , average quota ( 2 ) ================================================================================================================================ HOME : all, 421 ( 41 % ) , 1024 | 796058 ( 79 % ) , 1000000 | , SCR_usr : all, 269 ( 0 % ) , 30720 | 22 ( 0 % ) , 10000000 | , Workspace1 : 5 , 101 ( 1 % ) , 10240 | 4 ( 0 % ) , 10000000 | 2021 -02-25, 7 .5833 ( 0 ) space names starting with \"SCR_\" refer to the personal ( usr ) or Workspace SCRATCH quota. ( 1 ) accounting period start date, The date from which the average usage is computed. ( 2 ) file space average quota ( not files ) , calculated by the average of messured values in the actual accounting period. In the last example the workspace Workspace1 has 5TB of free quota, and a total of 10TB of quota ( 5TB additional storage requested). The start date defines the start of the accounting period and the average quota is computed as average over all datapoints starting from start date . Furthermore, the SCRATCH quota is presented starting with SCR_ , where SCR_usr is your personal SCRATCH quota and SCR_ plus Workspace name the group quota of the Workspace group in the scratch fileset. Workspace SCRATCH quota is only presented if a quota is set and the quota -l option selected. data gathering Workspaces: Workspace quota information is gathered twice a day. Thus the presented data may not completely represent the current state. HOME and SCRATCH: values presented are actual values directly gathered from the file system Note: the coloring of the relative values is green (<70%), yellow (70% < x < 90%), red (>90%). advanced quota method The following mmlsquota command present you actual values from the file system. For $HOME : $ mmlsquota --block-size = G -u $USER rs_gpfs:svc_homefs Block Limits | File Limits Filesystem Fileset type KB quota limit in_doubt grace | files quota limit in_doubt grace Remarks rs_gpfs svc_homefs USR 444181792 1073741824 1073741824 6072144 none | 815985 1000000 1000000 2462 none The --block-size option specify the unit {K , M, G, T} in which the numbers of blocks are displayed: mmlsquota --block-size = G -j workspace1 rs_gpfs Block Limits | File Limits Filesystem type GB quota limit in_doubt grace | files quota limit in_doubt grace Remarks rs_gpfs FILESET 57 10240 11264 0 none | 5 10000000 11000000 0 none The output shows the quotas for a worspace called Workspace1 . The quotas are set to a soft limit of 10240 GB, and a hard limit of 11264 GB. 57 GB is currently allocated to the workspace. An in_doubt value greater than zero means that the quota system has not yet been updated as to whether the space that is in doubt is still available or not. If the user/workspace exceeds the soft limit, the grace period will be set to one week. If usage is not reduced to a level below the soft limit during that time, the quota system interprets the soft limit as the hard limit and no further allocation is allowed. The user(s) can reset this condition by reducing usage enough to fall below the soft limit. The maximum amount of disk space the workspace/user can accumulate during the grace period is defined by the hard limit. The same information is also displayed for the file limits (number of files). Request Higher Quota Limits clean before ask Make sure to clean up your directories before requesting additional storage space. There will be no quota increase for HOME directories. Additional storage for workspaces can be requested by the workspace owner or the deputy, see Workspace Management Each research group can use up to 10TB of free disk storage in multiple Workspaces free of charge. Quota increase can be purchased, see Workspace Management . \u21a9 Workspaces are meant to be active directories and no archive. Workspace are active by default for one year. The duration can every time be extended to \u201ccurrent date plus one year\u201d. \u21a9 Scratch quota is currently implemented per user \u21a9 \u21a9 There is a automatic removal policy planned, but not implemented yet \u21a9","title":"Quota"},{"location":"file-system/quota.html#file-system-quota","text":"","title":"File System Quota"},{"location":"file-system/quota.html#description","text":"This page contains information about quota limits on the parallel file system. Quotas are enabled to control the file system usage. Job abortion Jobs will fail if no more disk space can be allocated, or if no more files can be created because the respective quota hard limit is exceeded","title":"Description"},{"location":"file-system/quota.html#quotas","text":"space quota file quota backup expiration HOME 1TB 1M yes - WORKSPACE free: up to 10TB per research group 1 1M per TB yes 1 year 2 SCRATCH 30TB 3 10M 3 no 1 month 4","title":"Quotas"},{"location":"file-system/quota.html#display-quota-information","text":"A quota tool is delivered with the Workspace module: $ quota UniBE Workspace Quota report ============================ : used ( GB )( % ) , quota ( GB ) | files used ( % ) , quota ================================================================================== HOME : 420 ( 41 % ) , 1024 | 773425 ( 77 % ) , 1000000 Workspace1 : 101 ( 1 % ) , 10240 | 3 ( 0 % ) , 10000000 Furthermore, there is a more detailed version using the -l or --long option $ quota -l UniBE Workspace Quota report ============================ : free quota, used ( GB )( % ) , quota ( GB ) | files used ( % ) , quota | start date ( 1 ) , average quota ( 2 ) ================================================================================================================================ HOME : all, 421 ( 41 % ) , 1024 | 796058 ( 79 % ) , 1000000 | , SCR_usr : all, 269 ( 0 % ) , 30720 | 22 ( 0 % ) , 10000000 | , Workspace1 : 5 , 101 ( 1 % ) , 10240 | 4 ( 0 % ) , 10000000 | 2021 -02-25, 7 .5833 ( 0 ) space names starting with \"SCR_\" refer to the personal ( usr ) or Workspace SCRATCH quota. ( 1 ) accounting period start date, The date from which the average usage is computed. ( 2 ) file space average quota ( not files ) , calculated by the average of messured values in the actual accounting period. In the last example the workspace Workspace1 has 5TB of free quota, and a total of 10TB of quota ( 5TB additional storage requested). The start date defines the start of the accounting period and the average quota is computed as average over all datapoints starting from start date . Furthermore, the SCRATCH quota is presented starting with SCR_ , where SCR_usr is your personal SCRATCH quota and SCR_ plus Workspace name the group quota of the Workspace group in the scratch fileset. Workspace SCRATCH quota is only presented if a quota is set and the quota -l option selected. data gathering Workspaces: Workspace quota information is gathered twice a day. Thus the presented data may not completely represent the current state. HOME and SCRATCH: values presented are actual values directly gathered from the file system Note: the coloring of the relative values is green (<70%), yellow (70% < x < 90%), red (>90%).","title":"Display quota information"},{"location":"file-system/quota.html#advanced-quota-method","text":"The following mmlsquota command present you actual values from the file system. For $HOME : $ mmlsquota --block-size = G -u $USER rs_gpfs:svc_homefs Block Limits | File Limits Filesystem Fileset type KB quota limit in_doubt grace | files quota limit in_doubt grace Remarks rs_gpfs svc_homefs USR 444181792 1073741824 1073741824 6072144 none | 815985 1000000 1000000 2462 none The --block-size option specify the unit {K , M, G, T} in which the numbers of blocks are displayed: mmlsquota --block-size = G -j workspace1 rs_gpfs Block Limits | File Limits Filesystem type GB quota limit in_doubt grace | files quota limit in_doubt grace Remarks rs_gpfs FILESET 57 10240 11264 0 none | 5 10000000 11000000 0 none The output shows the quotas for a worspace called Workspace1 . The quotas are set to a soft limit of 10240 GB, and a hard limit of 11264 GB. 57 GB is currently allocated to the workspace. An in_doubt value greater than zero means that the quota system has not yet been updated as to whether the space that is in doubt is still available or not. If the user/workspace exceeds the soft limit, the grace period will be set to one week. If usage is not reduced to a level below the soft limit during that time, the quota system interprets the soft limit as the hard limit and no further allocation is allowed. The user(s) can reset this condition by reducing usage enough to fall below the soft limit. The maximum amount of disk space the workspace/user can accumulate during the grace period is defined by the hard limit. The same information is also displayed for the file limits (number of files).","title":"advanced quota method"},{"location":"file-system/quota.html#request-higher-quota-limits","text":"clean before ask Make sure to clean up your directories before requesting additional storage space. There will be no quota increase for HOME directories. Additional storage for workspaces can be requested by the workspace owner or the deputy, see Workspace Management Each research group can use up to 10TB of free disk storage in multiple Workspaces free of charge. Quota increase can be purchased, see Workspace Management . \u21a9 Workspaces are meant to be active directories and no archive. Workspace are active by default for one year. The duration can every time be extended to \u201ccurrent date plus one year\u201d. \u21a9 Scratch quota is currently implemented per user \u21a9 \u21a9 There is a automatic removal policy planned, but not implemented yet \u21a9","title":"Request Higher Quota Limits"},{"location":"file-system/scratch.html","text":"Scratch - temporary file space Description Scratch file space are meant for temporary data storage. Interim computational data should be located there. We distinguish local and network scratch spaces. Network Scratch Network scratch spaces are located on the parallel file system and accessible to all nodes. In contrast to HOME or WORKSPACEs , scratch is meant for temporary data, especially with larger quota requirements. Jobs creating a lot of temporary data, which may need or may not need to be post-processed should run in this space. As an example, a application creating a huge amount of temporary output, which need to be analysed, but only partly need to be stored for a longer term. Quota and file quota is less restrictive on scratch compared to HOME or permanent WORKSPACE directories. Every user can use up to 30TB and 10M files. There is no snapshot and no backup feature available. Furthermore, an automatic deletion policy is planned, deleting files which are older than 30 days . Scratch file space can be accessed using the Workspace module and the $SCRATCH environment variable. module load Workspace cd $SCRATCH For personal Scratch see below Workspace Scratch Each Workspace has a $SCRATCH space with the same access permissions like the permanent Workspace directory (using primary and secondary groups). The Workspace can be accessed using $SCRATCH variable (after loading the Workspace module). It will point to /storage/scratch/<researchGroupID>/<WorkspaceID> . Please use $SCRATCH to access it. Personal Scratch Users without a Workspace can also use \u201cpersonal\u201d Scratch. This space does need to be created initially: module load Workspace_Home mkdir $SCRATCH cd $SCRATCH Please note that this space is per default no private space. If you want to restrict access you can change permissions using: chmod 700 $SCRATCH Local Scratch Cases: temporary files are produced, which are not relevant after the computation files need to be read or written multiple times within a job Local storage ( $TMPDIR ) should be used instead of network storage. $TMPDIR is a node local storage which only exists during the job life time and cleaned automatically afterwards. The actual directory is /scratch/local/<jobID> , but it is highly recommended to use $TMPDIR . If necessary data can be copied there initially at the beginning of the job, processes (multiple times) and necessary results copied back at the end. $TMPDIR instead of /tmp $TMPDIR is much larger than /tmp and cleaned automatically. Especially in case of job errors data in /tmp will persist and clog the nodes memory. Example: temporary files In the following example the example.exe will need a place to store temporary/intermediate files, not necessary after the computation. The location is provided using the --builddir option. And the local scratch ( $TMPDDIR ) is specified. #!/bin/bash #SBATCH --job-name tmpdir #SBATCH --nodes 1 #SBATCH --ntasks 1 #SBATCH --cpus-per-task 1 srun example.exe --builddir = $TMPDIR input.dat If you want to have the advantage of low latency file system (local) but you need to keep files, you still can use $TMPDIR and copy files to the network storage (e.g. $WORKSPACE or $HOME ) at the end of your job. This is only efficient if a) more files are manipulated local (in $TMPDIR ) than copied to the network storage or b) files are manipulated multiple times, before copying to the network storage. Example: including data movement In the following example script, all files from the submitting directory are copied to the head compute node. At the end of the job all files from the compute node local directory is copied back. The compute node local $TMPDIR is used, which points to /scratch/local/<jobid> , a job specific directory in the nodes internal disc. #!/bin/bash #SBATCH --job-name tmpdir #SBATCH --nodes 1 #SBATCH --ntasks 1 #SBATCH --cpus-per-task 1 ###SBATCH --output lsf.out # when specifying output file name, add rm lsf.out in cleanup function # I. Define directory names [DO NOT CHANGE] # ========================================= # get name of the temporary directory working directory, physically on the compute-node workdir = \" ${ TMPDIR } \" # get submit directory # (every file/folder below this directory is copied to the compute node) submitdir = \" ${ lsf_SUBMIT_DIR } \" # 1. Transfer to node [DO NOT CHANGE] # =================================== # create/empty the temporary directory on the compute node if [ ! -d \" ${ workdir } \" ] ; then mkdir -p \" ${ workdir } \" else rm -rf \" ${ workdir } \" /* fi # change current directory to the location of the sbatch command # (\"submitdir\" is somewhere in the home directory on the head node) cd \" ${ submitdir } \" # copy all files/folders in \"submitdir\" to \"workdir\" # (\"workdir\" == temporary directory on the compute node) cp -prf * ${ workdir } # change directory to the temporary directory on the compute-node cd ${ workdir } # 3. Function to transfer back to the head node [DO NOT CHANGE] # ============================================================= # define clean-up function function clean_up { # - remove log-file on the compute-node, to prevent overwiting actual output with empty file rm lsf- ${ lsf_JOB_ID } .out # - TODO delete temporary files from the compute-node, before copying. Prevent copying unnecessary files. # rm -r ... # - change directory to the location of the sbatch command (on the head node) cd \" ${ submitdir } \" # - copy everything from the temporary directory on the compute-node cp -prf \" ${ workdir } \" /* . # - erase the temporary directory from the compute-node rm -rf \" ${ workdir } \" /* rm -rf \" ${ workdir } \" # - exit the script exit } # call \"clean_up\" function when this script exits, it is run even if lsf cancels the job trap 'clean_up' EXIT # 2. Execute [MODIFY COMPLETELY TO YOUR NEEDS] # ============================================ # TODO add your computation here # simple example, hello world srun echo \"hello world from $HOSTNAME \" Further aspects to consider: copy only necessary files have only necessary files in the submit directory remove all unnecessary files before copying the data back, e.g. remove large input files In case of a parallel job, you need to verify that all process run on one single node ( --nodes=1 ) OR copy the data to all related nodes (e.g. srun -n1 cp ... ).","title":"Scratch"},{"location":"file-system/scratch.html#description","text":"Scratch file space are meant for temporary data storage. Interim computational data should be located there. We distinguish local and network scratch spaces.","title":"Description"},{"location":"file-system/scratch.html#network-scratch","text":"Network scratch spaces are located on the parallel file system and accessible to all nodes. In contrast to HOME or WORKSPACEs , scratch is meant for temporary data, especially with larger quota requirements. Jobs creating a lot of temporary data, which may need or may not need to be post-processed should run in this space. As an example, a application creating a huge amount of temporary output, which need to be analysed, but only partly need to be stored for a longer term. Quota and file quota is less restrictive on scratch compared to HOME or permanent WORKSPACE directories. Every user can use up to 30TB and 10M files. There is no snapshot and no backup feature available. Furthermore, an automatic deletion policy is planned, deleting files which are older than 30 days . Scratch file space can be accessed using the Workspace module and the $SCRATCH environment variable. module load Workspace cd $SCRATCH For personal Scratch see below","title":"Network Scratch"},{"location":"file-system/scratch.html#workspace-scratch","text":"Each Workspace has a $SCRATCH space with the same access permissions like the permanent Workspace directory (using primary and secondary groups). The Workspace can be accessed using $SCRATCH variable (after loading the Workspace module). It will point to /storage/scratch/<researchGroupID>/<WorkspaceID> . Please use $SCRATCH to access it.","title":"Workspace Scratch"},{"location":"file-system/scratch.html#personal-scratch","text":"Users without a Workspace can also use \u201cpersonal\u201d Scratch. This space does need to be created initially: module load Workspace_Home mkdir $SCRATCH cd $SCRATCH Please note that this space is per default no private space. If you want to restrict access you can change permissions using: chmod 700 $SCRATCH","title":"Personal Scratch"},{"location":"file-system/scratch.html#local-scratch","text":"Cases: temporary files are produced, which are not relevant after the computation files need to be read or written multiple times within a job Local storage ( $TMPDIR ) should be used instead of network storage. $TMPDIR is a node local storage which only exists during the job life time and cleaned automatically afterwards. The actual directory is /scratch/local/<jobID> , but it is highly recommended to use $TMPDIR . If necessary data can be copied there initially at the beginning of the job, processes (multiple times) and necessary results copied back at the end. $TMPDIR instead of /tmp $TMPDIR is much larger than /tmp and cleaned automatically. Especially in case of job errors data in /tmp will persist and clog the nodes memory.","title":"Local Scratch"},{"location":"file-system/scratch.html#example-temporary-files","text":"In the following example the example.exe will need a place to store temporary/intermediate files, not necessary after the computation. The location is provided using the --builddir option. And the local scratch ( $TMPDDIR ) is specified. #!/bin/bash #SBATCH --job-name tmpdir #SBATCH --nodes 1 #SBATCH --ntasks 1 #SBATCH --cpus-per-task 1 srun example.exe --builddir = $TMPDIR input.dat If you want to have the advantage of low latency file system (local) but you need to keep files, you still can use $TMPDIR and copy files to the network storage (e.g. $WORKSPACE or $HOME ) at the end of your job. This is only efficient if a) more files are manipulated local (in $TMPDIR ) than copied to the network storage or b) files are manipulated multiple times, before copying to the network storage.","title":"Example: temporary files"},{"location":"file-system/scratch.html#example-including-data-movement","text":"In the following example script, all files from the submitting directory are copied to the head compute node. At the end of the job all files from the compute node local directory is copied back. The compute node local $TMPDIR is used, which points to /scratch/local/<jobid> , a job specific directory in the nodes internal disc. #!/bin/bash #SBATCH --job-name tmpdir #SBATCH --nodes 1 #SBATCH --ntasks 1 #SBATCH --cpus-per-task 1 ###SBATCH --output lsf.out # when specifying output file name, add rm lsf.out in cleanup function # I. Define directory names [DO NOT CHANGE] # ========================================= # get name of the temporary directory working directory, physically on the compute-node workdir = \" ${ TMPDIR } \" # get submit directory # (every file/folder below this directory is copied to the compute node) submitdir = \" ${ lsf_SUBMIT_DIR } \" # 1. Transfer to node [DO NOT CHANGE] # =================================== # create/empty the temporary directory on the compute node if [ ! -d \" ${ workdir } \" ] ; then mkdir -p \" ${ workdir } \" else rm -rf \" ${ workdir } \" /* fi # change current directory to the location of the sbatch command # (\"submitdir\" is somewhere in the home directory on the head node) cd \" ${ submitdir } \" # copy all files/folders in \"submitdir\" to \"workdir\" # (\"workdir\" == temporary directory on the compute node) cp -prf * ${ workdir } # change directory to the temporary directory on the compute-node cd ${ workdir } # 3. Function to transfer back to the head node [DO NOT CHANGE] # ============================================================= # define clean-up function function clean_up { # - remove log-file on the compute-node, to prevent overwiting actual output with empty file rm lsf- ${ lsf_JOB_ID } .out # - TODO delete temporary files from the compute-node, before copying. Prevent copying unnecessary files. # rm -r ... # - change directory to the location of the sbatch command (on the head node) cd \" ${ submitdir } \" # - copy everything from the temporary directory on the compute-node cp -prf \" ${ workdir } \" /* . # - erase the temporary directory from the compute-node rm -rf \" ${ workdir } \" /* rm -rf \" ${ workdir } \" # - exit the script exit } # call \"clean_up\" function when this script exits, it is run even if lsf cancels the job trap 'clean_up' EXIT # 2. Execute [MODIFY COMPLETELY TO YOUR NEEDS] # ============================================ # TODO add your computation here # simple example, hello world srun echo \"hello world from $HOSTNAME \" Further aspects to consider: copy only necessary files have only necessary files in the submit directory remove all unnecessary files before copying the data back, e.g. remove large input files In case of a parallel job, you need to verify that all process run on one single node ( --nodes=1 ) OR copy the data to all related nodes (e.g. srun -n1 cp ... ).","title":"Example: including data movement"},{"location":"general/faq.html","text":"FAQ Description This page provides a collection of frequently asked questions. File system What if my HOME is full? If you reached your quota, you will get strange warning about not being able to write temporary files etc. You can check your quota using the 1. Decluttering: Check for unnecessary data. This could be: unused application packages, e.g. Python(2) packages in $HOME/.local/lib/python*/site-packages/* temporary computational data, like already post processed output files duplicated data \u2026 Pack and archive: The HPC storage is a high performance parallel storage and not meant to be an archive. Data not used in the short to midterm should be packed and moved to an archive storage. In general, we consider data on our HPC systems as research data. Further we consider research data to be shared sooner or later. And we aim to support and enhance collaborations. Therefore, we introduce group shared spaces, called HPC Workspaces. Ask your research group manager to add you to an existing Workspace or create a new one. There will be no quota increase for HOME directories. Workspaces I need access to a HPC Workspace, whome I need to ask? HPC Workspaces are managed by the group manager/leader and if applicable a deputy. Therewith you need to ask them to add you to the primary or secondary group. See also HPC Workspace members . I need to share data with my colleges. What can I do? HPC Workspaces are meant to host shared data. See HPC Workspaces Where can I get a Workspace? A research group manager need to create the Workspace, since there are possibilities for charged extensions. If you want to join an existing Workspace. Ask the Workspace manager or its deputy to add you. See HPC Workspaces How much does a Workspace cost? Workspaces itself are free of charge. Every research group has 10TB disk space free of charge, which can be used in multiple Workspaces. If necessary, additional storage can be purchased per Workspace, where only the actual usage will be charged, see Workspace Management What if our 10TB free of charge research group quota is full? Your Research group manager or a registered deputy can apply for an additional quota. Actual used quota will be charged. Why can I not submit jobs anymore? After joining an HPC Workspace the private lsf account gets deactivated and a Workspace account need to be specified. This can be done by loading the Workspace module, see Workspace environment : module load Workspace Otherwise lsf will present the following error message: sbatch: error: AssocGrpSubmitJobsLimit sbatch: error: Batch job submission failed: Job violates accounting/QOS policy ( job submit limit, user ' s size and/or time limits ) With this method we aim to distribute our resources in a more fair manner. HPC resources including compute power should be distriuted between registered research groups. We can only relate users with research groups by utilizing Workspace information. Software issues Why is my private conda installation broken after migration Unfortunately, Anaconda hard wires absolute paths into almost all files (including scripts and binary files). A proper migration process may have included conda pack . There is a way you may access your old environments and create new ones with the same specification: export CONDA_ENVS_PATH=${HOME}/anaconda3/envs ## or where you had your old envs module load Anaconda3 eval \"$(conda shell.bash hook)\" conda info --envs conda activate oldEnvName ## choose your old environment name conda list --explicit > spec-list.txt unset CONDA_ENVS_PATH conda create --name myEnvName --file spec-list.txt # select a name Please, also note that there is a system wide Anaconda installation, so no need for your own separate one. Finally, after recreating your environments please delete all old Anaconda installations and environments. These are not only big but also a ton of files. Why the system is complaining abount not finding an existing module? There are cases modules could not be found. This could be that the modules is not exiting in the target software stack, it could be hidden, or a version inconsitency. hidden modules Some modules are provided as hidden modules to keep the presented software stack nice and clean. Hidden modules can be listed using module --show-hidden avail . software stacks On UBELIX there are multiple software stacks. There are software stacks for each architecture. There are custom software stacks in Workspaces (again architectural software stacks included) and the VitalIT software stack. The targeted software stack need to be available. The different architectural software stacks are available on the related architecture, e.g. epyc2 in a job on the epyc2 partion. The Workspace and VitalIT software stack can be loaded using module load Workspace or module load vital-it. software stack inconstency It is strongly suggested to not mix different toolchains like foss or intel. Additionally, it is advised to stay with one version of a toolchain, e.g. foss/2021a and its dependency versions, e.g. GCC/10.3.0 etc. Further, LMOD has a confusing effect when loading inconsitent module combinations, e.g. $ module load foss/2021a $ module load intel/2020b Lmod has detected the following error: The following module ( s ) are unknown: \"zlib/.1.2.11-GCCcore-10.2.0\" Please check the spelling or version number. Also try \"module spider ...\" It is also possible your cache file is out-of-date ; it may help to try: $ module --ignore-cache load \"zlib/.1.2.11-GCCcore-10.2.0\" Also make sure that all modulefiles written in TCL start with the string #%Module The mentioned module zlib/.1.2.11-GCCcore-10.2.0 is available in general. When loading foss/2021a , the zlib/.1.2.11-GCCcore-10.3.0 should get loaded, but LMOD will not swap its version, but report the mentioned error. Please take this as an indication that you accidentality mix different toolchains, and rethink your procedure, and stay within the same toolchain and toolchain version. Environment issues I am using zsh, but some commands and tools fail, what can I do? There are known caveats with LMOD (or module system) and Bash scripts in zsh environments. Bash scripts do not source any system or user files. To initialize the (module) environment properly, you need to set export BASH_ENV=/etc/bashrc in your zsh profile ( .zshrc ). I modified my bashrc, but its not doing what I expect, how can I debug that bash script? The bashrc can be debugged as all other bash scripts, using set -x at the beginning of the script. This will print all commands executed on screen, including all subcommand also included in called scripts and tools print statements, e.g. echo \"DEBUG: variable PATH=$PATH\" These should provide a good indication where the script diverge from your expectation. Job issues Why is my job still pending? The REASON column of the squeue output gives you a hint why your job is not running. (Resources) The job is waiting for resources to become available so that the jobs resource request can be fulfilled. (Priority) The job is not allowed to run because at least one higher prioritized job is waiting for resources. (Dependency) The job is waiting for another job to finish first (\u2013dependency=\u2026 option). (DependencyNeverSatisfied) The job is waiting for a dependency that can never be satisfied. Such a job will remain pending forever. Please cancel such jobs. (QOSMaxCpuPerUserLimit) The job is not allowed to start because your currently running jobs consume all allowed CPU resources for your user in a specific partition. Wait for jobs to finish. (AssocGrpCpuLimit) dito. (AssocGrpJobsLimit) The job is not allowed to start because you have reached the maximum of allowed running jobs for your user in a specific partition. Wait for jobs to finish. (ReqNodeNotAvail, UnavailableNodes:\u2026) Some node required by the job is currently not available. The node may currently be in use, reserved for another job, in an advanced reservation, DOWN , DRAINED , or not responding. Most probably there is an active reservation for all nodes due to an upcoming maintenance downtime (see output of scontrol show reservation ) and your job is not able to finish before the start of the downtime. Another reason why you should specify the duration of a job (\u2013time) as accurately as possible. Your job will start after the downtime has finished. You can list all active reservations using scontrol show reservation . Why can\u2019t I submit further jobs? sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user\u2019s size and/or time limits) \u2026 means that you have reached the maximum of allowed jobs to be submitted to a specific partition. Job in state FAILED although job completed successfully lsf captures the return value of the batch script/last command and reports this value as the completion status of the job/job step. lsf indicates status FAILED if the value captured is non-zero. The following simplified example illustrates the issue: simple.c #include <unistd.h> #include <stdio.h> int main ( int argc, char *argv []) { char hostname [ 128 ] ; gethostname ( hostname, sizeof ( hostname )) ; printf ( \"%s says: Hello World.\\n\" , hostname ) ; } job.sh #!/bin/bash # lsf options #SBATCH --mail-user=foo@bar.unibe.ch #SBATCH --mail-type=END #SBATCH --job-name=\"Simple Hello World\" #SBATCH --time=00:05:00 #SBATCH --nodes=1 # Put your code below this line ./simple bash$ sbatch job.sh Submitted batch job 104 Although the job finished successfully\u2026 lsf-104.out knlnode02.ubelix.unibe.ch says: Hello World. \u2026lsf reports job FAILED: bash$ sacct -j 104 JobID JobName Partition Account AllocCPUS State ExitCode ------------ ---------- ---------- ---------- ---------- ---------- -------- 104 Simple He+ all 1 FAILED 45 :0 104 .batch batch 1 FAILED 45 :0 Problem: The exit code of the job is the exit status of batch script (job.sh) which in turn returns the exit status of the last command executed (simple) which in turn returns the return value of the last statement (printf()). Since printf() returns the number of characters printed (45), the exit code of the batch script is non-zero and consequently lsf reports job FAILED although the job produces the desired output. Solution: Explicitly return a value: #include <unistd.h> #include <stdio.h> int main ( int argc, char *argv []) { char hostname [ 128 ] ; int n ; gethostname ( hostname, sizeof ( hostname )) ; // If successful, the total number of characters written is returned. On failure, a negative number is returned. n = printf ( \"%s says: Hello World.\\n\" , hostname ) ; if ( n < 0 ) return 1 ; return 0 ; } bash$ sacct -j 105 JobID JobName Partition Account AllocCPUS State ExitCode ------------ ---------- ---------- ---------- ---------- ---------- -------- 105 Simple He+ all 1 COMPLETED 0 :0 105 .batch batch 1 COMPLETED 0 :0","title":"FAQ"},{"location":"general/faq.html#faq","text":"","title":"FAQ"},{"location":"general/faq.html#description","text":"This page provides a collection of frequently asked questions.","title":"Description"},{"location":"general/faq.html#file-system","text":"","title":"File system"},{"location":"general/faq.html#what-if-my-home-is-full","text":"If you reached your quota, you will get strange warning about not being able to write temporary files etc. You can check your quota using the 1. Decluttering: Check for unnecessary data. This could be: unused application packages, e.g. Python(2) packages in $HOME/.local/lib/python*/site-packages/* temporary computational data, like already post processed output files duplicated data \u2026 Pack and archive: The HPC storage is a high performance parallel storage and not meant to be an archive. Data not used in the short to midterm should be packed and moved to an archive storage. In general, we consider data on our HPC systems as research data. Further we consider research data to be shared sooner or later. And we aim to support and enhance collaborations. Therefore, we introduce group shared spaces, called HPC Workspaces. Ask your research group manager to add you to an existing Workspace or create a new one. There will be no quota increase for HOME directories.","title":"What if my HOME is full?"},{"location":"general/faq.html#workspaces","text":"","title":"Workspaces"},{"location":"general/faq.html#i-need-access-to-a-hpc-workspace-whome-i-need-to-ask","text":"HPC Workspaces are managed by the group manager/leader and if applicable a deputy. Therewith you need to ask them to add you to the primary or secondary group. See also HPC Workspace members .","title":"I need access to a HPC Workspace, whome I need to ask?"},{"location":"general/faq.html#i-need-to-share-data-with-my-colleges-what-can-i-do","text":"HPC Workspaces are meant to host shared data. See HPC Workspaces","title":"I need to share data with my colleges. What can I do?"},{"location":"general/faq.html#where-can-i-get-a-workspace","text":"A research group manager need to create the Workspace, since there are possibilities for charged extensions. If you want to join an existing Workspace. Ask the Workspace manager or its deputy to add you. See HPC Workspaces","title":"Where can I get a Workspace?"},{"location":"general/faq.html#how-much-does-a-workspace-cost","text":"Workspaces itself are free of charge. Every research group has 10TB disk space free of charge, which can be used in multiple Workspaces. If necessary, additional storage can be purchased per Workspace, where only the actual usage will be charged, see Workspace Management","title":"How much does a Workspace cost?"},{"location":"general/faq.html#what-if-our-10tb-free-of-charge-research-group-quota-is-full","text":"Your Research group manager or a registered deputy can apply for an additional quota. Actual used quota will be charged.","title":"What if our 10TB free of charge research group quota is full?"},{"location":"general/faq.html#why-can-i-not-submit-jobs-anymore","text":"After joining an HPC Workspace the private lsf account gets deactivated and a Workspace account need to be specified. This can be done by loading the Workspace module, see Workspace environment : module load Workspace Otherwise lsf will present the following error message: sbatch: error: AssocGrpSubmitJobsLimit sbatch: error: Batch job submission failed: Job violates accounting/QOS policy ( job submit limit, user ' s size and/or time limits ) With this method we aim to distribute our resources in a more fair manner. HPC resources including compute power should be distriuted between registered research groups. We can only relate users with research groups by utilizing Workspace information.","title":"Why can I not submit jobs anymore?"},{"location":"general/faq.html#software-issues","text":"","title":"Software issues"},{"location":"general/faq.html#why-is-my-private-conda-installation-broken-after-migration","text":"Unfortunately, Anaconda hard wires absolute paths into almost all files (including scripts and binary files). A proper migration process may have included conda pack . There is a way you may access your old environments and create new ones with the same specification: export CONDA_ENVS_PATH=${HOME}/anaconda3/envs ## or where you had your old envs module load Anaconda3 eval \"$(conda shell.bash hook)\" conda info --envs conda activate oldEnvName ## choose your old environment name conda list --explicit > spec-list.txt unset CONDA_ENVS_PATH conda create --name myEnvName --file spec-list.txt # select a name Please, also note that there is a system wide Anaconda installation, so no need for your own separate one. Finally, after recreating your environments please delete all old Anaconda installations and environments. These are not only big but also a ton of files.","title":"Why is my private conda installation broken after migration"},{"location":"general/faq.html#why-the-system-is-complaining-abount-not-finding-an-existing-module","text":"There are cases modules could not be found. This could be that the modules is not exiting in the target software stack, it could be hidden, or a version inconsitency.","title":"Why the system is complaining abount not finding an existing module?"},{"location":"general/faq.html#hidden-modules","text":"Some modules are provided as hidden modules to keep the presented software stack nice and clean. Hidden modules can be listed using module --show-hidden avail .","title":"hidden modules"},{"location":"general/faq.html#software-stacks","text":"On UBELIX there are multiple software stacks. There are software stacks for each architecture. There are custom software stacks in Workspaces (again architectural software stacks included) and the VitalIT software stack. The targeted software stack need to be available. The different architectural software stacks are available on the related architecture, e.g. epyc2 in a job on the epyc2 partion. The Workspace and VitalIT software stack can be loaded using module load Workspace or module load vital-it.","title":"software stacks"},{"location":"general/faq.html#software-stack-inconstency","text":"It is strongly suggested to not mix different toolchains like foss or intel. Additionally, it is advised to stay with one version of a toolchain, e.g. foss/2021a and its dependency versions, e.g. GCC/10.3.0 etc. Further, LMOD has a confusing effect when loading inconsitent module combinations, e.g. $ module load foss/2021a $ module load intel/2020b Lmod has detected the following error: The following module ( s ) are unknown: \"zlib/.1.2.11-GCCcore-10.2.0\" Please check the spelling or version number. Also try \"module spider ...\" It is also possible your cache file is out-of-date ; it may help to try: $ module --ignore-cache load \"zlib/.1.2.11-GCCcore-10.2.0\" Also make sure that all modulefiles written in TCL start with the string #%Module The mentioned module zlib/.1.2.11-GCCcore-10.2.0 is available in general. When loading foss/2021a , the zlib/.1.2.11-GCCcore-10.3.0 should get loaded, but LMOD will not swap its version, but report the mentioned error. Please take this as an indication that you accidentality mix different toolchains, and rethink your procedure, and stay within the same toolchain and toolchain version.","title":"software stack inconstency"},{"location":"general/faq.html#environment-issues","text":"","title":"Environment issues"},{"location":"general/faq.html#i-am-using-zsh-but-some-commands-and-tools-fail-what-can-i-do","text":"There are known caveats with LMOD (or module system) and Bash scripts in zsh environments. Bash scripts do not source any system or user files. To initialize the (module) environment properly, you need to set export BASH_ENV=/etc/bashrc in your zsh profile ( .zshrc ).","title":"I am using zsh, but some commands and tools fail, what can I do?"},{"location":"general/faq.html#i-modified-my-bashrc-but-its-not-doing-what-i-expect-how-can-i-debug-that-bash-script","text":"The bashrc can be debugged as all other bash scripts, using set -x at the beginning of the script. This will print all commands executed on screen, including all subcommand also included in called scripts and tools print statements, e.g. echo \"DEBUG: variable PATH=$PATH\" These should provide a good indication where the script diverge from your expectation.","title":"I modified my bashrc, but its not doing what I expect, how can I debug that bash script?"},{"location":"general/faq.html#job-issues","text":"","title":"Job issues"},{"location":"general/faq.html#why-is-my-job-still-pending","text":"The REASON column of the squeue output gives you a hint why your job is not running. (Resources) The job is waiting for resources to become available so that the jobs resource request can be fulfilled. (Priority) The job is not allowed to run because at least one higher prioritized job is waiting for resources. (Dependency) The job is waiting for another job to finish first (\u2013dependency=\u2026 option). (DependencyNeverSatisfied) The job is waiting for a dependency that can never be satisfied. Such a job will remain pending forever. Please cancel such jobs. (QOSMaxCpuPerUserLimit) The job is not allowed to start because your currently running jobs consume all allowed CPU resources for your user in a specific partition. Wait for jobs to finish. (AssocGrpCpuLimit) dito. (AssocGrpJobsLimit) The job is not allowed to start because you have reached the maximum of allowed running jobs for your user in a specific partition. Wait for jobs to finish. (ReqNodeNotAvail, UnavailableNodes:\u2026) Some node required by the job is currently not available. The node may currently be in use, reserved for another job, in an advanced reservation, DOWN , DRAINED , or not responding. Most probably there is an active reservation for all nodes due to an upcoming maintenance downtime (see output of scontrol show reservation ) and your job is not able to finish before the start of the downtime. Another reason why you should specify the duration of a job (\u2013time) as accurately as possible. Your job will start after the downtime has finished. You can list all active reservations using scontrol show reservation .","title":"Why is my job still pending?"},{"location":"general/faq.html#why-cant-i-submit-further-jobs","text":"sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user\u2019s size and/or time limits) \u2026 means that you have reached the maximum of allowed jobs to be submitted to a specific partition.","title":"Why can't I submit further jobs?"},{"location":"general/faq.html#job-in-state-failed-although-job-completed-successfully","text":"lsf captures the return value of the batch script/last command and reports this value as the completion status of the job/job step. lsf indicates status FAILED if the value captured is non-zero. The following simplified example illustrates the issue: simple.c #include <unistd.h> #include <stdio.h> int main ( int argc, char *argv []) { char hostname [ 128 ] ; gethostname ( hostname, sizeof ( hostname )) ; printf ( \"%s says: Hello World.\\n\" , hostname ) ; } job.sh #!/bin/bash # lsf options #SBATCH --mail-user=foo@bar.unibe.ch #SBATCH --mail-type=END #SBATCH --job-name=\"Simple Hello World\" #SBATCH --time=00:05:00 #SBATCH --nodes=1 # Put your code below this line ./simple bash$ sbatch job.sh Submitted batch job 104 Although the job finished successfully\u2026 lsf-104.out knlnode02.ubelix.unibe.ch says: Hello World. \u2026lsf reports job FAILED: bash$ sacct -j 104 JobID JobName Partition Account AllocCPUS State ExitCode ------------ ---------- ---------- ---------- ---------- ---------- -------- 104 Simple He+ all 1 FAILED 45 :0 104 .batch batch 1 FAILED 45 :0 Problem: The exit code of the job is the exit status of batch script (job.sh) which in turn returns the exit status of the last command executed (simple) which in turn returns the return value of the last statement (printf()). Since printf() returns the number of characters printed (45), the exit code of the batch script is non-zero and consequently lsf reports job FAILED although the job produces the desired output. Solution: Explicitly return a value: #include <unistd.h> #include <stdio.h> int main ( int argc, char *argv []) { char hostname [ 128 ] ; int n ; gethostname ( hostname, sizeof ( hostname )) ; // If successful, the total number of characters written is returned. On failure, a negative number is returned. n = printf ( \"%s says: Hello World.\\n\" , hostname ) ; if ( n < 0 ) return 1 ; return 0 ; } bash$ sacct -j 105 JobID JobName Partition Account AllocCPUS State ExitCode ------------ ---------- ---------- ---------- ---------- ---------- -------- 105 Simple He+ all 1 COMPLETED 0 :0 105 .batch batch 1 COMPLETED 0 :0","title":"Job in state FAILED although job completed successfully"},{"location":"general/investment.html","text":"Investment UBELIX is financed and maintained by the IT services of the University of Bern. Interested users can invest into GPUs, CPUs and storage usage. The investors get elevated access to specific resources. Furthermore, additional resoures will be purchased with the additional budget. If you are interested, get in touch with us: open a request at the Service Portal . Under Construction This page is still under construction. Details of possible ways to invest will follow.","title":"Investment"},{"location":"general/investment.html#investment","text":"UBELIX is financed and maintained by the IT services of the University of Bern. Interested users can invest into GPUs, CPUs and storage usage. The investors get elevated access to specific resources. Furthermore, additional resoures will be purchased with the additional budget. If you are interested, get in touch with us: open a request at the Service Portal . Under Construction This page is still under construction. Details of possible ways to invest will follow.","title":"Investment"},{"location":"general/news.html","text":"News 04-05-2021: major SLUM partition restructure, see lsf partitions . Job scripts may need to be adapted. HPC Workspace officially in production HPC Workspace Overview Kernel, CUDA driver, lsf, and Spectrum Scale update in June: HOME quota fixed to 1TB, removal of GPFS institute shared directories 17-02-2021: Home migration: User HOMEs started to get migrated to the newer Spectrum Scale System storage HPC Workspaces: Beta Phase of custom group shared file spaces with tools and lsf accounting","title":"Announcements"},{"location":"general/news.html#news","text":"04-05-2021: major SLUM partition restructure, see lsf partitions . Job scripts may need to be adapted. HPC Workspace officially in production HPC Workspace Overview Kernel, CUDA driver, lsf, and Spectrum Scale update in June: HOME quota fixed to 1TB, removal of GPFS institute shared directories 17-02-2021: Home migration: User HOMEs started to get migrated to the newer Spectrum Scale System storage HPC Workspaces: Beta Phase of custom group shared file spaces with tools and lsf accounting","title":"News"},{"location":"general/support.html","text":"Support Mailing List The official channel for getting information about upcoming UBELIX events (e.g. maintenance) and other important news is our mailing list. Sign up to receive information on what\u2019s going on on the cluster: https://listserv.unibe.ch/mailman/listinfo/hpc-users UniBE HPC support In case of questions, comments or issues get in touch with us. Please first collect all necessary details. In case of issues, this should include: JobID location of job scripts location of output/error files the full error message(s) your user name detailed description of expectation and observation Please open a ticket via https://serviceportal.unibe.ch/hpc Documentation If you found issues in this documentation or want to help improving it, open an issue or pull request on out Github repository: https://github.com/hpc-unibe-ch/hpc-docs Investment The HPCs are mainly financed by the UniBE IT services. Furthermore, interested users can buy elevated access to resources. Additional resources are purchased with this additional budget. See Investment Page . Documentation update If you find issues in the documentation, want to add your publication to the Hall Of Fame or want to contribute in improving this documentation please create a pull request to UBELIX hpc-docs github repository .","title":"Support"},{"location":"general/support.html#support","text":"","title":"Support"},{"location":"general/support.html#mailing-list","text":"The official channel for getting information about upcoming UBELIX events (e.g. maintenance) and other important news is our mailing list. Sign up to receive information on what\u2019s going on on the cluster: https://listserv.unibe.ch/mailman/listinfo/hpc-users","title":"Mailing List"},{"location":"general/support.html#unibe-hpc-support","text":"In case of questions, comments or issues get in touch with us. Please first collect all necessary details. In case of issues, this should include: JobID location of job scripts location of output/error files the full error message(s) your user name detailed description of expectation and observation Please open a ticket via https://serviceportal.unibe.ch/hpc","title":"UniBE HPC support"},{"location":"general/support.html#documentation","text":"If you found issues in this documentation or want to help improving it, open an issue or pull request on out Github repository: https://github.com/hpc-unibe-ch/hpc-docs","title":"Documentation"},{"location":"general/support.html#investment","text":"The HPCs are mainly financed by the UniBE IT services. Furthermore, interested users can buy elevated access to resources. Additional resources are purchased with this additional budget. See Investment Page .","title":"Investment"},{"location":"general/support.html#documentation-update","text":"If you find issues in the documentation, want to add your publication to the Hall Of Fame or want to contribute in improving this documentation please create a pull request to UBELIX hpc-docs github repository .","title":"Documentation update"},{"location":"getting-Started/about-clusters.html","text":"LILAC The Lilac cluster is now available to the general MSKCC research community; it is is available to all faculties for their scientific work. The cluster can also be used by students within a scope of a thesis or a course. The system is running the CentOS 7 Linux operating system along with the LSF scheduler from IBM. This sits on top of a large GPFS storage cluster for high performance data access. The cluster runs about 330 compute nodes featuring almost 6\u2018300 CPU cores and about 300\u2018000 GPU cores. If your MSK account is not yet activated for Lilac, the Getting Started Guide might be a good place to get you started. Lilac features a plethora of software and applications, which is outlined on the page Software, but the users are free to compile and install their own software within their home directories. General purpose Technical Specifications JUNO CMO BIC Technical specifications PHOENIX DMP Technical Specifications IGO Genomics Core Technical Specifications","title":"About the clusters"},{"location":"getting-Started/about-clusters.html#lilac","text":"The Lilac cluster is now available to the general MSKCC research community; it is is available to all faculties for their scientific work. The cluster can also be used by students within a scope of a thesis or a course. The system is running the CentOS 7 Linux operating system along with the LSF scheduler from IBM. This sits on top of a large GPFS storage cluster for high performance data access. The cluster runs about 330 compute nodes featuring almost 6\u2018300 CPU cores and about 300\u2018000 GPU cores. If your MSK account is not yet activated for Lilac, the Getting Started Guide might be a good place to get you started. Lilac features a plethora of software and applications, which is outlined on the page Software, but the users are free to compile and install their own software within their home directories. General purpose Technical Specifications","title":"LILAC"},{"location":"getting-Started/about-clusters.html#juno","text":"CMO BIC Technical specifications","title":"JUNO"},{"location":"getting-Started/about-clusters.html#phoenix","text":"DMP Technical Specifications","title":"PHOENIX"},{"location":"getting-Started/about-clusters.html#igo","text":"Genomics Core Technical Specifications","title":"IGO"},{"location":"getting-Started/account.html","text":"Account and Activation Description UBELIX is available to everybody with a valid Campus Account (CA) of the University of Bern. The cluster is meant to be used for research related to the University of Bern. Before you can use this service your CA need to be activated for UBELIX . Please respect the Code of Conduct On this page you will find useful information regarding the activation of your CA and the login procedure. Furthermore, the provided service structure is outlined. Account activation Request for activation To request the activation of your Campus Account, please send a request via https://serviceportal.unibe.ch/hpc including: a brief description of what you want to use the cluster for your Campus Account username Students must additionally provide: the name of the institute (e.g. Mathematical Institute) if available, the name of the research group (e.g. Numerical Analysis) If you possess multiple Campus Accounts (staff and student) use your staff account since this one is more specific. As soon as we get your email we will activate your account for UBELIX. Once activated, you will receive a confirmation email containing initial instructions You cannot choose a new username for UBELIX. The username/password combination will be the same as for your Campus Account that you also use to access other services provided by the University of Bern (e.g: email, Ilias). Apply for a Campus Account for external coworkers If you do not have a Campus Account of the University of Bern, but you need access to the cluster for your cooperative scientific research with an UniBE institute, the account manager of the institute has to request a Campus Account from the IT department of the University of Bern. Please ask your coworker at the institute to arrange this for you. The responsible account manager at your institute can be found from the following link: Account managers Mailing List The official channel for informing the UBELIX community about upcoming events (e.g. maintenance) and other important news is our mailing list. Sign up to receive information on what\u2019s going on on the cluster: https://listserv.unibe.ch/mailman/listinfo/hpc-users","title":"Account Creation and Activation"},{"location":"getting-Started/account.html#account-and-activation","text":"","title":"Account and Activation"},{"location":"getting-Started/account.html#description","text":"UBELIX is available to everybody with a valid Campus Account (CA) of the University of Bern. The cluster is meant to be used for research related to the University of Bern. Before you can use this service your CA need to be activated for UBELIX . Please respect the Code of Conduct On this page you will find useful information regarding the activation of your CA and the login procedure. Furthermore, the provided service structure is outlined.","title":"Description"},{"location":"getting-Started/account.html#account-activation","text":"Request for activation To request the activation of your Campus Account, please send a request via https://serviceportal.unibe.ch/hpc including: a brief description of what you want to use the cluster for your Campus Account username Students must additionally provide: the name of the institute (e.g. Mathematical Institute) if available, the name of the research group (e.g. Numerical Analysis) If you possess multiple Campus Accounts (staff and student) use your staff account since this one is more specific. As soon as we get your email we will activate your account for UBELIX. Once activated, you will receive a confirmation email containing initial instructions You cannot choose a new username for UBELIX. The username/password combination will be the same as for your Campus Account that you also use to access other services provided by the University of Bern (e.g: email, Ilias).","title":"Account activation"},{"location":"getting-Started/account.html#apply-for-a-campus-account-for-external-coworkers","text":"If you do not have a Campus Account of the University of Bern, but you need access to the cluster for your cooperative scientific research with an UniBE institute, the account manager of the institute has to request a Campus Account from the IT department of the University of Bern. Please ask your coworker at the institute to arrange this for you. The responsible account manager at your institute can be found from the following link: Account managers","title":"Apply for a Campus Account for external coworkers"},{"location":"getting-Started/account.html#mailing-list","text":"The official channel for informing the UBELIX community about upcoming events (e.g. maintenance) and other important news is our mailing list. Sign up to receive information on what\u2019s going on on the cluster: https://listserv.unibe.ch/mailman/listinfo/hpc-users","title":"Mailing List"},{"location":"getting-Started/bring-data.html","text":"Brining Data Into the Cluster - Information This page provides infohhrmation on various methods of bringing data into the cluster","title":"Bringing Data Into the Cluster"},{"location":"getting-Started/bring-data.html#brining-data-into-the-cluster-information","text":"This page provides infohhrmation on various methods of bringing data into the cluster","title":"Brining Data Into the Cluster - Information"},{"location":"getting-Started/command-line.html","text":"How to access clusters via command line Credentials Connection Host keys, warnings on first login Authentication Login","title":"Via Command Line"},{"location":"getting-Started/command-line.html#how-to-access-clusters-via-command-line","text":"","title":"How to access clusters via command line"},{"location":"getting-Started/command-line.html#credentials","text":"","title":"Credentials"},{"location":"getting-Started/command-line.html#connection","text":"","title":"Connection"},{"location":"getting-Started/command-line.html#host-keys-warnings-on-first-login","text":"","title":"Host keys, warnings on first login"},{"location":"getting-Started/command-line.html#authentication","text":"","title":"Authentication"},{"location":"getting-Started/command-line.html#login","text":"","title":"Login"},{"location":"getting-Started/glossary.html","text":"HPC Glossary: Important Terms to Know Units of Measurement 1TB (Terabyte) = 1,000GB (Gigabyte) 1GB (Gigabyte) = 1,000MB (Megabyte) Terms Cluster An HPC cluster is a high-performance, parallel computing infrastructure which consists of three key components: compute, network, and storage. On a cluster one can take advantage of multiple cores by running several instances of a program at once or using a parallelized version of the program. Batch Processing definition New term definition Core An alternative term for a central processing unit (CPU), especially used when several are present in a single processor chip. MPI An abbreviation of Message Passing Interface, a way of running the same job across multiple nodes (or maybe the same node). An MPI job will spawn multiple tasks that exchange control signals and data by \u201cmessages\u201d, hence the name. Task A single running instance of a computer program. Each task consists of at least one thread. Thread A sequence of instructions that can be managed independently by the operating system. Threads are grouped into tasks. Ideally, each thread should have its own core to run on. Environment def Node A single computing device within a cluster. A node is the equivalent of a personal computer or laptop. Every node in a NeSI cluster has many cores. Compute node: def SSH def Workspace def Workflow def Container def Singularity def Host def","title":"Glossary"},{"location":"getting-Started/glossary.html#glossary","text":"","title":"HPC Glossary: Important Terms to Know"},{"location":"getting-Started/glossary.html#units-of-measurement","text":"1TB (Terabyte) = 1,000GB (Gigabyte) 1GB (Gigabyte) = 1,000MB (Megabyte)","title":"Units of Measurement"},{"location":"getting-Started/glossary.html#terms","text":"Cluster An HPC cluster is a high-performance, parallel computing infrastructure which consists of three key components: compute, network, and storage. On a cluster one can take advantage of multiple cores by running several instances of a program at once or using a parallelized version of the program. Batch Processing definition New term definition Core An alternative term for a central processing unit (CPU), especially used when several are present in a single processor chip. MPI An abbreviation of Message Passing Interface, a way of running the same job across multiple nodes (or maybe the same node). An MPI job will spawn multiple tasks that exchange control signals and data by \u201cmessages\u201d, hence the name. Task A single running instance of a computer program. Each task consists of at least one thread. Thread A sequence of instructions that can be managed independently by the operating system. Threads are grouped into tasks. Ideally, each thread should have its own core to run on. Environment def Node A single computing device within a cluster. A node is the equivalent of a personal computer or laptop. Every node in a NeSI cluster has many cores. Compute node: def SSH def Workspace def Workflow def Container def Singularity def Host def","title":"Terms"},{"location":"getting-Started/lilac-overview.html","text":"UBELIX - Overview Description This page provides a high-level system overview of a HPC cluster such as UBELIX. It describes the different hardware components that constitute the cluster and gives a quantitative list of the different generations of compute nodes in UBELIX. Lilac is an HPC cluster that currently consists of about ___ compute nodes featuring almost CPU cores and GPUs and a High-level system overview Login node aka. Submit node A user connects to the cluster by logging into the submit host via SSH. You can use this host for medium-performance tasks, e.g. to edit files or to compile smaller programs. Resource-demanding/high-performance tasks must be submitted to the batch queuing system as jobs, and will finally run on one or multiple compute nodes. Even long running compile tasks should be submitted as a job on a compute node instead of running it on the submit host. lsf Batch-Queueing System On HPC clusters we use the open-source batch-queueing system lsf , managing all jobs on the compute nodes. The job submission is described in detail in the Job handling section, starting with Submitting jobs . The procedue look like: resource definition : resources required for your job need to be defined, including numbers of CPU cores , time limit, memory , partitions, QOS, etc.. These resources can be defined in the batch script or as command line arguments. Not explicitly specified parameters are chosen with default values . submitting : job can be submitted using sbatch (using a batch script), srun (directly running the executable), or salloc (interactive submission). The submission is checked from lsf if it is within the specification and limits. scheduling : lsf is finding the optimal spots for the registered jobs on the resources and time. This also includes priority handling and optimizing for best coverage. launch : lsf prepares the environment on the selected compute resources. This also includes setting up the MPI environment, if requested interactive sessions, etc., and launching your batch script. serial/parallel tasks : per default all the tasks defined in your batch script are run on the first core of your allocation. Compute tasks should be started with \u2018srun\u2019. Parallel task are launched on all (or as defined) job related resources. cancelling/completing : When tasks finished, wall time limit or memory limit is reached the job ant its environment gets removed from the resources. All output is written into file(s) (except of interactive sessions) Cluster Partitions (Queues) and their Compute Nodes UBELIX is a heterogeneous machine, consisting of different architectures. There are CPU compute nodes with: and GPU nodes with: Without explicit changes, jobs are scheduled by default in the AMD Epyc2 partition, running up to 3 days. Partitions group nodes into logical sets, which share the same limits. Furthermore, specific limits and privileges are Different partitions and QOS are listed in the lsf Partition/QOS article. Storage Infrastructure A modular, software-defined storage system (IBM Spectrum Scale) provides a shared, parallel file system that is mounted on all frontend servers and compute nodes. For more information see storage infrastructure and File System Quota .","title":"MSKCC HPC system \"LILAC\""},{"location":"getting-Started/lilac-overview.html#ubelix-overview","text":"","title":"UBELIX - Overview"},{"location":"getting-Started/lilac-overview.html#description","text":"This page provides a high-level system overview of a HPC cluster such as UBELIX. It describes the different hardware components that constitute the cluster and gives a quantitative list of the different generations of compute nodes in UBELIX. Lilac is an HPC cluster that currently consists of about ___ compute nodes featuring almost CPU cores and GPUs and a","title":"Description"},{"location":"getting-Started/lilac-overview.html#high-level-system-overview","text":"","title":"High-level system overview"},{"location":"getting-Started/lilac-overview.html#login-node-aka-submit-node","text":"A user connects to the cluster by logging into the submit host via SSH. You can use this host for medium-performance tasks, e.g. to edit files or to compile smaller programs. Resource-demanding/high-performance tasks must be submitted to the batch queuing system as jobs, and will finally run on one or multiple compute nodes. Even long running compile tasks should be submitted as a job on a compute node instead of running it on the submit host.","title":"Login node aka. Submit node"},{"location":"getting-Started/lilac-overview.html#lsf-batch-queueing-system","text":"On HPC clusters we use the open-source batch-queueing system lsf , managing all jobs on the compute nodes. The job submission is described in detail in the Job handling section, starting with Submitting jobs . The procedue look like: resource definition : resources required for your job need to be defined, including numbers of CPU cores , time limit, memory , partitions, QOS, etc.. These resources can be defined in the batch script or as command line arguments. Not explicitly specified parameters are chosen with default values . submitting : job can be submitted using sbatch (using a batch script), srun (directly running the executable), or salloc (interactive submission). The submission is checked from lsf if it is within the specification and limits. scheduling : lsf is finding the optimal spots for the registered jobs on the resources and time. This also includes priority handling and optimizing for best coverage. launch : lsf prepares the environment on the selected compute resources. This also includes setting up the MPI environment, if requested interactive sessions, etc., and launching your batch script. serial/parallel tasks : per default all the tasks defined in your batch script are run on the first core of your allocation. Compute tasks should be started with \u2018srun\u2019. Parallel task are launched on all (or as defined) job related resources. cancelling/completing : When tasks finished, wall time limit or memory limit is reached the job ant its environment gets removed from the resources. All output is written into file(s) (except of interactive sessions)","title":"lsf Batch-Queueing System"},{"location":"getting-Started/lilac-overview.html#cluster-partitions-queues-and-their-compute-nodes","text":"UBELIX is a heterogeneous machine, consisting of different architectures. There are CPU compute nodes with: and GPU nodes with: Without explicit changes, jobs are scheduled by default in the AMD Epyc2 partition, running up to 3 days. Partitions group nodes into logical sets, which share the same limits. Furthermore, specific limits and privileges are Different partitions and QOS are listed in the lsf Partition/QOS article.","title":"Cluster Partitions (Queues) and their Compute Nodes"},{"location":"getting-Started/lilac-overview.html#storage-infrastructure","text":"A modular, software-defined storage system (IBM Spectrum Scale) provides a shared, parallel file system that is mounted on all frontend servers and compute nodes. For more information see storage infrastructure and File System Quota .","title":"Storage Infrastructure"},{"location":"getting-Started/login-ssh.html","text":"Login Description UBELIX is available to everybody with a valid Campus Account (CA) of the University of Bern. The cluster is meant to be used for research related to the University of Bern. Before you can use this service we have to activate your CA for UBELIX , see Accounts and Activation . This page contains information on how to configure your SSH environment for a simplified login procedure and information regarding the application of a CA for external researchers. Log in to UBELIX Before proceeding make sure that: you have your Campus Account activated for UBELIX (see above) you have a working SSH client Linux/Mac: e.g ssh command in a terminal Microsoft Windows: MobaXterm , Windows Subsytem Linux, or Putty. Alternatively, a flavor of Linux can be installed on Microsoft Windows using virtualization software (e.g VirtualBox). We strongly encourage you to familiarize with a Unix-based Terminal commands. Requirement Login to UBELIX is only possible from within the UniBE network. If you want to connect from outside, you must first establish a VPN connection. For VPN profiles and instructions see the official tutorial . Mac/Linux/Unix Run the following commands in a terminal. Open an SSH connection to the submit host: $ ssh <username>@submit.unibe.ch OR $ ssh -l <username> submit.unibe.ch At the password prompt enter your Campus Account password: $ ssh <username>@submit.unibe.ch Password: Usually there is no indication of typing when entering your password (not even asterisks or bullets). That\u2019s intended. Just enter your password and press \u2018enter\u2019. After log in successfully you will see the welcome message and the command prompt: Last login: Tue Apr 21 16 :17:26 2020 CentOS 7 .7.1908.x86_64 FQDN: submit01.ubelix.unibe.ch ( 10 .1.129.21 ) Processor: 24x Intel ( R ) Xeon ( R ) CPU E5-2630 v2 @ 2 .60GHz Kernel: 3 .10.0-1062.9.1.el7.x86_64 Memory: 62 .73 GiB Customize your SSH session Useful feartures like SSH alias, X and port forwarding are described on our page SSH customization . MobaXterm at Microsoft Windows Here we present the configuration and first steps using MobaXterm. This tool combines Terminal sessions with file transfer (scp/ftp) and X Window Server. There are many more features which are not described here. For a productive work environment you should get familiar with the tools, configuration and features. MobaXterm can be downloaded on the MobaXterm Website . There are two versions, portable and installation, you can choose one. After installing and starting MobaXterm, a SSH session need to be configured: Click \u2018Session\u2019 in the top left corner: In \u201cSSH\u201d tab: Set the remote host to submit.unibe.ch Enable the \u201cSpecify username\u201d option and put your Campus Account short name in the corresponding box (here user ms20e149 will be used) In the \u201cAdvanced SSH settings\u201d Set SSH-browser type to \u2018SCP (enhanced speed)\u2019 Optionally, tick the \u2018Follow SSH path\u2019 button From now one the settings are stored and you can access the session on the left at the star icon MobaXterm will ask you to store the Password and manage a MasterPassword. After starting the session, you should see the UBELIX login message and prompt. Here we have a colored prompt, see Shell Prompt . On the left hand side a File browser is located. There the UBELIX file system can be browsed and files up or downloaded, e.g. using drag and drop or the context menue.","title":"Login"},{"location":"getting-Started/login-ssh.html#login","text":"","title":"Login"},{"location":"getting-Started/login-ssh.html#description","text":"UBELIX is available to everybody with a valid Campus Account (CA) of the University of Bern. The cluster is meant to be used for research related to the University of Bern. Before you can use this service we have to activate your CA for UBELIX , see Accounts and Activation . This page contains information on how to configure your SSH environment for a simplified login procedure and information regarding the application of a CA for external researchers.","title":"Description"},{"location":"getting-Started/login-ssh.html#log-in-to-ubelix","text":"Before proceeding make sure that: you have your Campus Account activated for UBELIX (see above) you have a working SSH client Linux/Mac: e.g ssh command in a terminal Microsoft Windows: MobaXterm , Windows Subsytem Linux, or Putty. Alternatively, a flavor of Linux can be installed on Microsoft Windows using virtualization software (e.g VirtualBox). We strongly encourage you to familiarize with a Unix-based Terminal commands. Requirement Login to UBELIX is only possible from within the UniBE network. If you want to connect from outside, you must first establish a VPN connection. For VPN profiles and instructions see the official tutorial .","title":"Log in to UBELIX"},{"location":"getting-Started/login-ssh.html#maclinuxunix","text":"Run the following commands in a terminal. Open an SSH connection to the submit host: $ ssh <username>@submit.unibe.ch OR $ ssh -l <username> submit.unibe.ch At the password prompt enter your Campus Account password: $ ssh <username>@submit.unibe.ch Password: Usually there is no indication of typing when entering your password (not even asterisks or bullets). That\u2019s intended. Just enter your password and press \u2018enter\u2019. After log in successfully you will see the welcome message and the command prompt: Last login: Tue Apr 21 16 :17:26 2020 CentOS 7 .7.1908.x86_64 FQDN: submit01.ubelix.unibe.ch ( 10 .1.129.21 ) Processor: 24x Intel ( R ) Xeon ( R ) CPU E5-2630 v2 @ 2 .60GHz Kernel: 3 .10.0-1062.9.1.el7.x86_64 Memory: 62 .73 GiB Customize your SSH session Useful feartures like SSH alias, X and port forwarding are described on our page SSH customization .","title":"Mac/Linux/Unix"},{"location":"getting-Started/login-ssh.html#mobaxterm-at-microsoft-windows","text":"Here we present the configuration and first steps using MobaXterm. This tool combines Terminal sessions with file transfer (scp/ftp) and X Window Server. There are many more features which are not described here. For a productive work environment you should get familiar with the tools, configuration and features. MobaXterm can be downloaded on the MobaXterm Website . There are two versions, portable and installation, you can choose one. After installing and starting MobaXterm, a SSH session need to be configured: Click \u2018Session\u2019 in the top left corner: In \u201cSSH\u201d tab: Set the remote host to submit.unibe.ch Enable the \u201cSpecify username\u201d option and put your Campus Account short name in the corresponding box (here user ms20e149 will be used) In the \u201cAdvanced SSH settings\u201d Set SSH-browser type to \u2018SCP (enhanced speed)\u2019 Optionally, tick the \u2018Follow SSH path\u2019 button From now one the settings are stored and you can access the session on the left at the star icon MobaXterm will ask you to store the Password and manage a MasterPassword. After starting the session, you should see the UBELIX login message and prompt. Here we have a colored prompt, see Shell Prompt . On the left hand side a File browser is located. There the UBELIX file system can be browsed and files up or downloaded, e.g. using drag and drop or the context menue.","title":"MobaXterm at Microsoft Windows"},{"location":"getting-Started/parallelization.html","text":"Parallelization Description With an increasing demand of more accuracy and therewith a reduced time to solution, application speed need to be increased. On the one hand, the CPU frequency is limited and will not significantly increase in future. On the other hand, the available computing resources increase continuously. More and more compute cores are available in all sorts of devices. Starting with your local laptops and cell phones up to extremely powerful supercomputers. These increasing amount of resources can be utilized to perform tasks in parallel, where possible and therewith reduce the overall simulation time. There are 3 main concepts in parallelization: shared memory: thread parallel, mostly OpenMP distributed memory: Task parallel; requiring communication (MPI) Offloading: Utilizing a so called accelerator, e.g. a General Purpose Graphic Processing Unit (GPGPU), using CUDA, OpenACC, OpenMP target directive Here we briefly describe and compare these three concepts and then shortly discussing extended memory requirements. This is not meant to be complete, nor a programming guide. Preface First, it should be mentioned that just requesting more compute resource does not necessary improve the performance of the application. On the one hand, the application need to be programmed to being able to utilize the resources, using specific programming models and programming languages. On the other hand, even if the application supports parallelization, the one or the other way, the efficiency is limited by the application algorithm and the problem size, leading to a specific scaling behavior. Without any specific implementation an application will be executed on one CPU core, even if more cores are accessible. This is called serial execution. The different parallelization models are described below. If an application supports parallel execution for desired features should be mentioned in the application description. Furthermore, the command ldd <exe> can list all linked libraries. Therewith, parallelization libraries should be listed. An application could support multiple parallelization models. If possible, often a hybrid (task and thread parallelism) is most efficient, e.g. 5 tasks with 4 threads each. The ration depends on the algorithm and problem size. Vectorization A serial application on a single CPU core can be improved in performance using vectorization. Instead of computing a single value at a time, vectorization allows to operate a single instruction on multiple data (SIMD). The size of the simultaneously computed set of data is determined by the instruction set (SSE, AVX, AVX2), which defined by the CPU architecture. Furthermore, the application need to be compiled for these instruction sets. The compiler tries to optimize for the targeted architecture. Different compilers (GCC, Intel, \u2026) optimize application differently. There is no better or worse compiler. It typically depends on the implemented algorithm and the way it is programmed and the compiler. Some compilers can provide compiler feedback, which may hint to suggestions where applications are vectorized, where not, and sometimes reasons for not vectorizing a loop. Most important is that the compiler detects the target architecture instruction set. Advisable is to compiling on the target architecture and/or specifying the target instruction set, e.g. gcc -mavx2 ... . Basic Hardware Architectural Considerations Supercomputers and Clusters are typically build of compute nodes (neglecting service and login nodes), a high speed network, and high bandwidth storage. The compute nodes are different types of compute nodes, with 2 CPUs, or a CPU and an accelerator (GPU). All nodes have CPU(s), Random-access Memory (RAM) and network card, additionally there may be accelerators, like GPUs, and a hard disk (HDD). Considering a CPU compute node (without GPUs), there are typically 2 CPUs, e.g. Intel Broadwell or AMD Epyc2. Each CPU consists of many compute cores an different stages of low level memory (L1, L2, L3 cache). The CPU cores are the units performing the actual computation. The different CPU cores can work on the same or on different applications, orchestrated by the scheduler. Shared memory / OpenMP Shared memory parallelization also know as Threading utilizes cores on one single node where each core can access the same RAM (Random-access memory). The most common implementation are OpenMP pragmas. C example: #pragma omp parallel for for ( int i = 0 ; i < len ( a ); i ++ ) //do stuff In many applications a (list of) operations need to be performed on a more or less large amount of data, e.g. running a loop over elements of an array, and computing various values. If enabled during compile time, the different iterations in the above example can run on different CPU cores. The amount of utilized cores is specified during runtime by lsf (using --cpus-per-task option) and noted to the application using $OMP_NUM_THREADS (or in worse case hard-coded by the programmer). There can be multiple parallel regions the application. Compiling and Running OpenMP pragmas are comments in the code. The compiler only react on it, when using a specific compile option, e.g. gcc -fopenmp ... . Thus, the same code could be build with or without threading support. When launching the application the threads are spawned on n CPU cores, when resources are requested with --cpus-per-task= n . For all threads (of one task) one instance is launched. lsf reserves the specified number of CPU cores for this instance. These CPU cores share memory and When instructed in the application, threads are spawned and merged later. There can be also multiple parallel section during one run. In ideal case, one thread runs on one CPU core 1 . The actual amount of created threads depend on the implementation in the application. Some applications by default create as many threads as CPU cores are on the node. Since typical jobs are using only a subset of CPU cores, this leads to an over-subscription, drastic loss in performance and probably influences the whole node performance including other users jobs. Therewith the amount of threads should be limited to the requested resources. Therefore, the commonly used environment variable $OMP_NUM_THREADS 2 exists. Alternatively, $lsf_CPUS_PER_TASK can be used. Developers may use them directly in the source code, or users specify the amount of threads with command line options, configuration/input files, or similar. Please verify that you specify the target amount of threads properly in your application Threading in libraries In certain libraries algorithms already are implemented using threading, for example in BLAS and ScaLAPACK. If the usage of such libraries dominate the overall runtime it can be efficient to inquire multiple threads/cores even if the original application does not use threading. Efficiency The dominating factor for efficiency is determined by the ration time in parallel regions and time in serial regions. The more time is spend in serial regions the less efficient is the parallelization. Distributed memory / MPI Regarding a cluster system, each node is an independent computer, tied together with a network system. The individual nodes have their own system daemons controlling processes and their own memory. And by default, a CPU core from one node has no access to the memory of a different node. Sharing work across multiple nodes require communication over the network. These messages are handled by the Message Passing Interface ( MPI ), and defined by the application programmer. The application process looks like: srun <exe> will start the executable on all N tasks (CPU cores) at the beginning all N instances perform the operation each instance has MPI rank specified by lsf the application react to the rank ID and change code path As am example, a worker/manager algorithm may first distribute tasks to the workers and later collect the results: The advantage is that the different tasks can be performed on different nodes. In contrast to threading, where the job is limit to the size of a node, MPI parallel jobs are \u201conly\u201d limited by the size of the cluster or lsf resource limitations. Compiling and Running Applications using MPI need to be compiled with an MPI compiler, e.g. mpicc. There are also libraries for Python mpi4py, which under the hood will utilize one of the lower level libraries like OpenMPI or Intel MPI. Therefore, one of these modules need to be loaded when installing and running mpi4py. In general, the MPI module need to be loaded during runtime, which is used for building the application. When submitting the job, N MPI tasks are requested using the --ntasks N option. Efficiency The N task presumably will perform different tasks in parallel. At certain stages there need to be communication between the tasks. This could be simple results, but also configurational stati. In most cases the communication overhead increases significantly with increasing job sizes. Furthermore, the communication is faster the closer the tasks are together. The fastest communication is typically within one node. The wider the job is distributed over the machine, the larger the latency. Last but not least, in extreme cases the job can be willingly spread over a larger amount of nodes to increase the available memory. If 20 tasks on one Broadwell node needs to share 256GB, these 20 tasks on 4 nodes can utilize up to 1TB of memory. GPGPU General Purpose computation on Graphic Processing Units (GPGPU) utilize GPUs for parallel computations. There can be multiple GPUs next to the CPU, each having thousands of compute cores. In contrast to CPU cores, these cores need to perform exactly the same instructions, the frequency is lower and the data need to be copied first to the GPU and later back. Therewith, only computations of very large data sets are efficient. Again the application need to programmed and build to utilize these resources. There are multiple languages offloading tasks to GPUs: CUDA, OpenACC, OpenMP target directives, OpenCL,\u2026 Compiling and Running The application again need to be build specifically for GPU. For CUDA, the nvcc compiler need to be used. Furthermore, there are compiler optimization flags for different GPU architectures. When submitting a job to a GPU node, the partition and the GPU architecture need be specified, see GPU jobs Scaling The main goal of parallelization is the reduction in the overall runtime. There more resources are utilized. In an ideal case , a linear scaling can be considered, where the whole algorithm can be parallelized and the parallelization overhead is zero. Therewith utilizing the double amount of CPU cores would half the runtime. But even linear scaling is limited. At a certain point always the overhead dominates and the advantage of more resources does not lead to performance improvements anymore. The sweet spot between more resources and shorter runtime need to be tested with an representable use case, utilizing the target algorithm, in best few minutes short (e.g. limited iterations), and a representable data set. Then by increasing the problem sizes and the job size the scaling could be estimated. The different parallelization methods can be combined, if supported. For example an application can use OpenMP threads and MPI tasks at the same time. UBELIX has hyperthreading disabled. On other systems with different hardware settings hyperthreading may be enabled. Then 2 or more threads per core (depending on the hardware) are supported by the hardware. Even then hyperthreading is only be efficient for specific algorithms. \u21a9 $OMP_NUM_THREADS is set automatically by lsf to the selected cpus per task ( $lsf_CPUS_PER_TASK ). \u21a9","title":"Parallelization"},{"location":"getting-Started/parallelization.html#parallelization","text":"","title":"Parallelization"},{"location":"getting-Started/parallelization.html#description","text":"With an increasing demand of more accuracy and therewith a reduced time to solution, application speed need to be increased. On the one hand, the CPU frequency is limited and will not significantly increase in future. On the other hand, the available computing resources increase continuously. More and more compute cores are available in all sorts of devices. Starting with your local laptops and cell phones up to extremely powerful supercomputers. These increasing amount of resources can be utilized to perform tasks in parallel, where possible and therewith reduce the overall simulation time. There are 3 main concepts in parallelization: shared memory: thread parallel, mostly OpenMP distributed memory: Task parallel; requiring communication (MPI) Offloading: Utilizing a so called accelerator, e.g. a General Purpose Graphic Processing Unit (GPGPU), using CUDA, OpenACC, OpenMP target directive Here we briefly describe and compare these three concepts and then shortly discussing extended memory requirements. This is not meant to be complete, nor a programming guide.","title":"Description"},{"location":"getting-Started/parallelization.html#preface","text":"First, it should be mentioned that just requesting more compute resource does not necessary improve the performance of the application. On the one hand, the application need to be programmed to being able to utilize the resources, using specific programming models and programming languages. On the other hand, even if the application supports parallelization, the one or the other way, the efficiency is limited by the application algorithm and the problem size, leading to a specific scaling behavior. Without any specific implementation an application will be executed on one CPU core, even if more cores are accessible. This is called serial execution. The different parallelization models are described below. If an application supports parallel execution for desired features should be mentioned in the application description. Furthermore, the command ldd <exe> can list all linked libraries. Therewith, parallelization libraries should be listed. An application could support multiple parallelization models. If possible, often a hybrid (task and thread parallelism) is most efficient, e.g. 5 tasks with 4 threads each. The ration depends on the algorithm and problem size.","title":"Preface"},{"location":"getting-Started/parallelization.html#vectorization","text":"A serial application on a single CPU core can be improved in performance using vectorization. Instead of computing a single value at a time, vectorization allows to operate a single instruction on multiple data (SIMD). The size of the simultaneously computed set of data is determined by the instruction set (SSE, AVX, AVX2), which defined by the CPU architecture. Furthermore, the application need to be compiled for these instruction sets. The compiler tries to optimize for the targeted architecture. Different compilers (GCC, Intel, \u2026) optimize application differently. There is no better or worse compiler. It typically depends on the implemented algorithm and the way it is programmed and the compiler. Some compilers can provide compiler feedback, which may hint to suggestions where applications are vectorized, where not, and sometimes reasons for not vectorizing a loop. Most important is that the compiler detects the target architecture instruction set. Advisable is to compiling on the target architecture and/or specifying the target instruction set, e.g. gcc -mavx2 ... .","title":"Vectorization"},{"location":"getting-Started/parallelization.html#basic-hardware-architectural-considerations","text":"Supercomputers and Clusters are typically build of compute nodes (neglecting service and login nodes), a high speed network, and high bandwidth storage. The compute nodes are different types of compute nodes, with 2 CPUs, or a CPU and an accelerator (GPU). All nodes have CPU(s), Random-access Memory (RAM) and network card, additionally there may be accelerators, like GPUs, and a hard disk (HDD). Considering a CPU compute node (without GPUs), there are typically 2 CPUs, e.g. Intel Broadwell or AMD Epyc2. Each CPU consists of many compute cores an different stages of low level memory (L1, L2, L3 cache). The CPU cores are the units performing the actual computation. The different CPU cores can work on the same or on different applications, orchestrated by the scheduler.","title":"Basic Hardware Architectural Considerations"},{"location":"getting-Started/parallelization.html#shared-memory-openmp","text":"Shared memory parallelization also know as Threading utilizes cores on one single node where each core can access the same RAM (Random-access memory). The most common implementation are OpenMP pragmas. C example: #pragma omp parallel for for ( int i = 0 ; i < len ( a ); i ++ ) //do stuff In many applications a (list of) operations need to be performed on a more or less large amount of data, e.g. running a loop over elements of an array, and computing various values. If enabled during compile time, the different iterations in the above example can run on different CPU cores. The amount of utilized cores is specified during runtime by lsf (using --cpus-per-task option) and noted to the application using $OMP_NUM_THREADS (or in worse case hard-coded by the programmer). There can be multiple parallel regions the application.","title":"Shared memory / OpenMP"},{"location":"getting-Started/parallelization.html#compiling-and-running","text":"OpenMP pragmas are comments in the code. The compiler only react on it, when using a specific compile option, e.g. gcc -fopenmp ... . Thus, the same code could be build with or without threading support. When launching the application the threads are spawned on n CPU cores, when resources are requested with --cpus-per-task= n . For all threads (of one task) one instance is launched. lsf reserves the specified number of CPU cores for this instance. These CPU cores share memory and When instructed in the application, threads are spawned and merged later. There can be also multiple parallel section during one run. In ideal case, one thread runs on one CPU core 1 . The actual amount of created threads depend on the implementation in the application. Some applications by default create as many threads as CPU cores are on the node. Since typical jobs are using only a subset of CPU cores, this leads to an over-subscription, drastic loss in performance and probably influences the whole node performance including other users jobs. Therewith the amount of threads should be limited to the requested resources. Therefore, the commonly used environment variable $OMP_NUM_THREADS 2 exists. Alternatively, $lsf_CPUS_PER_TASK can be used. Developers may use them directly in the source code, or users specify the amount of threads with command line options, configuration/input files, or similar. Please verify that you specify the target amount of threads properly in your application","title":"Compiling and Running"},{"location":"getting-Started/parallelization.html#threading-in-libraries","text":"In certain libraries algorithms already are implemented using threading, for example in BLAS and ScaLAPACK. If the usage of such libraries dominate the overall runtime it can be efficient to inquire multiple threads/cores even if the original application does not use threading.","title":"Threading in libraries"},{"location":"getting-Started/parallelization.html#efficiency","text":"The dominating factor for efficiency is determined by the ration time in parallel regions and time in serial regions. The more time is spend in serial regions the less efficient is the parallelization.","title":"Efficiency"},{"location":"getting-Started/parallelization.html#distributed-memory-mpi","text":"Regarding a cluster system, each node is an independent computer, tied together with a network system. The individual nodes have their own system daemons controlling processes and their own memory. And by default, a CPU core from one node has no access to the memory of a different node. Sharing work across multiple nodes require communication over the network. These messages are handled by the Message Passing Interface ( MPI ), and defined by the application programmer. The application process looks like: srun <exe> will start the executable on all N tasks (CPU cores) at the beginning all N instances perform the operation each instance has MPI rank specified by lsf the application react to the rank ID and change code path As am example, a worker/manager algorithm may first distribute tasks to the workers and later collect the results: The advantage is that the different tasks can be performed on different nodes. In contrast to threading, where the job is limit to the size of a node, MPI parallel jobs are \u201conly\u201d limited by the size of the cluster or lsf resource limitations.","title":"Distributed memory / MPI"},{"location":"getting-Started/parallelization.html#compiling-and-running_1","text":"Applications using MPI need to be compiled with an MPI compiler, e.g. mpicc. There are also libraries for Python mpi4py, which under the hood will utilize one of the lower level libraries like OpenMPI or Intel MPI. Therefore, one of these modules need to be loaded when installing and running mpi4py. In general, the MPI module need to be loaded during runtime, which is used for building the application. When submitting the job, N MPI tasks are requested using the --ntasks N option.","title":"Compiling and Running"},{"location":"getting-Started/parallelization.html#efficiency_1","text":"The N task presumably will perform different tasks in parallel. At certain stages there need to be communication between the tasks. This could be simple results, but also configurational stati. In most cases the communication overhead increases significantly with increasing job sizes. Furthermore, the communication is faster the closer the tasks are together. The fastest communication is typically within one node. The wider the job is distributed over the machine, the larger the latency. Last but not least, in extreme cases the job can be willingly spread over a larger amount of nodes to increase the available memory. If 20 tasks on one Broadwell node needs to share 256GB, these 20 tasks on 4 nodes can utilize up to 1TB of memory.","title":"Efficiency"},{"location":"getting-Started/parallelization.html#gpgpu","text":"General Purpose computation on Graphic Processing Units (GPGPU) utilize GPUs for parallel computations. There can be multiple GPUs next to the CPU, each having thousands of compute cores. In contrast to CPU cores, these cores need to perform exactly the same instructions, the frequency is lower and the data need to be copied first to the GPU and later back. Therewith, only computations of very large data sets are efficient. Again the application need to programmed and build to utilize these resources. There are multiple languages offloading tasks to GPUs: CUDA, OpenACC, OpenMP target directives, OpenCL,\u2026","title":"GPGPU"},{"location":"getting-Started/parallelization.html#compiling-and-running_2","text":"The application again need to be build specifically for GPU. For CUDA, the nvcc compiler need to be used. Furthermore, there are compiler optimization flags for different GPU architectures. When submitting a job to a GPU node, the partition and the GPU architecture need be specified, see GPU jobs","title":"Compiling and Running"},{"location":"getting-Started/parallelization.html#scaling","text":"The main goal of parallelization is the reduction in the overall runtime. There more resources are utilized. In an ideal case , a linear scaling can be considered, where the whole algorithm can be parallelized and the parallelization overhead is zero. Therewith utilizing the double amount of CPU cores would half the runtime. But even linear scaling is limited. At a certain point always the overhead dominates and the advantage of more resources does not lead to performance improvements anymore. The sweet spot between more resources and shorter runtime need to be tested with an representable use case, utilizing the target algorithm, in best few minutes short (e.g. limited iterations), and a representable data set. Then by increasing the problem sizes and the job size the scaling could be estimated. The different parallelization methods can be combined, if supported. For example an application can use OpenMP threads and MPI tasks at the same time. UBELIX has hyperthreading disabled. On other systems with different hardware settings hyperthreading may be enabled. Then 2 or more threads per core (depending on the hardware) are supported by the hardware. Even then hyperthreading is only be efficient for specific algorithms. \u21a9 $OMP_NUM_THREADS is set automatically by lsf to the selected cpus per task ( $lsf_CPUS_PER_TASK ). \u21a9","title":"Scaling"},{"location":"getting-Started/shell.html","text":"Shell settings Description This article mentions provide suggestions to setup your Shell environment in a more effective way. Shell Prompt The default Linux prompt is not really highlighted and not informative. -bash-4.2$ my_command --options A colored and more descriptive prompt helps you separating different commands and their outputs and may guide you better thru the different directories and nodes. E.g.: submit01 ~/projectA $ my_command \u2013options The prompt is defined in the environment variable $PS1 and preferably been set in $HOME/.bash_profile . The following lines are a first hint and can be customized: # for providing the name of the git branch in the prompt parse_git_branch () { git branch 2 > /dev/null | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/ (\\1)/' } # creating a colorful prompt Reset = \" $( tput sgr0 ) \" Black = \" $( tput setaf 0 ) \" DarkGrey = \" $( tput bold ; tput setaf 0 ) \" LightGrey = \" $( tput setaf 7 ) \" White = \" $( tput bold ; tput setaf 7 ) \" Red = \" $( tput setaf 1 ) \" LightRed = \" $( tput bold ; tput setaf 1 ) \" Green = \" $( tput setaf 2 ) \" LightGreen = \" $( tput bold ; tput setaf 2 ) \" Brown = \" $( tput setaf 3 ) \" Yellow = \" $( tput bold ; tput setaf 3 ) \" Blue = \" $( tput setaf 4 ) \" LightBlue = \" $( tput bold ; tput setaf 4 ) \" Purple = \" $( tput setaf 5 ) \" Pink = \" $( tput bold ; tput setaf 5 ) \" Cyan = \" $( tput setaf 6 ) \" LightCyan = \" $( tput bold ; tput setaf 6 ) \" export PS1 = \"\\[ $Green \\]\\h\\[ $Reset \\] \\[ $Blue \\]\\w $( parse_git_branch ) \\[ $Reset \\]\\[ $Red \\]\\$\\[ $Reset \\] \" # correct issues with tab completion of variables (\\ added in front of them, preventing tab completion) shopt -s direxpand Beside the colors the shown information can be customized. These could be fixed text or from the following variables: \\d The date, in \"Weekday Month Date\" format ( e.g., \"Tue May 26\" ) . \\h The hostname, up to the first . ( e.g. deckard ) \\H The hostname. ( e.g. deckard.SS64.com ) \\j The number of tasks currently managed by the shell. \\l The basename of the shell ' s terminal device name. \\s The name of the shell, the basename of $0 ( the portion following the final slash ) . \\t The time, in 24 -hour HH:MM:SS format. \\T The time, in 12 -hour HH:MM:SS format. \\@ The time, in 12 -hour am/pm format. \\u The username of the current user. \\v The version of Bash ( e.g., 2 .00 ) \\V The release of Bash, version + patchlevel ( e.g., 2 .00.0 ) \\w The current working directory. \\W The basename of $PWD . \\! The history number of this command. \\# The command number of this command. \\$ If you are not root, inserts a \" $ \" ; if you are root, you get a \"#\" ( root uid = 0 ) \\n nn The character whose ASCII code is the octal value nnn. \\n A newline. \\r A carriage return . \\e An escape character ( typically a color code ) . \\a A bell character. \\\\ A backslash.","title":"Shell customization"},{"location":"getting-Started/shell.html#shell-settings","text":"","title":"Shell settings"},{"location":"getting-Started/shell.html#description","text":"This article mentions provide suggestions to setup your Shell environment in a more effective way.","title":"Description"},{"location":"getting-Started/shell.html#shell-prompt","text":"The default Linux prompt is not really highlighted and not informative. -bash-4.2$ my_command --options A colored and more descriptive prompt helps you separating different commands and their outputs and may guide you better thru the different directories and nodes. E.g.: submit01 ~/projectA $ my_command \u2013options The prompt is defined in the environment variable $PS1 and preferably been set in $HOME/.bash_profile . The following lines are a first hint and can be customized: # for providing the name of the git branch in the prompt parse_git_branch () { git branch 2 > /dev/null | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/ (\\1)/' } # creating a colorful prompt Reset = \" $( tput sgr0 ) \" Black = \" $( tput setaf 0 ) \" DarkGrey = \" $( tput bold ; tput setaf 0 ) \" LightGrey = \" $( tput setaf 7 ) \" White = \" $( tput bold ; tput setaf 7 ) \" Red = \" $( tput setaf 1 ) \" LightRed = \" $( tput bold ; tput setaf 1 ) \" Green = \" $( tput setaf 2 ) \" LightGreen = \" $( tput bold ; tput setaf 2 ) \" Brown = \" $( tput setaf 3 ) \" Yellow = \" $( tput bold ; tput setaf 3 ) \" Blue = \" $( tput setaf 4 ) \" LightBlue = \" $( tput bold ; tput setaf 4 ) \" Purple = \" $( tput setaf 5 ) \" Pink = \" $( tput bold ; tput setaf 5 ) \" Cyan = \" $( tput setaf 6 ) \" LightCyan = \" $( tput bold ; tput setaf 6 ) \" export PS1 = \"\\[ $Green \\]\\h\\[ $Reset \\] \\[ $Blue \\]\\w $( parse_git_branch ) \\[ $Reset \\]\\[ $Red \\]\\$\\[ $Reset \\] \" # correct issues with tab completion of variables (\\ added in front of them, preventing tab completion) shopt -s direxpand Beside the colors the shown information can be customized. These could be fixed text or from the following variables: \\d The date, in \"Weekday Month Date\" format ( e.g., \"Tue May 26\" ) . \\h The hostname, up to the first . ( e.g. deckard ) \\H The hostname. ( e.g. deckard.SS64.com ) \\j The number of tasks currently managed by the shell. \\l The basename of the shell ' s terminal device name. \\s The name of the shell, the basename of $0 ( the portion following the final slash ) . \\t The time, in 24 -hour HH:MM:SS format. \\T The time, in 12 -hour HH:MM:SS format. \\@ The time, in 12 -hour am/pm format. \\u The username of the current user. \\v The version of Bash ( e.g., 2 .00 ) \\V The release of Bash, version + patchlevel ( e.g., 2 .00.0 ) \\w The current working directory. \\W The basename of $PWD . \\! The history number of this command. \\# The command number of this command. \\$ If you are not root, inserts a \" $ \" ; if you are root, you get a \"#\" ( root uid = 0 ) \\n nn The character whose ASCII code is the octal value nnn. \\n A newline. \\r A carriage return . \\e An escape character ( typically a color code ) . \\a A bell character. \\\\ A backslash.","title":"Shell Prompt"},{"location":"getting-Started/ssh-customization.html","text":"Customize your SSH environment Description This page is listing useful tricks and features with SSH connections. Create a SSH alias Mac/Linux/Unix To simplify the login procedure you can define an alias for the user-/hostname combination. Add a host declaration to ~/.ssh/config on your local desktop/laptop (substitute your own alias and username): ~/.ssh/config Host <alias> Hostname submit.unibe.ch User <username> From now on you can log in to the cluster by using the specified alias: $ ssh <alias> You still have to provide your password! SSH session timeout Mac/Linux/Unix If a SSH connection goes idle for a specific amount of time (default 10 minutes), you may be confronted with a \u201cWrite failed: Broken pipe\u201d error message or the connection is simply frozen, and you are forced to log in again. To prevent this from happening, configure the client to periodically (e.g. every 60 seconds) send a message to trigger a response from the remote server. To do so, add the following line to the SSH configuration file: ServerAliveInterval 60 The host declaration may now look like this: ~/.ssh/config Host <alias> Hostname submit.unibe.ch User <username> ServerAliveInterval 60 SSH key pairs Mac/Linux/Unix SSH keys serve as a means of identifying a user to a SSH server. When using SSH keys your password will never be send over the network. Here SSH keys are created on your local desktop/laptop which are later used to authenticate during a SSH login into UBELIX. Therefore, the following steps are required: Creation of key pair consisting of a private and a public key Adding a public key to your UBELIX account Adding the key to the SSH config Creation of key pair Remember to always keep your private keys private! Share only public keys, never share your private key. If you already have a valid private/public key pair that you also want to use for UBELIX, you can omit the rest of this section and continue with \u201cAdding a public key to your UBELIX account\u201d. First, generate a private/public key pair. You can substitute your own comment (-C). To accept the default name/location simply press Enter, otherwise specify a different name/location: $ ssh-keygen -t rsa -b 4096 -C \"ubelix\" Generating public/private rsa key pair. Enter file in which to save the key ( /Users/<user>/.ssh/id_rsa ) : Enter and confirm a secure passphrase: If you do not specify a passphrase and someone else gets a copy of your private key, then he will be able to login with your identity on any account that uses the corresponding public key! Enter passphrase ( empty for no passphrase ) : Enter same passphrase again: Adding a public key to your UBELIX account Now, the public key need to be added to the ~/.ssh/authorized_keys file in your UBELIX account. This step can be done by simply issuing: ssh-copy-id -i ~/.ssh/id_rsa_ubelix.pub ` <alias> ` Adding the key to the SSH config Add the key to your host declaration in your local ssh configuration: ~/.ssh/config Host <alias> Hostname submit.unibe.ch User <username> ServerAliveInterval 60 IdentityFile ~/.ssh/id_rsa_ubelix If everything was correct, you will now be able to login without providing you Campus Account password upon your next login attempt. However, if you have secured your key with a passphrase, you will get prompted for your passphrase instead. You can use ssh-agent to securely save your passphrase, so you do not have to re-enter it all the time. Adding your Key to SSH-Agent The behavior of ssh-agent depends on the flavor and version of your operating system. On OS X Leopard or later your keys can be saved in the system\u2019s keychain. Most Linux installations will automatically start ssh-agent when you log in. Add the key to ssh-agent: $ ssh-add ~/.ssh/id_rsa_ubelix X11 - forwarding For applications with graphical interfaces X11-forwarding is sometimes necessary. You can enable X11-forwarding by using -Y option during your login process: ssh -Y <alias> The success can be tested e.g. by calling xterm on the login node, which should open a new window. Keep in mind your local operating system need to have a X server running. E.g. Xming on Windows or XQuartz for Mac. Passwordless SSH within the HPCs Some application require passwordless SSH within the HPC machine, e.g. for establishing reverse port forwarding. Please verify that you created and registered a SSH key within UBLEIX. If you can perform the following command without entering your password your are ready to go: ssh localhost otherwise create and register a new key on a login node. ssh-keygen -t rsa -b 4096 cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys chmod 640 .ssh/authorized_keys Port forwarding Some application like JupyterLab require port forwarding, where a port on the remote machine gets connected with a port on the local machine. The ssh command need to be called with additional arguments: ssh -Y -L 15051 :localhost:15051 submit.unibe.ch Here port 15051 is selected for both sides. Ports are numbers between 2000 and 65000, which needs to be unique on the present machine. The default port for JupyterLab is 8888, but only one user can use this port on the machine at a time. To avoid the need for modifying your workflow again and again, we suggest to (once) select a unique number (between 2000 and 65000), which hopfully and most likely will not be used by another user.","title":"SSH customization"},{"location":"getting-Started/ssh-customization.html#customize-your-ssh-environment","text":"","title":"Customize your SSH environment"},{"location":"getting-Started/ssh-customization.html#description","text":"This page is listing useful tricks and features with SSH connections.","title":"Description"},{"location":"getting-Started/ssh-customization.html#create-a-ssh-alias","text":"Mac/Linux/Unix To simplify the login procedure you can define an alias for the user-/hostname combination. Add a host declaration to ~/.ssh/config on your local desktop/laptop (substitute your own alias and username): ~/.ssh/config Host <alias> Hostname submit.unibe.ch User <username> From now on you can log in to the cluster by using the specified alias: $ ssh <alias> You still have to provide your password!","title":"Create a SSH alias"},{"location":"getting-Started/ssh-customization.html#ssh-session-timeout","text":"Mac/Linux/Unix If a SSH connection goes idle for a specific amount of time (default 10 minutes), you may be confronted with a \u201cWrite failed: Broken pipe\u201d error message or the connection is simply frozen, and you are forced to log in again. To prevent this from happening, configure the client to periodically (e.g. every 60 seconds) send a message to trigger a response from the remote server. To do so, add the following line to the SSH configuration file: ServerAliveInterval 60 The host declaration may now look like this: ~/.ssh/config Host <alias> Hostname submit.unibe.ch User <username> ServerAliveInterval 60","title":"SSH session timeout"},{"location":"getting-Started/ssh-customization.html#ssh-key-pairs","text":"Mac/Linux/Unix SSH keys serve as a means of identifying a user to a SSH server. When using SSH keys your password will never be send over the network. Here SSH keys are created on your local desktop/laptop which are later used to authenticate during a SSH login into UBELIX. Therefore, the following steps are required: Creation of key pair consisting of a private and a public key Adding a public key to your UBELIX account Adding the key to the SSH config","title":"SSH key pairs"},{"location":"getting-Started/ssh-customization.html#creation-of-key-pair","text":"Remember to always keep your private keys private! Share only public keys, never share your private key. If you already have a valid private/public key pair that you also want to use for UBELIX, you can omit the rest of this section and continue with \u201cAdding a public key to your UBELIX account\u201d. First, generate a private/public key pair. You can substitute your own comment (-C). To accept the default name/location simply press Enter, otherwise specify a different name/location: $ ssh-keygen -t rsa -b 4096 -C \"ubelix\" Generating public/private rsa key pair. Enter file in which to save the key ( /Users/<user>/.ssh/id_rsa ) : Enter and confirm a secure passphrase: If you do not specify a passphrase and someone else gets a copy of your private key, then he will be able to login with your identity on any account that uses the corresponding public key! Enter passphrase ( empty for no passphrase ) : Enter same passphrase again:","title":"Creation of key pair"},{"location":"getting-Started/ssh-customization.html#adding-a-public-key-to-your-ubelix-account","text":"Now, the public key need to be added to the ~/.ssh/authorized_keys file in your UBELIX account. This step can be done by simply issuing: ssh-copy-id -i ~/.ssh/id_rsa_ubelix.pub ` <alias> `","title":"Adding a public key to your UBELIX account"},{"location":"getting-Started/ssh-customization.html#adding-the-key-to-the-ssh-config","text":"Add the key to your host declaration in your local ssh configuration: ~/.ssh/config Host <alias> Hostname submit.unibe.ch User <username> ServerAliveInterval 60 IdentityFile ~/.ssh/id_rsa_ubelix If everything was correct, you will now be able to login without providing you Campus Account password upon your next login attempt. However, if you have secured your key with a passphrase, you will get prompted for your passphrase instead. You can use ssh-agent to securely save your passphrase, so you do not have to re-enter it all the time.","title":"Adding the key to the SSH config"},{"location":"getting-Started/ssh-customization.html#adding-your-key-to-ssh-agent","text":"The behavior of ssh-agent depends on the flavor and version of your operating system. On OS X Leopard or later your keys can be saved in the system\u2019s keychain. Most Linux installations will automatically start ssh-agent when you log in. Add the key to ssh-agent: $ ssh-add ~/.ssh/id_rsa_ubelix","title":"Adding your Key to SSH-Agent"},{"location":"getting-Started/ssh-customization.html#x11-forwarding","text":"For applications with graphical interfaces X11-forwarding is sometimes necessary. You can enable X11-forwarding by using -Y option during your login process: ssh -Y <alias> The success can be tested e.g. by calling xterm on the login node, which should open a new window. Keep in mind your local operating system need to have a X server running. E.g. Xming on Windows or XQuartz for Mac.","title":"X11 - forwarding"},{"location":"getting-Started/ssh-customization.html#passwordless-ssh-within-the-hpcs","text":"Some application require passwordless SSH within the HPC machine, e.g. for establishing reverse port forwarding. Please verify that you created and registered a SSH key within UBLEIX. If you can perform the following command without entering your password your are ready to go: ssh localhost otherwise create and register a new key on a login node. ssh-keygen -t rsa -b 4096 cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys chmod 640 .ssh/authorized_keys","title":"Passwordless SSH within the HPCs"},{"location":"getting-Started/ssh-customization.html#port-forwarding","text":"Some application like JupyterLab require port forwarding, where a port on the remote machine gets connected with a port on the local machine. The ssh command need to be called with additional arguments: ssh -Y -L 15051 :localhost:15051 submit.unibe.ch Here port 15051 is selected for both sides. Ports are numbers between 2000 and 65000, which needs to be unique on the present machine. The default port for JupyterLab is 8888, but only one user can use this port on the machine at a time. To avoid the need for modifying your workflow again and again, we suggest to (once) select a unique number (between 2000 and 65000), which hopfully and most likely will not be used by another user.","title":"Port forwarding"},{"location":"getting-Started/unix-linux.html","text":"Unix and Linux Resources","title":"Unix/Linux Resources"},{"location":"getting-Started/unix-linux.html#unix-and-linux-resources","text":"","title":"Unix and Linux Resources"},{"location":"getting-Started/web-browser.html","text":"How to access clusters via web browser On demand Info and Resources, access","title":"Via Web Browser"},{"location":"getting-Started/web-browser.html#how-to-access-clusters-via-web-browser","text":"","title":"How to access clusters via web browser"},{"location":"getting-Started/web-browser.html#on-demand-info-and-resources-access","text":"","title":"On demand Info and Resources, access"},{"location":"getting-Started/workspaces.html","text":"HPC Workspaces Description The HPC Workspaces provide a group shared environment, including storage with user-defined access, lsf accounting, and tools. An HPC Workspace belong to a research group and need to be requested by the research group leader, see Workspace management . Short Summary Workspaces provide a collaborative environment with user defined access groups: a primary group with read/write access and a secondary group with read only access Each Workspace provide: permanent storage ( /storage/workspaces/<researchGroupID>/<workspaceID> ) temporary storage ( /storage/scratch/<researchGroupID>/<workspaceID> ) user-friendly access to a custom software repositories and monitoring tools and lsf accounting to that Workspace. Fair share between research groups. Usage Please always load the Workspace module when using it, even if you only copy files into it. The module provides you with shortcuts (e.g. $WORKSPACE ), the custom Software stack (if existing) and lsf settings. Application Workspaces need to be created by registered research group lead/managers, see Workspace Application More Details For more details see: Workspace Introduction , Workspace Software Environment , and Workspace Monitoring","title":"Intro to Workspaces"},{"location":"getting-Started/workspaces.html#hpc-workspaces","text":"","title":"HPC Workspaces"},{"location":"getting-Started/workspaces.html#description","text":"The HPC Workspaces provide a group shared environment, including storage with user-defined access, lsf accounting, and tools. An HPC Workspace belong to a research group and need to be requested by the research group leader, see Workspace management .","title":"Description"},{"location":"getting-Started/workspaces.html#short-summary","text":"Workspaces provide a collaborative environment with user defined access groups: a primary group with read/write access and a secondary group with read only access Each Workspace provide: permanent storage ( /storage/workspaces/<researchGroupID>/<workspaceID> ) temporary storage ( /storage/scratch/<researchGroupID>/<workspaceID> ) user-friendly access to a custom software repositories and monitoring tools and lsf accounting to that Workspace. Fair share between research groups.","title":"Short Summary"},{"location":"getting-Started/workspaces.html#usage","text":"Please always load the Workspace module when using it, even if you only copy files into it. The module provides you with shortcuts (e.g. $WORKSPACE ), the custom Software stack (if existing) and lsf settings.","title":"Usage"},{"location":"getting-Started/workspaces.html#application","text":"Workspaces need to be created by registered research group lead/managers, see Workspace Application","title":"Application"},{"location":"getting-Started/workspaces.html#more-details","text":"For more details see: Workspace Introduction , Workspace Software Environment , and Workspace Monitoring","title":"More Details"},{"location":"hpc-workspaces/environment.html","text":"HPC Workspace Data and Software Tools Description HPC Workspace modules provides support for user-friendly file system access, custom software stacks in HPC Workspaces, and lsf accounting. The module can also be used to set up HOME for a custom software stack. Furthermore, there are modules provided to load a working Workspace and additionally a software stacks from another Workspace, see Additional software stacks Workspace module The Workspace module adjust the environment to work in a specific HPC Workspace. module load Workspace sets the following environment variables ( Shortcuts ) and Software stacks There are the following possibilities: you belong to no Workspace: load module load Workspace_Home to use your software stack in your HOME directory and set $WORKSPACE and $SCRATCH variables to your private directories. you belong to one Workspace: this Workspace gets loaded when module load Workspace you belong to multiple Workspaces: you need to specify the Workspace to load using the variable $HPC_WORKSPACE . If not specified, the module presents the possible options, e.g.: $ module load Workspace Workspaces are available: HPC_SW_test, hpc_training, Please select and load ONE of the following: HPC_WORKSPACE=HPC_SW_test module load Workspace HPC_WORKSPACE=hpc_training module load Workspace Thus you load a specific Workspace using: HPC_WORKSPACE=<WorkspaceName> module load Workspace There are also ways to load an additional Workspace for an additional software stack, see Additional Software Stacks below. Shortcuts The workspace module provides the following variables: Variable Function $WORKSPACE full path to the Workspace. Thus, you can access the workspace using: cd $WORKSPACE $SCRATCH full path to the Workspace SCRATCH directory. Thus you can access it using: cd $SCRATCH lsf Account by loading the Workspace module by default the Workspace account is selected. Thus all jobs submitted without a specified --account will be submitted to this Workspace account. Additional Settings the module provides the following settings for a more user-friendly usage of applications. You may not need to use them directly, but tools like lsf, Singularity, Python, and R will use them. Variable Function $SBATCH_ACCOUNT $lsf_ACCOUNT $SALLOC_ACCOUNT sets the lsf account to the Workspace account. Thus all submitted jobs with that module are accounted to the Workspace account automatically. No need to set it in the sbatch script $SINGULARITY_BINDPATH using singularity, the Workspace directory will be bind into the container without manual specification. The WORKSPACE variable as well as the SCRATCH variable will also be ported into the container. Thus, you can specify locations with $WORKSPACE or $SCRATCH within the container. $PYTHONPATH if Python or Anaconda is loaded beforehand, it is set to: $WORKSPACE/PyPackages/lib/pythonXXX/site-packages where XXX is the Python major and minor version. And also add the bin directory to $PATH . $PYTHONPACKAGEPATH if Python or Anaconda is loaded beforehand, it is set to: $WORKSPACE/PyPackages . This can be used for e.g. pip install --prefix $PYTHONPACKAGEPATH $CONDA_ENVS_PATH therewith conda environments can be created and shared within the Workspace $R_LIBS therewith additional R packages can be installed and searched in the shared Workspace. The directory need to be created first. See R page Software stacks Beside, a set of software packages we provide for our different CPU architecture, the Workspace module provides tools to install custom software stacks within your Workspace. Especially with EasyBuild shortcuts are provided to install and use custom software stacks easily build for all architectures. For installing packages with EasyBuild, see EasyBuild description . Manual package can also be installed in the similar manner. Adding a Modulefile provides the users to load packages as used to. Please see Installing Custom Software . As a result all users of the Workspace can use the software packages by loading the Workspace module and the software product module. Python packages The Workspace module provides support to install and use Python packages in a shared manner, by installing them into the Workspace. Please see Python Additional Packages First load Python/Anaconda3 Python or Anaconda3 module need to be loaded before loading the Workspace module, since variables to be set depend on Python version. Workspace module can also be reloaded, e.g.: HPC_WORKSPACE=HPC_SW_test module load Workspace module load Python module load Workspace Conda environments The Workspace module provides support for creating and using conda environments in the shared Workspace. See Anaconda Conda environments . R packages The Workspace module provides support for installing and using additional R packages in the shared Workspace. Thus a package once installed by one user can be used by all Workspace members. See R installing packages . UMASK The Workspace module sets the umask to 002. Thus files and directories get group-writeable, e.g.: -rw-rw-r-- 1 user group 0 Mar 15 15 :15 /path/to/file Additional Software Stacks The module Workspace_SW_only provide the access to a software stack of an HPC Workspace B while working in an HPC Workspace A . This could be that a common software stack is provided for multiple (data) Workspaces or that you are trying software packages in your HOME As an example you could load: HPC_WORKSPACE = A module load Workspace HPC_WORKSPACE = B module load Workspace_SW_only When you want to load packages from your HOME while working in A , you can HPC_WORKSPACE = $HOME module load Workspace_SW_only HPC_WORKSPACE = A module load Workspace Note that the variable HPC_WORKSPACE is cleared after each loading of a Workspace* module. The currently loaded Workspace names are stored in $HPC_WORKSPACE_LOADED for the Workspace module and $HPC_WORKSPACE_SW_ONLY for the Workspace_SW_only module. Reloading The Workspace modules are configured to \u201cremember\u201d the selected Workspace you once loaded in the current session, even after unload the Workspace module. Therefore, environment variables are set in the current session, $HPC_WORKSPACE for the Workspace module, and $HPC_WORKSPACE_SW_ONLY for the Workspace_SW_only module. If you belong to multiple Workspaces and you want to list the available Workspaces you need to unset HPC_WORKSPACE before loading the Workspace module. If you already know the name, you can switch into another Workspace (here Workspace foo ) by: module unload Workspace HPC_WORKSPACE = foo module load Workspace When you are creating a new module, there are cases where you need to reload a Workspace module, e.g. for a Python packages. This can be obtained using e.g. the following lua modulefile syntax: if mode () == 'load' then if not ( isloaded ( \"Python\" ) ) then load ( \"Python\" ) if ( isloaded ( \"Workspace\" ) ) then load ( \"Workspace\" ) end if ( isloaded ( \"Workspace_SW_only\" ) ) then load ( \"Workspace_SW_only\" ) end if ( isloaded ( \"Workspace_HOME\" ) ) then load ( \"Workspace_HOME\" ) end end end Assuming we want to create a module for an additional Python package. In this example we not only verify that Python is loaded, but also that the Workspace Python settings (incl. PYTHONPATH and PYTHONPACKAGEPATH ) are set properly by reloading the Workspace module.","title":"Software environment"},{"location":"hpc-workspaces/environment.html#hpc-workspace-data-and-software-tools","text":"","title":"HPC Workspace Data and Software Tools"},{"location":"hpc-workspaces/environment.html#description","text":"HPC Workspace modules provides support for user-friendly file system access, custom software stacks in HPC Workspaces, and lsf accounting. The module can also be used to set up HOME for a custom software stack. Furthermore, there are modules provided to load a working Workspace and additionally a software stacks from another Workspace, see Additional software stacks","title":"Description"},{"location":"hpc-workspaces/environment.html#workspace-module","text":"The Workspace module adjust the environment to work in a specific HPC Workspace. module load Workspace sets the following environment variables ( Shortcuts ) and Software stacks There are the following possibilities: you belong to no Workspace: load module load Workspace_Home to use your software stack in your HOME directory and set $WORKSPACE and $SCRATCH variables to your private directories. you belong to one Workspace: this Workspace gets loaded when module load Workspace you belong to multiple Workspaces: you need to specify the Workspace to load using the variable $HPC_WORKSPACE . If not specified, the module presents the possible options, e.g.: $ module load Workspace Workspaces are available: HPC_SW_test, hpc_training, Please select and load ONE of the following: HPC_WORKSPACE=HPC_SW_test module load Workspace HPC_WORKSPACE=hpc_training module load Workspace Thus you load a specific Workspace using: HPC_WORKSPACE=<WorkspaceName> module load Workspace There are also ways to load an additional Workspace for an additional software stack, see Additional Software Stacks below.","title":"Workspace module"},{"location":"hpc-workspaces/environment.html#shortcuts","text":"The workspace module provides the following variables: Variable Function $WORKSPACE full path to the Workspace. Thus, you can access the workspace using: cd $WORKSPACE $SCRATCH full path to the Workspace SCRATCH directory. Thus you can access it using: cd $SCRATCH","title":"Shortcuts"},{"location":"hpc-workspaces/environment.html#lsf-account","text":"by loading the Workspace module by default the Workspace account is selected. Thus all jobs submitted without a specified --account will be submitted to this Workspace account.","title":"lsf Account"},{"location":"hpc-workspaces/environment.html#additional-settings","text":"the module provides the following settings for a more user-friendly usage of applications. You may not need to use them directly, but tools like lsf, Singularity, Python, and R will use them. Variable Function $SBATCH_ACCOUNT $lsf_ACCOUNT $SALLOC_ACCOUNT sets the lsf account to the Workspace account. Thus all submitted jobs with that module are accounted to the Workspace account automatically. No need to set it in the sbatch script $SINGULARITY_BINDPATH using singularity, the Workspace directory will be bind into the container without manual specification. The WORKSPACE variable as well as the SCRATCH variable will also be ported into the container. Thus, you can specify locations with $WORKSPACE or $SCRATCH within the container. $PYTHONPATH if Python or Anaconda is loaded beforehand, it is set to: $WORKSPACE/PyPackages/lib/pythonXXX/site-packages where XXX is the Python major and minor version. And also add the bin directory to $PATH . $PYTHONPACKAGEPATH if Python or Anaconda is loaded beforehand, it is set to: $WORKSPACE/PyPackages . This can be used for e.g. pip install --prefix $PYTHONPACKAGEPATH $CONDA_ENVS_PATH therewith conda environments can be created and shared within the Workspace $R_LIBS therewith additional R packages can be installed and searched in the shared Workspace. The directory need to be created first. See R page","title":"Additional Settings"},{"location":"hpc-workspaces/environment.html#software-stacks","text":"Beside, a set of software packages we provide for our different CPU architecture, the Workspace module provides tools to install custom software stacks within your Workspace. Especially with EasyBuild shortcuts are provided to install and use custom software stacks easily build for all architectures. For installing packages with EasyBuild, see EasyBuild description . Manual package can also be installed in the similar manner. Adding a Modulefile provides the users to load packages as used to. Please see Installing Custom Software . As a result all users of the Workspace can use the software packages by loading the Workspace module and the software product module.","title":"Software stacks"},{"location":"hpc-workspaces/environment.html#python-packages","text":"The Workspace module provides support to install and use Python packages in a shared manner, by installing them into the Workspace. Please see Python Additional Packages First load Python/Anaconda3 Python or Anaconda3 module need to be loaded before loading the Workspace module, since variables to be set depend on Python version. Workspace module can also be reloaded, e.g.: HPC_WORKSPACE=HPC_SW_test module load Workspace module load Python module load Workspace","title":"Python packages"},{"location":"hpc-workspaces/environment.html#conda-environments","text":"The Workspace module provides support for creating and using conda environments in the shared Workspace. See Anaconda Conda environments .","title":"Conda environments"},{"location":"hpc-workspaces/environment.html#r-packages","text":"The Workspace module provides support for installing and using additional R packages in the shared Workspace. Thus a package once installed by one user can be used by all Workspace members. See R installing packages .","title":"R packages"},{"location":"hpc-workspaces/environment.html#umask","text":"The Workspace module sets the umask to 002. Thus files and directories get group-writeable, e.g.: -rw-rw-r-- 1 user group 0 Mar 15 15 :15 /path/to/file","title":"UMASK"},{"location":"hpc-workspaces/environment.html#additional-software-stacks","text":"The module Workspace_SW_only provide the access to a software stack of an HPC Workspace B while working in an HPC Workspace A . This could be that a common software stack is provided for multiple (data) Workspaces or that you are trying software packages in your HOME As an example you could load: HPC_WORKSPACE = A module load Workspace HPC_WORKSPACE = B module load Workspace_SW_only When you want to load packages from your HOME while working in A , you can HPC_WORKSPACE = $HOME module load Workspace_SW_only HPC_WORKSPACE = A module load Workspace Note that the variable HPC_WORKSPACE is cleared after each loading of a Workspace* module. The currently loaded Workspace names are stored in $HPC_WORKSPACE_LOADED for the Workspace module and $HPC_WORKSPACE_SW_ONLY for the Workspace_SW_only module.","title":"Additional Software Stacks"},{"location":"hpc-workspaces/environment.html#reloading","text":"The Workspace modules are configured to \u201cremember\u201d the selected Workspace you once loaded in the current session, even after unload the Workspace module. Therefore, environment variables are set in the current session, $HPC_WORKSPACE for the Workspace module, and $HPC_WORKSPACE_SW_ONLY for the Workspace_SW_only module. If you belong to multiple Workspaces and you want to list the available Workspaces you need to unset HPC_WORKSPACE before loading the Workspace module. If you already know the name, you can switch into another Workspace (here Workspace foo ) by: module unload Workspace HPC_WORKSPACE = foo module load Workspace When you are creating a new module, there are cases where you need to reload a Workspace module, e.g. for a Python packages. This can be obtained using e.g. the following lua modulefile syntax: if mode () == 'load' then if not ( isloaded ( \"Python\" ) ) then load ( \"Python\" ) if ( isloaded ( \"Workspace\" ) ) then load ( \"Workspace\" ) end if ( isloaded ( \"Workspace_SW_only\" ) ) then load ( \"Workspace_SW_only\" ) end if ( isloaded ( \"Workspace_HOME\" ) ) then load ( \"Workspace_HOME\" ) end end end Assuming we want to create a module for an additional Python package. In this example we not only verify that Python is loaded, but also that the Workspace Python settings (incl. PYTHONPATH and PYTHONPACKAGEPATH ) are set properly by reloading the Workspace module.","title":"Reloading"},{"location":"hpc-workspaces/management.html","text":"Workspace management Description This article targets Workspace managers. It covers applications, Workspace properties, up to modifications and suggested usage of Workspaces. Workspace Intention Workspaces are group shared resources. This group could be for example: whole research group working together on shared data and software packages student(s) an their supervisor collaborating researchers from different research groups/institutes sub-group within the research group, which requires data separation Workspace Properties Ownership HPC Workspaces manage compute and storage resources. Especially the freely available resources are meant to be shared between participating research groups. Therefore, the Workspaces belong to a beforehand registered research group. An HPC Workspace can be only requested by a research group leader , who responsible and accountable, since costly extensions can be added to the Workspace. Additionally, a deputy can be nominated, who also can manage the Workspace (see Workspace Modification ). Owners and deputies are called Workspace managers . Deputies Deputies have the same privileges than the owner, up to purchasing costly resources without additional notification. If the workspace is meant to be for a collaboration of researchers from different research groups, you need to agree to one research group which is responsibilities and gets accounted for the resources. This research group leader need to request the workspace. Member groups Each Workspace has two member groups: primary users with read and write access and secondary users with read only access Only members of the primary group can create and modify data, belonging to the Workspace, as well as submitting jobs to the Workspace account. The member lists are defined at Workspace application time and can be modified later. Members can be anyone with an UniBE Campus Account, but need to be registered for UBELIX usage, see Account Activation . Free Of Charge Quota Every research group has 10TB free of charge quota. This can be used within one or more Workspaces. The amount used per Workspace is set at application time and can be changed later within the limitation. Additional Storage Additional storage can be purchased for 50CHF per TB per year. On the application or modification form an quota upper limit can be set. Accounted will be the actual usage. Therefore, the actual usage is monitored and twice a day. The average value of all data points is used for accounting. Availability Storage is a limited and expensive resource. Abandoned, unused workspaces should be prevented by design. Therefore, an HPC Workspace has a default live time of one year. A notification will be send before the Workspace expiry. The Workspace expiry date can be changed at any time to any date within the next 365 days by any Workspace manager. ServicePortal -> Shop -> HPC -> Edit HPC Workspace -> Workspace Duratio Application Prerequisite Since we are sharing the HPC resources on basis of research groups, a registration of these is required. Only official University of Bern research groups can register. These need to be officially represented within the unibe.ch sites. Since research group definition are vague. In unclear situation please specify the responsible professor . Required information: research group name research group responsible , in best case responsible professor A long term responsible person, e.g. for data in case actual research group lead leaves university. Research group or topic need to be at least stated on the UniBE webpage. cost center for location in organizational tree (a UniBE cost center) for determining the proper cost center, please ask YOUR UniBE secretary official unibe.ch research group URL , where the research group name and research group head is mentioned research group ID which is merged with the institute ID. This code is used in the UBELIX file system tree Registration Form: Service Portal -> Register Research Group The request need to be verified manually. This may take some time. Application Form An HPC Workspace can (only) be requested by a registered research group lead/manager using the ServicePortal application form: Service Portal -> Create HPC Workspace The following information are required: Workspace ID (max. 20 characters), please choose a unique name Workspace Name Workspace Description registered research group (see prerequisites) Deputy (permissions for managing the Workspace) (optional) Free Quota (see above) additional Storage (optional): an upper limit of quota, where the actual quota will be charged. When selected this requires a valid cost center for accounting. Cost Center (necessary when requesting Additional Storage) primary group members (all accounts need UBELIX activation beforehand) secondary group members (optional) (all accounts need UBELIX activation beforehand) member lists can be selected one by one or as a comma separated list of Campus accounts (see Import Bulk User ) All members need to have their account activated for UBELIX, otherwise the process will fail and need manual intervention. See Account Activation If the requester only want to hold the managing position without UBELIX, the requester can remove his/her account from the primary member list. This can be changed any time. Workspace ID The Workspace ID need to be a unique string. Please avoid duplications with user IDs, Research Group IDs and other Workspace names. processing time The Workspace creation for now relies on a temporary automatic process which is running only once a day at 20:00. In future the process will be much faster. Workspace modifications After creation, owners and deputies can modify Workspace properties using the Service Portal Form: Service Portal -> Edit HPC Workspace Properties to change are: - adding/removing members to/from primary and secondary group - storage extension - Workspace live time extension - Workspace closure (so far you need to \u201cdeactivate\u201d AND THEN \u201cdelete\u201d the workspace) Note During the processing of a modification no other modification can be requested. The Workspace is even not visible in the ServicePortal for that time. Most modification will be processed within few minutes, but adding non-free-of-charge features like additional storage, need human approval, which may delay the process. The Workspace itself (file storage and lsf, etc.) will not be interrupted by a change. Investor QoS Investors get elevated priviledges for specific queues. These are managed in so called lsf QoS (Quality of Service). Where in the past the investors specified a list of users, who can use the QoS, in future Workspaces are able to manage the QoS on Workspace level. Therefore, you need to open a request to add an existing QoS to a (list of) Workspace(s). The membership managment is done within the Workspace. Warning Investor QoS are bind to lsf accounts. Since personal lsf accounts get deactivated when joining an HPC Workspace, the investor QoS need to get transfered. This process is not done automatically, please request the transfer using our ServicePortal Import Bulk Users The \u201cImport Bulk Users\u201d field provides the possibility to list a larger set of members for primary or secondary group without selecting them one by one. There the members need to be specified as a comma seperated list of Campus Accounts (not full names). Keep in mind: you need to specify the full list of members in these field. After leaving the field the upper primary/secondary member list will be replaced with this list. Permission Background This sections provides more advanced information about the implementation of the permission handling for both permission groups. Nevertheless, we strongly suggest to keep default permissions. -rw-rw-r-- for files and drwxrwxr-x for directories. In Linux permissions are manged using: user (owner), group and other . user will always be the username creating the file/directory. In a Workspace the group will always be the Workspace primary group. This should (and this is default) get read/write permissions. The Workspace secondary group gets access to the Workspace main directory using ACLs. Then, within the Workspace these members acts as other and need to get read permissions. Thus a file: -rw-rw-r-- 2 user ws_group 4096 Jan 01 09 :11 filename can be modified by all members of the ws_group and read by everyone else (with access to that location, which is grated for secondary Workspace group members). And a file -rw-rw---- 2 user ws_group 4096 Jan 01 09 :11 filename2 can be modified by all members of the ws_group , but NOT read by anyone else (even not secondary Workspace group members). Please, make sure that all your files and directories keep this permissions. In case of moving data from other locations, these could vary and can be corrected using: find /storage/workspace/<researchGroupID>/<workspaceID>/ \\ \\( -type f -exec chmod 664 {} \\; \\) , \\ \\( -type d -exec chmod 775 {} \\; \\)","title":"Workspace management"},{"location":"hpc-workspaces/management.html#workspace-management","text":"","title":"Workspace management"},{"location":"hpc-workspaces/management.html#description","text":"This article targets Workspace managers. It covers applications, Workspace properties, up to modifications and suggested usage of Workspaces.","title":"Description"},{"location":"hpc-workspaces/management.html#workspace-intention","text":"Workspaces are group shared resources. This group could be for example: whole research group working together on shared data and software packages student(s) an their supervisor collaborating researchers from different research groups/institutes sub-group within the research group, which requires data separation","title":"Workspace Intention"},{"location":"hpc-workspaces/management.html#workspace-properties","text":"","title":"Workspace Properties"},{"location":"hpc-workspaces/management.html#ownership","text":"HPC Workspaces manage compute and storage resources. Especially the freely available resources are meant to be shared between participating research groups. Therefore, the Workspaces belong to a beforehand registered research group. An HPC Workspace can be only requested by a research group leader , who responsible and accountable, since costly extensions can be added to the Workspace. Additionally, a deputy can be nominated, who also can manage the Workspace (see Workspace Modification ). Owners and deputies are called Workspace managers . Deputies Deputies have the same privileges than the owner, up to purchasing costly resources without additional notification. If the workspace is meant to be for a collaboration of researchers from different research groups, you need to agree to one research group which is responsibilities and gets accounted for the resources. This research group leader need to request the workspace.","title":"Ownership"},{"location":"hpc-workspaces/management.html#member-groups","text":"Each Workspace has two member groups: primary users with read and write access and secondary users with read only access Only members of the primary group can create and modify data, belonging to the Workspace, as well as submitting jobs to the Workspace account. The member lists are defined at Workspace application time and can be modified later. Members can be anyone with an UniBE Campus Account, but need to be registered for UBELIX usage, see Account Activation .","title":"Member groups"},{"location":"hpc-workspaces/management.html#free-of-charge-quota","text":"Every research group has 10TB free of charge quota. This can be used within one or more Workspaces. The amount used per Workspace is set at application time and can be changed later within the limitation.","title":"Free Of Charge Quota"},{"location":"hpc-workspaces/management.html#additional-storage","text":"Additional storage can be purchased for 50CHF per TB per year. On the application or modification form an quota upper limit can be set. Accounted will be the actual usage. Therefore, the actual usage is monitored and twice a day. The average value of all data points is used for accounting.","title":"Additional Storage"},{"location":"hpc-workspaces/management.html#availability","text":"Storage is a limited and expensive resource. Abandoned, unused workspaces should be prevented by design. Therefore, an HPC Workspace has a default live time of one year. A notification will be send before the Workspace expiry. The Workspace expiry date can be changed at any time to any date within the next 365 days by any Workspace manager. ServicePortal -> Shop -> HPC -> Edit HPC Workspace -> Workspace Duratio","title":"Availability"},{"location":"hpc-workspaces/management.html#application","text":"","title":"Application"},{"location":"hpc-workspaces/management.html#prerequisite","text":"Since we are sharing the HPC resources on basis of research groups, a registration of these is required. Only official University of Bern research groups can register. These need to be officially represented within the unibe.ch sites. Since research group definition are vague. In unclear situation please specify the responsible professor . Required information: research group name research group responsible , in best case responsible professor A long term responsible person, e.g. for data in case actual research group lead leaves university. Research group or topic need to be at least stated on the UniBE webpage. cost center for location in organizational tree (a UniBE cost center) for determining the proper cost center, please ask YOUR UniBE secretary official unibe.ch research group URL , where the research group name and research group head is mentioned research group ID which is merged with the institute ID. This code is used in the UBELIX file system tree Registration Form: Service Portal -> Register Research Group The request need to be verified manually. This may take some time.","title":"Prerequisite"},{"location":"hpc-workspaces/management.html#application-form","text":"An HPC Workspace can (only) be requested by a registered research group lead/manager using the ServicePortal application form: Service Portal -> Create HPC Workspace The following information are required: Workspace ID (max. 20 characters), please choose a unique name Workspace Name Workspace Description registered research group (see prerequisites) Deputy (permissions for managing the Workspace) (optional) Free Quota (see above) additional Storage (optional): an upper limit of quota, where the actual quota will be charged. When selected this requires a valid cost center for accounting. Cost Center (necessary when requesting Additional Storage) primary group members (all accounts need UBELIX activation beforehand) secondary group members (optional) (all accounts need UBELIX activation beforehand) member lists can be selected one by one or as a comma separated list of Campus accounts (see Import Bulk User ) All members need to have their account activated for UBELIX, otherwise the process will fail and need manual intervention. See Account Activation If the requester only want to hold the managing position without UBELIX, the requester can remove his/her account from the primary member list. This can be changed any time. Workspace ID The Workspace ID need to be a unique string. Please avoid duplications with user IDs, Research Group IDs and other Workspace names. processing time The Workspace creation for now relies on a temporary automatic process which is running only once a day at 20:00. In future the process will be much faster.","title":"Application Form"},{"location":"hpc-workspaces/management.html#workspace-modifications","text":"After creation, owners and deputies can modify Workspace properties using the Service Portal Form: Service Portal -> Edit HPC Workspace Properties to change are: - adding/removing members to/from primary and secondary group - storage extension - Workspace live time extension - Workspace closure (so far you need to \u201cdeactivate\u201d AND THEN \u201cdelete\u201d the workspace) Note During the processing of a modification no other modification can be requested. The Workspace is even not visible in the ServicePortal for that time. Most modification will be processed within few minutes, but adding non-free-of-charge features like additional storage, need human approval, which may delay the process. The Workspace itself (file storage and lsf, etc.) will not be interrupted by a change.","title":"Workspace modifications"},{"location":"hpc-workspaces/management.html#investor-qos","text":"Investors get elevated priviledges for specific queues. These are managed in so called lsf QoS (Quality of Service). Where in the past the investors specified a list of users, who can use the QoS, in future Workspaces are able to manage the QoS on Workspace level. Therefore, you need to open a request to add an existing QoS to a (list of) Workspace(s). The membership managment is done within the Workspace. Warning Investor QoS are bind to lsf accounts. Since personal lsf accounts get deactivated when joining an HPC Workspace, the investor QoS need to get transfered. This process is not done automatically, please request the transfer using our ServicePortal","title":"Investor QoS"},{"location":"hpc-workspaces/management.html#import-bulk-users","text":"The \u201cImport Bulk Users\u201d field provides the possibility to list a larger set of members for primary or secondary group without selecting them one by one. There the members need to be specified as a comma seperated list of Campus Accounts (not full names). Keep in mind: you need to specify the full list of members in these field. After leaving the field the upper primary/secondary member list will be replaced with this list.","title":"Import Bulk Users"},{"location":"hpc-workspaces/management.html#permission-background","text":"This sections provides more advanced information about the implementation of the permission handling for both permission groups. Nevertheless, we strongly suggest to keep default permissions. -rw-rw-r-- for files and drwxrwxr-x for directories. In Linux permissions are manged using: user (owner), group and other . user will always be the username creating the file/directory. In a Workspace the group will always be the Workspace primary group. This should (and this is default) get read/write permissions. The Workspace secondary group gets access to the Workspace main directory using ACLs. Then, within the Workspace these members acts as other and need to get read permissions. Thus a file: -rw-rw-r-- 2 user ws_group 4096 Jan 01 09 :11 filename can be modified by all members of the ws_group and read by everyone else (with access to that location, which is grated for secondary Workspace group members). And a file -rw-rw---- 2 user ws_group 4096 Jan 01 09 :11 filename2 can be modified by all members of the ws_group , but NOT read by anyone else (even not secondary Workspace group members). Please, make sure that all your files and directories keep this permissions. In case of moving data from other locations, these could vary and can be corrected using: find /storage/workspace/<researchGroupID>/<workspaceID>/ \\ \\( -type f -exec chmod 664 {} \\; \\) , \\ \\( -type d -exec chmod 775 {} \\; \\)","title":"Permission Background"},{"location":"hpc-workspaces/monitoring.html","text":"HPC Workspace Monitoring Tools Description Workspaces are consting of different features. Depending on the feature you can check settings using: Feature tool permission Storage call quota on a ubelix login node, see Quota Tool , accounting information using quota -l everyone belonging to the Workspace prim./sec. group membership Service Portal -> Edit HPC Workspace Workspace owner and deputy lsf fair share still under construction, comming soon everyone belonging to the Workspace Workspace properties can be changed by Workspace managers, see Workspace Management","title":"Monitoring"},{"location":"hpc-workspaces/monitoring.html#hpc-workspace-monitoring-tools","text":"","title":"HPC Workspace Monitoring Tools"},{"location":"hpc-workspaces/monitoring.html#description","text":"Workspaces are consting of different features. Depending on the feature you can check settings using: Feature tool permission Storage call quota on a ubelix login node, see Quota Tool , accounting information using quota -l everyone belonging to the Workspace prim./sec. group membership Service Portal -> Edit HPC Workspace Workspace owner and deputy lsf fair share still under construction, comming soon everyone belonging to the Workspace Workspace properties can be changed by Workspace managers, see Workspace Management","title":"Description"},{"location":"hpc-workspaces/workspaces.html","text":"Workspaces Introduction Description This article introduces HPC workspaces with the main aspects. A guideline for Workspace managers including application and modification can be found at Workspace Management . If you want to join an existing Workspace , please ask the Workspace owner or manager to add your account. An HPC workspace consists of: 2 access groups, read/write and read only permanent and temporary storage lsf accounting fair share on research group level Attention Please always load the Workspace module, even if only just copying files into it. The module corrects the umask and therewith the created file and directory permissions. Furthermore, it is good practice to use $WORKSPACE/file1 instead of absolute path /path/to/Workspace/file1 Motivation HPC data typically is shared data. This could be between students and supervisors, between researchers of a research group, or even between researchers of different institutes. These data needs to be accessible even if people leave the team. Furthermore, these data is usually processed with a set of custom software tools, which need to be easy accessible, share, between the collaborators. Advantages group based storage access (data and software) enhanced collaborations between researchers, even across institutes user-friendly access control by Workspace managers high bandwidth storage and backup temporary space with less restricted quota research group based compute resource sharing in-line with other HPC centres Storage Access Permissions HOME is meant to be a private space, mainly for configurational data. All group oriented data is meant to be located in a HPC Workspace directories: /storage/workspaces/<researchGroupID>/<workspaceID> for permanent storage /storage/scratch/ for temporary storage, see File Systems All files and directories in the group shared spaces are meant to stay with default permissions, like -rw-rw-r-- : read and write for owner and primary group members read only access for others. Since the Workspace directory itself is limited to primary and secondary group members using ACLs, secondary group members get read permissions. Members The Workspace owner can define a deputy who gets same permissions as owner, including booking at cost. Workspace permissions are managed with two lists of members : primary users, with read and write access to all data in the spaces, permission to account to that Workspace secondary users, with read only access Thus, the Workspace and SCRATCH space are accessible to all members of the both lists of users, but only the members of the primary list can write or modify data. Members can be anyone with an active UniBE Campus Account. The Workspace owner or its deputies can manage the lists using the Service Portal Workspace edit Form: Service Portal -> Edit HPC Workspace Backup All data in the permanent space ( /storage/workspaces/ ) is protected using daily snapshots and backups. Scratch will not be protected by snapshots or backups. Quota For default and actual quota information use quota tool. More details see File System Quota . lsf Computational work is accounted to a Workspace account. Every workspace belongs to a research group. The freely available resources are shared between research groups. In contrast to the previous implementation, the priorities are based on research group usage and shared between all workspaces related to this research group.","title":"Overview"},{"location":"hpc-workspaces/workspaces.html#workspaces-introduction","text":"","title":"Workspaces Introduction"},{"location":"hpc-workspaces/workspaces.html#description","text":"This article introduces HPC workspaces with the main aspects. A guideline for Workspace managers including application and modification can be found at Workspace Management . If you want to join an existing Workspace , please ask the Workspace owner or manager to add your account. An HPC workspace consists of: 2 access groups, read/write and read only permanent and temporary storage lsf accounting fair share on research group level Attention Please always load the Workspace module, even if only just copying files into it. The module corrects the umask and therewith the created file and directory permissions. Furthermore, it is good practice to use $WORKSPACE/file1 instead of absolute path /path/to/Workspace/file1","title":"Description"},{"location":"hpc-workspaces/workspaces.html#motivation","text":"HPC data typically is shared data. This could be between students and supervisors, between researchers of a research group, or even between researchers of different institutes. These data needs to be accessible even if people leave the team. Furthermore, these data is usually processed with a set of custom software tools, which need to be easy accessible, share, between the collaborators.","title":"Motivation"},{"location":"hpc-workspaces/workspaces.html#advantages","text":"group based storage access (data and software) enhanced collaborations between researchers, even across institutes user-friendly access control by Workspace managers high bandwidth storage and backup temporary space with less restricted quota research group based compute resource sharing in-line with other HPC centres","title":"Advantages"},{"location":"hpc-workspaces/workspaces.html#storage-access-permissions","text":"HOME is meant to be a private space, mainly for configurational data. All group oriented data is meant to be located in a HPC Workspace directories: /storage/workspaces/<researchGroupID>/<workspaceID> for permanent storage /storage/scratch/ for temporary storage, see File Systems All files and directories in the group shared spaces are meant to stay with default permissions, like -rw-rw-r-- : read and write for owner and primary group members read only access for others. Since the Workspace directory itself is limited to primary and secondary group members using ACLs, secondary group members get read permissions.","title":"Storage Access Permissions"},{"location":"hpc-workspaces/workspaces.html#members","text":"The Workspace owner can define a deputy who gets same permissions as owner, including booking at cost. Workspace permissions are managed with two lists of members : primary users, with read and write access to all data in the spaces, permission to account to that Workspace secondary users, with read only access Thus, the Workspace and SCRATCH space are accessible to all members of the both lists of users, but only the members of the primary list can write or modify data. Members can be anyone with an active UniBE Campus Account. The Workspace owner or its deputies can manage the lists using the Service Portal Workspace edit Form: Service Portal -> Edit HPC Workspace","title":"Members"},{"location":"hpc-workspaces/workspaces.html#backup","text":"All data in the permanent space ( /storage/workspaces/ ) is protected using daily snapshots and backups. Scratch will not be protected by snapshots or backups.","title":"Backup"},{"location":"hpc-workspaces/workspaces.html#quota","text":"For default and actual quota information use quota tool. More details see File System Quota .","title":"Quota"},{"location":"hpc-workspaces/workspaces.html#lsf","text":"Computational work is accounted to a Workspace account. Every workspace belongs to a research group. The freely available resources are shared between research groups. In contrast to the previous implementation, the priorities are based on research group usage and shared between all workspaces related to this research group.","title":"lsf"},{"location":"lsf/Running%20jobs.html","text":"Running jobs on the clusters","title":"Running jobs on the clusters"},{"location":"lsf/Running%20jobs.html#running-jobs-on-the-clusters","text":"","title":"Running jobs on the clusters"},{"location":"lsf/Running%20jobs.html#_1","text":"","title":""},{"location":"lsf/array-jobs.html","text":"Array Jobs with lsf Description Array jobs are jobs where the job setup, including job size, memory, time etc. is constant, but the application input varies. One use case are parameter studies. Instead of submitting N jobs independently, you can submit one array job unifying N tasks. These provide advantages in the job handling as well as for the lsf scheduler. Submitting an Array To submit an array job, specify the number of tasks as a range of task IDs using the \u2013array option: #SBATCH --array=n[,k[,...]][-m[:s]]%<max_tasks> The task id range specified in the option argument may be: comma separated list of values: #SBATCH --array=1,3,5 simple range of the form n-m: #SBATCH --array=201-300 (201, 202, 203, \u2026, 300) range with a step size s: #SBATCH --array=100-200:2 (100, 102, 104, \u2026 200) combination thereof: #SBATCH --array=1,3,100-200 (1, 3, 100, 101, 102, \u2026, 200) Furthermore, the amount of concurent running jobs can limited using the % seperator, e.g. for max 100 concurrent jobs of 1-400: #SBATCH --array=1-400%100 . Therewith you can prevent fully filling your available resources. The task IDs will be exported to the job tasks via the environment variable lsf_ARRAY_TASK_ID . Additionally, lsf_ARRAY_TASK_MAX , lsf_ARRAY_TASK_MIN , lsf_ARRAY_TASK_STEP are available in job, describing the task range of the job. Specifying --array=10 will not submit an array job with 10 tasks, but an array job with a single task with task id 10. To run an array job with multiple tasks you must specify a range or a comma separated list of task ids. Output files Per default the output files are named as lsf-<jobid>_<taskid>.out . When renaming the output/error files variables for the job ID ( %A ) and for the task ID ( %a ) can be used. For example: #SBATCH --output=array_example_%A_%a.out #SBATCH --error=array_example_%A_%a.err Thus a file array_example_6543212_12.out will be written for the 12th task of job 6543212. Canceling Individual Tasks You can cancel individual tasks of an array job by indicating tasks ids to the scancel command: $ squeue JOBID PARTITION NAME USER ST TIME NODES NODELIST ( REASON ) 79265_ [ 49 -99:2%20 ] test Simple H foo PD 0 :00 1 ( QOSMaxCpuPerUserLimit ) 79265_41 test Simple H foo R 0 :10 1 fnode03 79265_43 test Simple H foo R 0 :10 1 fnode03 79265_45 test Simple H foo R 0 :10 1 fnode03 79265_47 test Simple H foo R 0 :10 1 fnode03 Use the --array option to the squeue command to display one tasks per line: $ squeue --array JOBID PARTITION NAME USER ST TIME NODES NODELIST ( REASON ) 79265_65 test Simple H foo PD 0 :00 1 ( QOSMaxCpuPerUserLimit ) 79265_67 test Simple H foo PD 0 :00 1 ( QOSMaxCpuPerUserLimit ) 79265_69 test Simple H foo PD 0 :00 1 ( QOSMaxCpuPerUserLimit ) 79265_97 test Simple H foo PD 0 :00 1 ( QOSMaxCpuPerUserLimit ) 79265_57 test Simple H foo R 0 :47 1 fnode03 79265_59 test Simple H foo R 0 :47 1 fnode03 79265_61 test Simple H foo R 0 :47 1 fnode03 79265_63 test Simple H foo R 0 :47 1 fnode03 Examples Use case 1: 1000 computations, same resource requirements, different input/output arguments Instead of submitting 1000 individual jobs, submit a single array jobs with 1000 tasks: #!/bin/bash #SBATCH --time=00:30:00 # Each task takes max 30 minutes #SBATCH --mem-per-cpu=2G # Each task uses max 2G of memory #SBATCH --array=1-1000 # Submit 1000 tasks with task ID 1,2,...,1000. # The name of the input files must reflect the task ID! srun ./foo input_data_ ${ lsf_ARRAY_TASK_ID } .txt > output_ ${ lsf_ARRAY_TASK_ID } .txt Task with ID 20 will run the program foo with the following arguments: ./foo input_data_20.txt > output_20.txt Use case 2: Read arguments from file Submit an array job with 1000 tasks. Each task executes the program foo with different arguments: #!/bin/bash #SBATCH --time=00:30:00 # Each task takes max 30 minutes #SBATCH --mem-per-cpu=2G # Each task uses max 2G of memory ### Submit 1000 tasks with task ID 1,2,...,1000. Run max 20 tasks concurrently #SBATCH --array=1-1000%20 data_dir = $WORKSPACE /projects/example/input_data result_dir = $WORKSPACE /projects/example/results param_store = $WORKSPACE /projects/example/args.txt ### args.txt contains 1000 lines with 2 arguments per line. ### Line <i> contains arguments for run <i> # Get first argument param_a = $( cat $param_store | awk -v var = $lsf_ARRAY_TASK_ID 'NR==var {print $1}' ) # Get second argument param_b = $( cat $param_store | awk -v var = $lsf_ARRAY_TASK_ID 'NR==var {print $2}' ) ### Input files are named input_run_0001.txt,...input_run_1000.txt ### Zero pad the task ID to match the numbering of the input files n = $( printf \"%04d\" $lsf_ARRAY_TASK_ID ) srun ./foo -c $param_a -p $param_b -i ${ data_dir } /input_run_ ${ n } .txt -o ${ result_dir } /result_run_ ${ n } .txt","title":"Array Jobs with lsf"},{"location":"lsf/array-jobs.html#array-jobs-with-lsf","text":"","title":"Array Jobs with lsf"},{"location":"lsf/array-jobs.html#description","text":"Array jobs are jobs where the job setup, including job size, memory, time etc. is constant, but the application input varies. One use case are parameter studies. Instead of submitting N jobs independently, you can submit one array job unifying N tasks. These provide advantages in the job handling as well as for the lsf scheduler.","title":"Description"},{"location":"lsf/array-jobs.html#submitting-an-array","text":"To submit an array job, specify the number of tasks as a range of task IDs using the \u2013array option: #SBATCH --array=n[,k[,...]][-m[:s]]%<max_tasks> The task id range specified in the option argument may be: comma separated list of values: #SBATCH --array=1,3,5 simple range of the form n-m: #SBATCH --array=201-300 (201, 202, 203, \u2026, 300) range with a step size s: #SBATCH --array=100-200:2 (100, 102, 104, \u2026 200) combination thereof: #SBATCH --array=1,3,100-200 (1, 3, 100, 101, 102, \u2026, 200) Furthermore, the amount of concurent running jobs can limited using the % seperator, e.g. for max 100 concurrent jobs of 1-400: #SBATCH --array=1-400%100 . Therewith you can prevent fully filling your available resources. The task IDs will be exported to the job tasks via the environment variable lsf_ARRAY_TASK_ID . Additionally, lsf_ARRAY_TASK_MAX , lsf_ARRAY_TASK_MIN , lsf_ARRAY_TASK_STEP are available in job, describing the task range of the job. Specifying --array=10 will not submit an array job with 10 tasks, but an array job with a single task with task id 10. To run an array job with multiple tasks you must specify a range or a comma separated list of task ids.","title":"Submitting an Array"},{"location":"lsf/array-jobs.html#output-files","text":"Per default the output files are named as lsf-<jobid>_<taskid>.out . When renaming the output/error files variables for the job ID ( %A ) and for the task ID ( %a ) can be used. For example: #SBATCH --output=array_example_%A_%a.out #SBATCH --error=array_example_%A_%a.err Thus a file array_example_6543212_12.out will be written for the 12th task of job 6543212.","title":"Output files"},{"location":"lsf/array-jobs.html#canceling-individual-tasks","text":"You can cancel individual tasks of an array job by indicating tasks ids to the scancel command: $ squeue JOBID PARTITION NAME USER ST TIME NODES NODELIST ( REASON ) 79265_ [ 49 -99:2%20 ] test Simple H foo PD 0 :00 1 ( QOSMaxCpuPerUserLimit ) 79265_41 test Simple H foo R 0 :10 1 fnode03 79265_43 test Simple H foo R 0 :10 1 fnode03 79265_45 test Simple H foo R 0 :10 1 fnode03 79265_47 test Simple H foo R 0 :10 1 fnode03 Use the --array option to the squeue command to display one tasks per line: $ squeue --array JOBID PARTITION NAME USER ST TIME NODES NODELIST ( REASON ) 79265_65 test Simple H foo PD 0 :00 1 ( QOSMaxCpuPerUserLimit ) 79265_67 test Simple H foo PD 0 :00 1 ( QOSMaxCpuPerUserLimit ) 79265_69 test Simple H foo PD 0 :00 1 ( QOSMaxCpuPerUserLimit ) 79265_97 test Simple H foo PD 0 :00 1 ( QOSMaxCpuPerUserLimit ) 79265_57 test Simple H foo R 0 :47 1 fnode03 79265_59 test Simple H foo R 0 :47 1 fnode03 79265_61 test Simple H foo R 0 :47 1 fnode03 79265_63 test Simple H foo R 0 :47 1 fnode03","title":"Canceling Individual Tasks"},{"location":"lsf/array-jobs.html#examples","text":"","title":"Examples"},{"location":"lsf/array-jobs.html#use-case-1-1000-computations-same-resource-requirements-different-inputoutput-arguments","text":"Instead of submitting 1000 individual jobs, submit a single array jobs with 1000 tasks: #!/bin/bash #SBATCH --time=00:30:00 # Each task takes max 30 minutes #SBATCH --mem-per-cpu=2G # Each task uses max 2G of memory #SBATCH --array=1-1000 # Submit 1000 tasks with task ID 1,2,...,1000. # The name of the input files must reflect the task ID! srun ./foo input_data_ ${ lsf_ARRAY_TASK_ID } .txt > output_ ${ lsf_ARRAY_TASK_ID } .txt Task with ID 20 will run the program foo with the following arguments: ./foo input_data_20.txt > output_20.txt","title":"Use case 1: 1000 computations, same resource requirements, different input/output arguments"},{"location":"lsf/array-jobs.html#use-case-2-read-arguments-from-file","text":"Submit an array job with 1000 tasks. Each task executes the program foo with different arguments: #!/bin/bash #SBATCH --time=00:30:00 # Each task takes max 30 minutes #SBATCH --mem-per-cpu=2G # Each task uses max 2G of memory ### Submit 1000 tasks with task ID 1,2,...,1000. Run max 20 tasks concurrently #SBATCH --array=1-1000%20 data_dir = $WORKSPACE /projects/example/input_data result_dir = $WORKSPACE /projects/example/results param_store = $WORKSPACE /projects/example/args.txt ### args.txt contains 1000 lines with 2 arguments per line. ### Line <i> contains arguments for run <i> # Get first argument param_a = $( cat $param_store | awk -v var = $lsf_ARRAY_TASK_ID 'NR==var {print $1}' ) # Get second argument param_b = $( cat $param_store | awk -v var = $lsf_ARRAY_TASK_ID 'NR==var {print $2}' ) ### Input files are named input_run_0001.txt,...input_run_1000.txt ### Zero pad the task ID to match the numbering of the input files n = $( printf \"%04d\" $lsf_ARRAY_TASK_ID ) srun ./foo -c $param_a -p $param_b -i ${ data_dir } /input_run_ ${ n } .txt -o ${ result_dir } /result_run_ ${ n } .txt","title":"Use case 2: Read arguments from file"},{"location":"lsf/checkpointing.html","text":"Checkpointing Description Checkpointing: Saving the state of a computation so that it can be resumed later. On this page we provide some useful information for making your own code checkpoint-able. Currently, we do not provide and support programs and libraries (e.g. BLCR) that allow to checkpoint proprietary (closed source) software. Some applications provide built-in checkpoint/restart mechanisms: Gaussian, Quantum Espresso, CP2K and more. Why checkpointing Imagine a job is already running for several hours when an event occurs which leads to the abortion of the job. Such events can be: Exceeding the time limit Exceeding allocated memory Job gets preempted by another job (gpu partition only!) Node failure Checkpointing a job means that you frequently save the job state so that you can resume computation from the last checkpoint in case of a disastrous event. General recipe for checkpointing your own code Introducing checkpointing logic in your code consists of 3 steps 1. Look for a state file containing a previously saved state. 2. If a state file exists, then restore the state. Else, start from scratch. 3. Periodically save the state. Using UNIX signals You can save the state of your job at specific points in time, after certain iterations, or at whatever event you choose to trigger a state saving. You can also trap specific UNIX signals and act as soon as the signal occurs. The following table lists common signals that you might want to trap in your program: Signal Name Signal Number Description Default Disposition SIGTERM 15 SIGTERM initiates the termination of a process Term - Terminate the process SIGCONT 18 SIGCONT continues a stopped process Cont - Continue the process if stopped SIGUSR1 10 User-defined signals. SIGUSR1/SIGUSR2 are never sent by the kernel Term - Terminate the process SIGUSR2 12 User-defined signals. SIGUSR1/SIGUSR2 are never sent by the kernel Term - Terminate the process kill -l for a list of all supported signals. Note that some signals cannot be trapped, e.g SIGKILL lsf sends SIGCONT followed by SIGTERM just before a job is canceled. Trapping the signal (e.g. SIGTERM) gives you 60 seconds for housekeeping tasks, e.g. save current state. At the latest after that your job is canceled with SIGKILL. This is true for jobs canceled by the owner using scancel and jobs canceled by lsf, e.g. because of exceeding time limit. Register a signal handler for a UNIX signal The following examples show how to register a signal handler in different languages, but omit the logic for creating a checkpoint and restart a job from an existing checkpoint. We will provide a working example further down below on this page. Bash #!/bin/bash function signal_handler { # Save program state and exit ( ... ) exit } trap signal_handler TERM ( ... ) C/C++ #include <signal.h> // C #include <csignal> // C++ void signal_handler ( int signal ) { // Save program state and exit (...) exit ( 0 ); } // Register signal handler for SIGTERM signal ( SIGTERM , signal_handler ); // signal_handler: function to handle signal (...) Python #! /usr/bin/env python import signal import sys def signal_handler ( sig , frame ): # Save program state and exit ( ... ) sys . exit ( 0 ) signal . signal ( signal . SIGTERM , signal_handler ) ( ... ) Signaling checkpoint creation without canceling the job lsf distinguishes between the job script, its child processes and job steps. Job steps are launched using srun . All applications which should reveive more signals than the default SIGERM at the end of the job, does need to be started using srun . Then signals (here SIGUSR1 ) can be send using: scancel --signal = USR1 <jobID> If you need/want to handle signals with the batch script, add --batch (signals only to the batch script) or --full (signal to all steps and the batch script), e.g. scancel --full --signal = USR1 <jobid> Therewith, you can use a UNIX signal to trigger the creation of a checkpoint of a running job. For example, consider a job that traps SIGUSR1 and saves intermediate results as soon as the signal occurs. You can then create a checkpoint by signaling SIGUSR1 to the job. Using scancel with the \u2013signal option won\u2019t terminate the job or job step.","title":"Checkpointing"},{"location":"lsf/checkpointing.html#checkpointing","text":"","title":"Checkpointing"},{"location":"lsf/checkpointing.html#description","text":"Checkpointing: Saving the state of a computation so that it can be resumed later. On this page we provide some useful information for making your own code checkpoint-able. Currently, we do not provide and support programs and libraries (e.g. BLCR) that allow to checkpoint proprietary (closed source) software. Some applications provide built-in checkpoint/restart mechanisms: Gaussian, Quantum Espresso, CP2K and more.","title":"Description"},{"location":"lsf/checkpointing.html#why-checkpointing","text":"Imagine a job is already running for several hours when an event occurs which leads to the abortion of the job. Such events can be: Exceeding the time limit Exceeding allocated memory Job gets preempted by another job (gpu partition only!) Node failure Checkpointing a job means that you frequently save the job state so that you can resume computation from the last checkpoint in case of a disastrous event.","title":"Why checkpointing"},{"location":"lsf/checkpointing.html#general-recipe-for-checkpointing-your-own-code","text":"Introducing checkpointing logic in your code consists of 3 steps 1. Look for a state file containing a previously saved state. 2. If a state file exists, then restore the state. Else, start from scratch. 3. Periodically save the state.","title":"General recipe for checkpointing your own code"},{"location":"lsf/checkpointing.html#using-unix-signals","text":"You can save the state of your job at specific points in time, after certain iterations, or at whatever event you choose to trigger a state saving. You can also trap specific UNIX signals and act as soon as the signal occurs. The following table lists common signals that you might want to trap in your program: Signal Name Signal Number Description Default Disposition SIGTERM 15 SIGTERM initiates the termination of a process Term - Terminate the process SIGCONT 18 SIGCONT continues a stopped process Cont - Continue the process if stopped SIGUSR1 10 User-defined signals. SIGUSR1/SIGUSR2 are never sent by the kernel Term - Terminate the process SIGUSR2 12 User-defined signals. SIGUSR1/SIGUSR2 are never sent by the kernel Term - Terminate the process kill -l for a list of all supported signals. Note that some signals cannot be trapped, e.g SIGKILL lsf sends SIGCONT followed by SIGTERM just before a job is canceled. Trapping the signal (e.g. SIGTERM) gives you 60 seconds for housekeeping tasks, e.g. save current state. At the latest after that your job is canceled with SIGKILL. This is true for jobs canceled by the owner using scancel and jobs canceled by lsf, e.g. because of exceeding time limit.","title":"Using UNIX signals"},{"location":"lsf/checkpointing.html#register-a-signal-handler-for-a-unix-signal","text":"The following examples show how to register a signal handler in different languages, but omit the logic for creating a checkpoint and restart a job from an existing checkpoint. We will provide a working example further down below on this page. Bash #!/bin/bash function signal_handler { # Save program state and exit ( ... ) exit } trap signal_handler TERM ( ... ) C/C++ #include <signal.h> // C #include <csignal> // C++ void signal_handler ( int signal ) { // Save program state and exit (...) exit ( 0 ); } // Register signal handler for SIGTERM signal ( SIGTERM , signal_handler ); // signal_handler: function to handle signal (...) Python #! /usr/bin/env python import signal import sys def signal_handler ( sig , frame ): # Save program state and exit ( ... ) sys . exit ( 0 ) signal . signal ( signal . SIGTERM , signal_handler ) ( ... )","title":"Register a signal handler for a UNIX signal"},{"location":"lsf/checkpointing.html#signaling-checkpoint-creation-without-canceling-the-job","text":"lsf distinguishes between the job script, its child processes and job steps. Job steps are launched using srun . All applications which should reveive more signals than the default SIGERM at the end of the job, does need to be started using srun . Then signals (here SIGUSR1 ) can be send using: scancel --signal = USR1 <jobID> If you need/want to handle signals with the batch script, add --batch (signals only to the batch script) or --full (signal to all steps and the batch script), e.g. scancel --full --signal = USR1 <jobid> Therewith, you can use a UNIX signal to trigger the creation of a checkpoint of a running job. For example, consider a job that traps SIGUSR1 and saves intermediate results as soon as the signal occurs. You can then create a checkpoint by signaling SIGUSR1 to the job. Using scancel with the \u2013signal option won\u2019t terminate the job or job step.","title":"Signaling checkpoint creation without canceling the job"},{"location":"lsf/deleting-jobs.html","text":"Deleting Jobs Description This page provides information on how to delete jobs. scancel Use the scancel command to delete active jobs Syntax scancel [ options ] <jobid> ... scancel can be restricted to a subset of jobs, using the following options with the related value, e.g: -u, --user $USER jobs of current user -A, --account jobs under this charge account -n, --jobname jobs with this job name -p, --partition jobs in this partition -t, --state jobs in this state Examples Delete specific job: scancel 12345678 Delete all running jobs: scancel --state = R Delete all of your jobs: scancel --user $USER","title":"Deleting Jobs"},{"location":"lsf/deleting-jobs.html#deleting-jobs","text":"","title":"Deleting Jobs"},{"location":"lsf/deleting-jobs.html#description","text":"This page provides information on how to delete jobs.","title":"Description"},{"location":"lsf/deleting-jobs.html#scancel","text":"Use the scancel command to delete active jobs Syntax scancel [ options ] <jobid> ... scancel can be restricted to a subset of jobs, using the following options with the related value, e.g: -u, --user $USER jobs of current user -A, --account jobs under this charge account -n, --jobname jobs with this job name -p, --partition jobs in this partition -t, --state jobs in this state","title":"scancel"},{"location":"lsf/deleting-jobs.html#examples","text":"Delete specific job: scancel 12345678 Delete all running jobs: scancel --state = R Delete all of your jobs: scancel --user $USER","title":"Examples"},{"location":"lsf/dependencies.html","text":"Job Dependencies Description This pages describes the lsf depencency feature. Use cases This feature is used when you need to chain jobs, due to dependencies. For example: a preprocessing job with 1 core should be followed by a simulation with 40 cores. Results should be post processed with a single core job. a post processing job should be submitted after all tasks of a job array are finished Usage The follow-up job need to specify the dependency using the sbatch option --dependency=<type>:<listOfJobIDs> . The type can be after , afterok , afterany , afternotok , aftercorr , expand , singleton . (see man sbatch for more info). The underlying job (which this job depends on) need to be submitted first. The related job ID can be caught, by collecting the sbatch output with the --parsable option, e.g. jid_w01 = $( sbatch --parsable job01.sh ) Example A pipeline should be build with: - preparation: job_prep.sh - 2 worker jobs ( job01.sh and job02.sh ) - if successfull: a collector job ( job_coll.sh ) - otherwise: a handling the error job ( job_handle_err.sh ) - The following script would submit all 3 job with respect to their dependencies. jid_pre = $( sbatch --parsable job_prep.sh ) jid_w01 = $( sbatch --parsable --dependency = afterok: ${ jid_pre } job01.sh ) jid_w02 = $( sbatch --parsable --dependency = afterok: ${ jid_pre } job02.sh ) sbatch --dependency = afterok: ${ jid_w01 } : ${ jid_w02 } job_coll.sh sbatch --dependency = afternotok: ${ jid_w01 } : ${ jid_w02 } job_handle_err.sh Dependency on array job When specifying a dependency to an array job only one job ID need to be specified, no matter how many array tasks are included. Thus, a 100 task array job and a postprocessing job can be launched using: jid = $( sbatch --parsable --array = 1 -100 job_arr.sh ) sbatch --dependency = afterok: ${ jid } job_post.sh Where the postprocessing job only runs if all 100 array task ended without error.","title":"Job dependencies"},{"location":"lsf/dependencies.html#job-dependencies","text":"","title":"Job Dependencies"},{"location":"lsf/dependencies.html#description","text":"This pages describes the lsf depencency feature.","title":"Description"},{"location":"lsf/dependencies.html#use-cases","text":"This feature is used when you need to chain jobs, due to dependencies. For example: a preprocessing job with 1 core should be followed by a simulation with 40 cores. Results should be post processed with a single core job. a post processing job should be submitted after all tasks of a job array are finished","title":"Use cases"},{"location":"lsf/dependencies.html#usage","text":"The follow-up job need to specify the dependency using the sbatch option --dependency=<type>:<listOfJobIDs> . The type can be after , afterok , afterany , afternotok , aftercorr , expand , singleton . (see man sbatch for more info). The underlying job (which this job depends on) need to be submitted first. The related job ID can be caught, by collecting the sbatch output with the --parsable option, e.g. jid_w01 = $( sbatch --parsable job01.sh )","title":"Usage"},{"location":"lsf/dependencies.html#example","text":"A pipeline should be build with: - preparation: job_prep.sh - 2 worker jobs ( job01.sh and job02.sh ) - if successfull: a collector job ( job_coll.sh ) - otherwise: a handling the error job ( job_handle_err.sh ) - The following script would submit all 3 job with respect to their dependencies. jid_pre = $( sbatch --parsable job_prep.sh ) jid_w01 = $( sbatch --parsable --dependency = afterok: ${ jid_pre } job01.sh ) jid_w02 = $( sbatch --parsable --dependency = afterok: ${ jid_pre } job02.sh ) sbatch --dependency = afterok: ${ jid_w01 } : ${ jid_w02 } job_coll.sh sbatch --dependency = afternotok: ${ jid_w01 } : ${ jid_w02 } job_handle_err.sh","title":"Example"},{"location":"lsf/dependencies.html#dependency-on-array-job","text":"When specifying a dependency to an array job only one job ID need to be specified, no matter how many array tasks are included. Thus, a 100 task array job and a postprocessing job can be launched using: jid = $( sbatch --parsable --array = 1 -100 job_arr.sh ) sbatch --dependency = afterok: ${ jid } job_post.sh Where the postprocessing job only runs if all 100 array task ended without error.","title":"Dependency on array job"},{"location":"lsf/fair-share.html","text":"Fair Share Description The provided resources of UBELIX are meant to be provided in a fair faishon between all interested research groups. Therefore, Workspaces belong to research groups. Every participating research group is entitled for the same amount of resources. This entitlement is shared between all Workspace accounts and its members using that accounts. The fair-share system is designed to encourage users to balance their use of resources over time and de-prioritize users/accounts with over average usage. Thus no user group/research group gets the opportunity to over-dominate on the systems, while others request resources. Fair-share is the largest factor in determining priority, but not the only one. Fair Share Score Your Fair Share score is a number between 0 and 1. Projects with a larger Fair Share score receive a higher priority in the queue. If an entity \u2014 a research group or its Workspace account \u2014 is using the machine more slowly than expected, for Fair Share purposes it is considered a light user. By contrast, one using the machine faster than expected is a heavy user. Workspaces at lightly using research groups get a higher Fair Share score than those at heavily using research groups. Within each research group, lightly using Workspaces get a higher Fair Share score than heavily using Workspaces. Using faster than your expected rate of usage will usually cause your Fair Share score to decrease . The more extreme the overuse, the more severe the likely drop. Using slower than your expected rate of usage will usually cause your Fair Share score to increase . The more extreme the underuse, the greater the Fair Share bonus. Using the cluster unevenly will cause your Fair Share score to decrease . Priorities The Fair Share score is used to set the job priorities. It is based on a share of the cluster, which is a fraction of the cluster\u2019s overall computing capacity. Fair Share under Construction detailed information will follow soon For investors there priorities may vary.","title":"Fair Share"},{"location":"lsf/fair-share.html#fair-share","text":"","title":"Fair Share"},{"location":"lsf/fair-share.html#description","text":"The provided resources of UBELIX are meant to be provided in a fair faishon between all interested research groups. Therefore, Workspaces belong to research groups. Every participating research group is entitled for the same amount of resources. This entitlement is shared between all Workspace accounts and its members using that accounts. The fair-share system is designed to encourage users to balance their use of resources over time and de-prioritize users/accounts with over average usage. Thus no user group/research group gets the opportunity to over-dominate on the systems, while others request resources. Fair-share is the largest factor in determining priority, but not the only one.","title":"Description"},{"location":"lsf/fair-share.html#fair-share-score","text":"Your Fair Share score is a number between 0 and 1. Projects with a larger Fair Share score receive a higher priority in the queue. If an entity \u2014 a research group or its Workspace account \u2014 is using the machine more slowly than expected, for Fair Share purposes it is considered a light user. By contrast, one using the machine faster than expected is a heavy user. Workspaces at lightly using research groups get a higher Fair Share score than those at heavily using research groups. Within each research group, lightly using Workspaces get a higher Fair Share score than heavily using Workspaces. Using faster than your expected rate of usage will usually cause your Fair Share score to decrease . The more extreme the overuse, the more severe the likely drop. Using slower than your expected rate of usage will usually cause your Fair Share score to increase . The more extreme the underuse, the greater the Fair Share bonus. Using the cluster unevenly will cause your Fair Share score to decrease .","title":"Fair Share Score"},{"location":"lsf/fair-share.html#priorities","text":"The Fair Share score is used to set the job priorities. It is based on a share of the cluster, which is a fraction of the cluster\u2019s overall computing capacity.","title":"Priorities"},{"location":"lsf/fair-share.html#fair-share_1","text":"under Construction detailed information will follow soon For investors there priorities may vary.","title":"Fair Share"},{"location":"lsf/gpus.html","text":"GPUs Description This page contains all information you need to submit GPU-jobs successfully on Ubelix. Important Information on GPU Usage Code that runs on the CPU will not magically make use of GPUs by simply submitting a job to the \u2018gpu\u2019 partition! You have to explicitly adapt your code to run on the GPU, e.g. an CUDA or OpenACC implementation. Also, code that runs on a GPU will not necessarily run faster than it runs on the CPU. For example, GPUs require a huge amount of highly parallelizable tasks. In other words, you must understand the characteristics of your job, and make sure that you only submit jobs to the \u2018gpu\u2019 partition that can actually benefit from GPUs. When submitting to the GPU partition the GPU type specification is required . GPU Type Ubelix currently features four types of GPUs. You have to choose an architecture and use the following --gres option to select it. Type lsf gres option Nvidia Geforce GTX 1080 Ti --gres=gpu:gtx1080ti:<number_of_gpus> Nvidia Geforce RTX 2080 Ti --gres=gpu:rtx2080ti:<number_of_gpus> Nvidia Geforce RTX 3090 --gres=gpu:rtx3090:<number_of_gpus> Nvidia Tesla P100 --gres=gpu:teslap100:<number_of_gpus> Job Submission Use the following options to submit a job to the gpu partition using the default job QoS: #SBATCH --partition=gpu #SBATCH --gres=gpu:<type>:<number_of_gpus> job_gpu_preempt For investors we provides investor partitions with specific QoS for each investor, defining the purchased resources. In case of GPU we want/need to provide instant access to purchased GPU resources. Nevertheless, to efficiently use all resources, the job_gpu_preemt exists in the gpu partition. Jobs, submitted with this QoS, may interrupted if resources are required for investors. Short jobs, and jobs with checkpointing benefit from these additional resources. For example requesting 4 RTX2080Ti #SBATCH --partition=gpu #SBATCH --qos=job_gpu_preempt #SBATCH --gres=gpu:rtx2080ti:4 Use the following option to ensure that the job, if preempted, won\u2019t be requeued but canceled instead: #SBATCH --no-requeue Application adaptation Applications do only ran on GPUs if they are build specifically for GPUs. There are multiple ways to implement algorithms for GPU usage. The most common ones are low level languages like CUDA or pragma oriented implementations like OpenACC. CUDA To build and run CUDA applications, its compiler and libraries are provided managed via modules. Run module avail to see which versions are available, for example: module avail CUDA ---- /software.el7/modulefiles/all ---- CUDA/8.0.61 cuDNN/7.1.4-CUDA-9.2.88 CUDA/9.0.176 cuDNN/7.6.0.64-gcccuda-2019a ( D ) CUDA/9.1.85 fosscuda/2019a CUDA/9.2.88 fosscuda/2019b ( D ) CUDA/10.1.105-GCC-8.2.0-2.31.1 gcccuda/2019a CUDA/10.1.243 ( D ) gcccuda/2019b ( D ) cuDNN/6.0-CUDA-8.0.61 OpenMPI/3.1.3-gcccuda-2019a cuDNN/7.0.5-CUDA-9.0.176 OpenMPI/3.1.4-gcccuda-2019b cuDNN/7.0.5-CUDA-9.1.85 Run module load <module> to load a specific version of CUDA: module load cuDNN/7.1.4-CUDA-9.2.88 If you need cuDNN you must load the cuDNN module. The appropriate CUDA version is then loaded automatically as a dependency. GPU usage monitoring To verify the usage of one or multiple GPUs the nvidia-smi tool can be utilized. The tool need to be launched on the related nodes. After the job started running, a new job step can be created using srun and call nvidia-smi to display the resource utilization. Here we attach the process to an job with the jobID 123456 . You need to replace the jobId with your gathered jobID, presented in the sbatch output. $ sbatch job.sh Submitted batch job 123456 $ squeue --me # verify that job gets started $ srun --ntasks-per-node = 1 --jobid 123456 nvidia-smi Fri Nov 11 11 :11:11 2021 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 495 .29.05 Driver Version: 495 .29.05 CUDA Version: 11 .5 | | -------------------------------+----------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | | | MIG M. | | =============================== + ====================== + ====================== | | 0 NVIDIA GeForce ... On | 00000000 :04:00.0 Off | N/A | | 23 % 25C P8 8W / 250W | 1MiB / 11178MiB | 0 % Default | | | | N/A | +-------------------------------+----------------------+----------------------+ | 1 NVIDIA GeForce ... On | 00000000 :08:00.0 Off | N/A | | 23 % 24C P8 8W / 250W | 1MiB / 11178MiB | 0 % Default | | | | N/A | +-------------------------------+----------------------+----------------------+ Therewith the GPU core utilization and memory usage can be displayed for all GPU cards belonging to that job. Note that this is a one off presentation of the usage and the called nvidia-smi command runs within your allocation. The required resources for this job step should be minimal and should not noticably influence your job performance. Further Information CUDA: https://developer.nvidia.com/cuda-zone CUDA C/C++ Basics: http://www.nvidia.com/docs/IO/116711/sc11-cuda-c-basics.pdf Nvidia Geforce GTX 1080 Ti: https://www.nvidia.com/en-us/geforce/products/10series/geforce-gtx-1080-ti Nvidia Geforce RTX 2080 Ti: https://www.nvidia.com/de-de/geforce/graphics-cards/rtx-2080-ti/ Nvidia Geforce RTX 3090: https://www.nvidia.com/de-de/geforce/graphics-cards/30-series/rtx-3090/ Nvidia Tesla P100: http://www.nvidia.com/object/tesla-p100.html","title":"GPUs"},{"location":"lsf/gpus.html#gpus","text":"","title":"GPUs"},{"location":"lsf/gpus.html#description","text":"This page contains all information you need to submit GPU-jobs successfully on Ubelix.","title":"Description"},{"location":"lsf/gpus.html#important-information-on-gpu-usage","text":"Code that runs on the CPU will not magically make use of GPUs by simply submitting a job to the \u2018gpu\u2019 partition! You have to explicitly adapt your code to run on the GPU, e.g. an CUDA or OpenACC implementation. Also, code that runs on a GPU will not necessarily run faster than it runs on the CPU. For example, GPUs require a huge amount of highly parallelizable tasks. In other words, you must understand the characteristics of your job, and make sure that you only submit jobs to the \u2018gpu\u2019 partition that can actually benefit from GPUs. When submitting to the GPU partition the GPU type specification is required .","title":"Important Information on GPU Usage"},{"location":"lsf/gpus.html#gpu-type","text":"Ubelix currently features four types of GPUs. You have to choose an architecture and use the following --gres option to select it. Type lsf gres option Nvidia Geforce GTX 1080 Ti --gres=gpu:gtx1080ti:<number_of_gpus> Nvidia Geforce RTX 2080 Ti --gres=gpu:rtx2080ti:<number_of_gpus> Nvidia Geforce RTX 3090 --gres=gpu:rtx3090:<number_of_gpus> Nvidia Tesla P100 --gres=gpu:teslap100:<number_of_gpus>","title":"GPU Type"},{"location":"lsf/gpus.html#job-submission","text":"Use the following options to submit a job to the gpu partition using the default job QoS: #SBATCH --partition=gpu #SBATCH --gres=gpu:<type>:<number_of_gpus>","title":"Job Submission"},{"location":"lsf/gpus.html#job_gpu_preempt","text":"For investors we provides investor partitions with specific QoS for each investor, defining the purchased resources. In case of GPU we want/need to provide instant access to purchased GPU resources. Nevertheless, to efficiently use all resources, the job_gpu_preemt exists in the gpu partition. Jobs, submitted with this QoS, may interrupted if resources are required for investors. Short jobs, and jobs with checkpointing benefit from these additional resources. For example requesting 4 RTX2080Ti #SBATCH --partition=gpu #SBATCH --qos=job_gpu_preempt #SBATCH --gres=gpu:rtx2080ti:4 Use the following option to ensure that the job, if preempted, won\u2019t be requeued but canceled instead: #SBATCH --no-requeue","title":"job_gpu_preempt"},{"location":"lsf/gpus.html#application-adaptation","text":"Applications do only ran on GPUs if they are build specifically for GPUs. There are multiple ways to implement algorithms for GPU usage. The most common ones are low level languages like CUDA or pragma oriented implementations like OpenACC.","title":"Application adaptation"},{"location":"lsf/gpus.html#cuda","text":"To build and run CUDA applications, its compiler and libraries are provided managed via modules. Run module avail to see which versions are available, for example: module avail CUDA ---- /software.el7/modulefiles/all ---- CUDA/8.0.61 cuDNN/7.1.4-CUDA-9.2.88 CUDA/9.0.176 cuDNN/7.6.0.64-gcccuda-2019a ( D ) CUDA/9.1.85 fosscuda/2019a CUDA/9.2.88 fosscuda/2019b ( D ) CUDA/10.1.105-GCC-8.2.0-2.31.1 gcccuda/2019a CUDA/10.1.243 ( D ) gcccuda/2019b ( D ) cuDNN/6.0-CUDA-8.0.61 OpenMPI/3.1.3-gcccuda-2019a cuDNN/7.0.5-CUDA-9.0.176 OpenMPI/3.1.4-gcccuda-2019b cuDNN/7.0.5-CUDA-9.1.85 Run module load <module> to load a specific version of CUDA: module load cuDNN/7.1.4-CUDA-9.2.88 If you need cuDNN you must load the cuDNN module. The appropriate CUDA version is then loaded automatically as a dependency.","title":"CUDA"},{"location":"lsf/gpus.html#gpu-usage-monitoring","text":"To verify the usage of one or multiple GPUs the nvidia-smi tool can be utilized. The tool need to be launched on the related nodes. After the job started running, a new job step can be created using srun and call nvidia-smi to display the resource utilization. Here we attach the process to an job with the jobID 123456 . You need to replace the jobId with your gathered jobID, presented in the sbatch output. $ sbatch job.sh Submitted batch job 123456 $ squeue --me # verify that job gets started $ srun --ntasks-per-node = 1 --jobid 123456 nvidia-smi Fri Nov 11 11 :11:11 2021 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 495 .29.05 Driver Version: 495 .29.05 CUDA Version: 11 .5 | | -------------------------------+----------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | | | MIG M. | | =============================== + ====================== + ====================== | | 0 NVIDIA GeForce ... On | 00000000 :04:00.0 Off | N/A | | 23 % 25C P8 8W / 250W | 1MiB / 11178MiB | 0 % Default | | | | N/A | +-------------------------------+----------------------+----------------------+ | 1 NVIDIA GeForce ... On | 00000000 :08:00.0 Off | N/A | | 23 % 24C P8 8W / 250W | 1MiB / 11178MiB | 0 % Default | | | | N/A | +-------------------------------+----------------------+----------------------+ Therewith the GPU core utilization and memory usage can be displayed for all GPU cards belonging to that job. Note that this is a one off presentation of the usage and the called nvidia-smi command runs within your allocation. The required resources for this job step should be minimal and should not noticably influence your job performance.","title":"GPU usage monitoring"},{"location":"lsf/gpus.html#further-information","text":"CUDA: https://developer.nvidia.com/cuda-zone CUDA C/C++ Basics: http://www.nvidia.com/docs/IO/116711/sc11-cuda-c-basics.pdf Nvidia Geforce GTX 1080 Ti: https://www.nvidia.com/en-us/geforce/products/10series/geforce-gtx-1080-ti Nvidia Geforce RTX 2080 Ti: https://www.nvidia.com/de-de/geforce/graphics-cards/rtx-2080-ti/ Nvidia Geforce RTX 3090: https://www.nvidia.com/de-de/geforce/graphics-cards/30-series/rtx-3090/ Nvidia Tesla P100: http://www.nvidia.com/object/tesla-p100.html","title":"Further Information"},{"location":"lsf/interactive-jobs.html","text":"Interactive Jobs Description This page describes how to request resources for interactive jobs and how to use the allocated resources when working interactively. There are various use cases for requesting interactive resources, e.g. debugging: launching a job, tweaking the setup (e.g. compile options), launching job again, tweaking, \u2026 interactive interfaces: inspecting a node, or when launching a GUI In general there are 3 major ways to allocate resources: sbatch : submitting a script which gets scheduled and launched when resources are available, after submitting the shell is coming back immediately srun : submitting a single task (no serial preparation or post-processes required), output on screen shell is blocked until job finished salloc : requesting resources but no specification of tasks. requested resources will be blocked until job gets killed/canceled shell block until job starts srun command launches task on these resources salloc salloc creates a lsf job allocation with the specified (of default) resources, including CPUs/GPUs, memory, walltime. Here 4 tasks on 1 node with 2GB (8GB total) and 1h is requested from submit01 bash-4.2$ hostname submit01.ubelix.unibe.ch bash-4.2$ salloc --nodes = 1 --ntasks-per-node = 4 --mem-per-cpu = 2G --time = 01 :00:00 salloc: Pending job allocation 63752579 salloc: job 63752579 queued and waiting for resources salloc: job 63752579 has been allocated resources salloc: Granted job allocation 63752579 bash-4.2$ hostname submit01.ubelix.unibe.ch bash-4.2$ srun hostname bnode007 After submitting the salloc command the terminal will be blocked until the job gets granted. Then the session still persists on the login node submit01 . Only when using srun commands are executed on the requested compute node. The task send with srun can run immediately, since the resources are allocated already. ! type Attention \u201cquit session\u201d Please release resources immediately if not needed anymore, by using exit , Ctrl-d or scancel $lsf_JOB_ID Interactive shell session An interactive shell session on a compute node can be established using bash-4.2$ srun --pty bash srun: job 9173384 queued and waiting for resources srun: job 9173384 has been allocated resources bash-4.2$ hostname bnode026 The command is blocking until the resources are granted. The session then is established directly on the first compute node. Graphical Interfaces using X11 Forwarding Requirements: You must login to UBELIX with X11 forwarding enabled: ssh -Y <username>@submit.unibe.ch . Make this the default with ForwardX11 yes in ~/.ssh/config . Password-less communication between all nodes within UBELIX. In order to make this possible, generate a new SSH key (without passphrase) on the login node (submit) and add the public key to ~/.ssh/authorized_keys : ssh-keygen -t rsa -b 4096 cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys A X-Server on your local workstation, e.g. MAC: Xquartz (X11 no longer included in macOS) Windows: MobaXTerm or Xming DO NOT reuse an existing SSH key for this purpose, i.e. do not copy an existing private key from your local machine to UBELIX. With all the requirements in place can now submit an interactive job and export an X11 display on the allocated compute node, e.g: srun -n 1 --x11 gnuplot ex_gnuplot.p You can also use X11 forwarding with non interactive jobs adding the option #SBATCH --x11 in your job script and using again srun --x11 to launch your application.","title":"Running Interactive Jobs"},{"location":"lsf/interactive-jobs.html#interactive-jobs","text":"","title":"Interactive Jobs"},{"location":"lsf/interactive-jobs.html#description","text":"This page describes how to request resources for interactive jobs and how to use the allocated resources when working interactively. There are various use cases for requesting interactive resources, e.g. debugging: launching a job, tweaking the setup (e.g. compile options), launching job again, tweaking, \u2026 interactive interfaces: inspecting a node, or when launching a GUI In general there are 3 major ways to allocate resources: sbatch : submitting a script which gets scheduled and launched when resources are available, after submitting the shell is coming back immediately srun : submitting a single task (no serial preparation or post-processes required), output on screen shell is blocked until job finished salloc : requesting resources but no specification of tasks. requested resources will be blocked until job gets killed/canceled shell block until job starts srun command launches task on these resources","title":"Description"},{"location":"lsf/interactive-jobs.html#salloc","text":"salloc creates a lsf job allocation with the specified (of default) resources, including CPUs/GPUs, memory, walltime. Here 4 tasks on 1 node with 2GB (8GB total) and 1h is requested from submit01 bash-4.2$ hostname submit01.ubelix.unibe.ch bash-4.2$ salloc --nodes = 1 --ntasks-per-node = 4 --mem-per-cpu = 2G --time = 01 :00:00 salloc: Pending job allocation 63752579 salloc: job 63752579 queued and waiting for resources salloc: job 63752579 has been allocated resources salloc: Granted job allocation 63752579 bash-4.2$ hostname submit01.ubelix.unibe.ch bash-4.2$ srun hostname bnode007 After submitting the salloc command the terminal will be blocked until the job gets granted. Then the session still persists on the login node submit01 . Only when using srun commands are executed on the requested compute node. The task send with srun can run immediately, since the resources are allocated already. ! type Attention \u201cquit session\u201d Please release resources immediately if not needed anymore, by using exit , Ctrl-d or scancel $lsf_JOB_ID","title":"salloc"},{"location":"lsf/interactive-jobs.html#interactive-shell-session","text":"An interactive shell session on a compute node can be established using bash-4.2$ srun --pty bash srun: job 9173384 queued and waiting for resources srun: job 9173384 has been allocated resources bash-4.2$ hostname bnode026 The command is blocking until the resources are granted. The session then is established directly on the first compute node.","title":"Interactive shell session"},{"location":"lsf/interactive-jobs.html#graphical-interfaces-using-x11-forwarding","text":"Requirements: You must login to UBELIX with X11 forwarding enabled: ssh -Y <username>@submit.unibe.ch . Make this the default with ForwardX11 yes in ~/.ssh/config . Password-less communication between all nodes within UBELIX. In order to make this possible, generate a new SSH key (without passphrase) on the login node (submit) and add the public key to ~/.ssh/authorized_keys : ssh-keygen -t rsa -b 4096 cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys A X-Server on your local workstation, e.g. MAC: Xquartz (X11 no longer included in macOS) Windows: MobaXTerm or Xming DO NOT reuse an existing SSH key for this purpose, i.e. do not copy an existing private key from your local machine to UBELIX. With all the requirements in place can now submit an interactive job and export an X11 display on the allocated compute node, e.g: srun -n 1 --x11 gnuplot ex_gnuplot.p You can also use X11 forwarding with non interactive jobs adding the option #SBATCH --x11 in your job script and using again srun --x11 to launch your application.","title":"Graphical Interfaces using X11 Forwarding"},{"location":"lsf/investigating-job-failure.html","text":"Investigating a Job Failure Description Not always jobs execute successfully. There are a list of reasons jobs or applications stop or crash. The most common causes are: exceeding resource limits and software-specific errors Here, discussed are ways to gather information, aspects of avoiding misleading information and aspects of common issues. It is important to collect error/output messages either by writing such information to the default location or by specifying specific locations using the --error / --output option. Do not redirect the error/output stream to /dev/null unless you know what you are doing. Error and output messages are the starting point for investigating a job failure. Exceeding Resource Limits Each partition defines maximum and default limits for runtime and memory usage. Within the job specification the current limits can be defined within the ranges. For better scheduling, the job requirements should be estimated and the limits should be adapted to the needs. The lower the limits the better lsf can find a spot. Furthermore, the less resource overhead is specified the less resources are wasted, e.g. for memory. If a job exceeds the runtime or memory limit, it will get killed by lsf. Error Information In both cases, the error file provides appropriate information: Time limit: ( ... ) lsfstepd: error: *** JOB 41239 ON fnode01 CANCELLED AT 2016 -11-30T11:22:57 DUE TO TIME LIMIT *** ( ... ) `````` Memory limit: ``` Bash ( ... ) lsfstepd: error: Job 41176 exceeded memory limit ( 3940736 > 2068480 ) , being killed lsfstepd: error: Exceeded job memory limit lsfstepd: error: *** JOB 41176 ON fnode01 CANCELLED AT 2016 -11-30T10:21:37 *** ( ... ) Software Errors The exit code of a job is captured by lsf and saved as part of the job record. For sbatch jobs the exit code of the batch script is captured. For srun, the exit code will be the return value of the executed command. Any non-zero exit code is considered a job failure, and results in job state of FAILED. When a signal was responsible for a job/step termination, the signal number will also be captured, and displayed after the exit code (separated by a colon). Depending on the execution order of the commands in the batch script, it is possible that a specific command fails but the batch script will return zero indicating success. Consider the following simplified example: fail.R var<-sq ( 1 ,1000000000 ) job.sbatch #!/bin/bash # lsf options #SBATCH --mail-user=mustermann@unibe.ch #SBATCH --mail-type=begin,end,fail #SBATCH --job-name=\"Simple Example\" #SBATCH --time=00:05:00 #SBATCH --mem-per-cpu=2G # Put your code below this line R CMD BATCH --vanilla fail.R echo \"Script finished\" The exit code and state wrongly indicates that the job finished successfully: $ sbatch job_lsf.sh Submitted batch job 41585 $ sacct -j 41585 JobID JobName Partition Account AllocCPUS State ExitCode ------------ ---------- ---------- ---------- ---------- ---------- -------- 41585 Simple E + all id 1 COMPLETED 0 :0 41585 .batch batch id 1 COMPLETED 0 :0 Only the R-specific output file shows the error: fail.Rout ( ... ) > var<-sq ( 1 ,1000000000 ) Error: could not find function \"sq\" Execution halted You can bypass this problem by exiting with a proper exit code as soon as the command failed: jobsbatch #!/bin/bash # lsf options #SBATCH --mail-user=nico.faerber@id.unibe.ch #SBATCH --mail-type=begin,end,fail #SBATCH --job-name=\"Simple Example\" #SBATCH --time=00:05:00 #SBATCH --mem-per-cpu=2G # Put your code below this line R CMD BATCH --vanilla fail.R || exit 91 echo \"Script finished\" Now, the exit code and state matches the true outcome: $ sbatch job_lsf.sh Submitted batch job 41925 $ sacct -j 41925 JobID JobName Partition Account AllocCPUS State ExitCode ------------ ---------- ---------- ---------- ---------- ---------- -------- 41925 Simple E + all id 1 FAILED 91 :0 41925 .batch batch id 1 FAILED 91 :0 Always check application-specifc output files for error messages.","title":"Investigating a Job Failure"},{"location":"lsf/investigating-job-failure.html#investigating-a-job-failure","text":"","title":"Investigating a Job Failure"},{"location":"lsf/investigating-job-failure.html#description","text":"Not always jobs execute successfully. There are a list of reasons jobs or applications stop or crash. The most common causes are: exceeding resource limits and software-specific errors Here, discussed are ways to gather information, aspects of avoiding misleading information and aspects of common issues. It is important to collect error/output messages either by writing such information to the default location or by specifying specific locations using the --error / --output option. Do not redirect the error/output stream to /dev/null unless you know what you are doing. Error and output messages are the starting point for investigating a job failure.","title":"Description"},{"location":"lsf/investigating-job-failure.html#exceeding-resource-limits","text":"Each partition defines maximum and default limits for runtime and memory usage. Within the job specification the current limits can be defined within the ranges. For better scheduling, the job requirements should be estimated and the limits should be adapted to the needs. The lower the limits the better lsf can find a spot. Furthermore, the less resource overhead is specified the less resources are wasted, e.g. for memory. If a job exceeds the runtime or memory limit, it will get killed by lsf.","title":"Exceeding Resource Limits"},{"location":"lsf/investigating-job-failure.html#error-information","text":"In both cases, the error file provides appropriate information: Time limit: ( ... ) lsfstepd: error: *** JOB 41239 ON fnode01 CANCELLED AT 2016 -11-30T11:22:57 DUE TO TIME LIMIT *** ( ... ) `````` Memory limit: ``` Bash ( ... ) lsfstepd: error: Job 41176 exceeded memory limit ( 3940736 > 2068480 ) , being killed lsfstepd: error: Exceeded job memory limit lsfstepd: error: *** JOB 41176 ON fnode01 CANCELLED AT 2016 -11-30T10:21:37 *** ( ... )","title":"Error Information"},{"location":"lsf/investigating-job-failure.html#software-errors","text":"The exit code of a job is captured by lsf and saved as part of the job record. For sbatch jobs the exit code of the batch script is captured. For srun, the exit code will be the return value of the executed command. Any non-zero exit code is considered a job failure, and results in job state of FAILED. When a signal was responsible for a job/step termination, the signal number will also be captured, and displayed after the exit code (separated by a colon). Depending on the execution order of the commands in the batch script, it is possible that a specific command fails but the batch script will return zero indicating success. Consider the following simplified example: fail.R var<-sq ( 1 ,1000000000 ) job.sbatch #!/bin/bash # lsf options #SBATCH --mail-user=mustermann@unibe.ch #SBATCH --mail-type=begin,end,fail #SBATCH --job-name=\"Simple Example\" #SBATCH --time=00:05:00 #SBATCH --mem-per-cpu=2G # Put your code below this line R CMD BATCH --vanilla fail.R echo \"Script finished\" The exit code and state wrongly indicates that the job finished successfully: $ sbatch job_lsf.sh Submitted batch job 41585 $ sacct -j 41585 JobID JobName Partition Account AllocCPUS State ExitCode ------------ ---------- ---------- ---------- ---------- ---------- -------- 41585 Simple E + all id 1 COMPLETED 0 :0 41585 .batch batch id 1 COMPLETED 0 :0 Only the R-specific output file shows the error: fail.Rout ( ... ) > var<-sq ( 1 ,1000000000 ) Error: could not find function \"sq\" Execution halted You can bypass this problem by exiting with a proper exit code as soon as the command failed: jobsbatch #!/bin/bash # lsf options #SBATCH --mail-user=nico.faerber@id.unibe.ch #SBATCH --mail-type=begin,end,fail #SBATCH --job-name=\"Simple Example\" #SBATCH --time=00:05:00 #SBATCH --mem-per-cpu=2G # Put your code below this line R CMD BATCH --vanilla fail.R || exit 91 echo \"Script finished\" Now, the exit code and state matches the true outcome: $ sbatch job_lsf.sh Submitted batch job 41925 $ sacct -j 41925 JobID JobName Partition Account AllocCPUS State ExitCode ------------ ---------- ---------- ---------- ---------- ---------- -------- 41925 Simple E + all id 1 FAILED 91 :0 41925 .batch batch id 1 FAILED 91 :0 Always check application-specifc output files for error messages.","title":"Software Errors"},{"location":"lsf/lsf-glossary.html","text":"Glossary of terms important to LSF and Job Scheduling Job A piece of work that a user requests of a computer. A job consists of one or more tasks, which may be run sequentially, in parallel, or a mix of both. Wall time def Scheduler A piece of software that runs on a shared cluster. Its role is to determine in what order queued jobs should run. GPU def GPU Job def CPU Job def Parallel Job def Interactive job def Batch (array) job def CPU def Queue def SLAs def","title":"LSF Glossary"},{"location":"lsf/lsf-glossary.html#glossary-of-terms-important-to-lsf-and-job-scheduling","text":"Job A piece of work that a user requests of a computer. A job consists of one or more tasks, which may be run sequentially, in parallel, or a mix of both. Wall time def Scheduler A piece of software that runs on a shared cluster. Its role is to determine in what order queued jobs should run. GPU def GPU Job def CPU Job def Parallel Job def Interactive job def Batch (array) job def CPU def Queue def SLAs def","title":"Glossary of terms important to LSF and Job Scheduling"},{"location":"lsf/monitoring-jobs.html","text":"Monitoring Jobs Description This page provides information about monitoring user jobs. Different lsf commands provide information about jobs/job steps on different levels. The command squeue provides high-level information about jobs in the lsf scheduling queue (state information, allocated resources, runtime, \u2026). The command sstat provides detailed usage information about running jobs, and sacct provides accounting information about active and completed (past) jobs. The command scontrol provides even more detailed information about jobs and job steps. The output format of most commands is highly configurable to your needs. Look for the \u2013format or \u2013Format options. Most command options support a short form as well as a long form (e.g. -u , and \u2013user= ). Because few options only support the long form, we will consistently use the long form throughout this documentation. squeue Use the squeue command to get a high-level overview of all active (running and pending) jobs in the cluster. Syntax squeue [ options ] Common options --user = <user [ ,user [ ,... ]] > Request jobs from a comma separated list of users. --jobs = <job_id [ ,job_id [ ,... ]] > Request specific jobs to be displayed --partition = <part [ ,part [ ,... ]] > Request jobs to be displayed from a comma separated list of partitions --states = <state [ ,state [ ,... ]] > Display jobs in specific states. Comma separated list or \"all\" . Default: \"PD,R,CG\" The default output format is as follows: JOBID PARTITION NAME USER ST TIME NODES NODELIST ( REASON ) where JOBID Job or step ID. For array jobs, the job ID format will be of the form <job_id>_<index> PARTITION Partition of the job/step NAME Name of the job/step USER Owner of the job/step ST State of the job/step. See below for a description of the most common states TIME Time used by the job/step. Format is days-hours:minutes:seconds ( days,hours only printed as needed ) NODES Number of nodes allocated to the job or the minimum amount of nodes required by a pending job NODELIST ( REASON ) For pending jobs: Reason why pending. For failed jobs: Reason why failed. For all other job states: List of allocated nodes. See below for a list of the most common reason codes You can easily tailor the output format of squeue to your own needs. Use the \u2013format (-o) or \u2013Format (-O) options to request a comma separated list of job information to be displayed. See the man page for more information: man squeue Job States During its lifetime, a job passes through several states. The most common states are PENDING, RUNNING, SUSPENDED, COMPLETING, and COMPLETED. PD Pending. Job is waiting for resource allocation R Running. Job has an allocation and is running S Suspended. Execution has been suspended and resources have been released for other jobs CA Cancelled. Job was explicitly cancelled by the user or the system administrator CG Completing. Job is in the process of completing. Some processes on some nodes may still be active CD Completed. Job has terminated all processes on all nodes with an exit code of zero F Failed. Job has terminated with non-zero exit code or other failure condition Why is my job still pending? The REASON column of the squeue output gives you a hint why your job is not running. (Resources) The job is waiting for resources to become available so that the jobs resource request can be fulfilled. (Priority) The job is not allowed to run because at least one higher prioritized job is waiting for resources. (Dependency) The job is waiting for another job to finish first (\u2013dependency=\u2026 option). (DependencyNeverSatisfied) The job is waiting for a dependency that can never be satisfied. Such a job will remain pending forever. Please cancel such jobs. (QOSMaxCpuPerUserLimit) The job is not allowed to start because your currently running jobs consume all allowed CPU resources for your user in a specific partition. Wait for jobs to finish. (AssocGrpCpuLimit) dito. (AssocGrpJobsLimit) The job is not allowed to start because you have reached the maximum of allowed running jobs for your user in a specific partition. Wait for jobs to finish. (ReqNodeNotAvail, UnavailableNodes:\u2026) Some node required by the job is currently not available. The node may currently be in use, reserved for another job, in an advanced reservation, DOWN, DRAINED, or not responding. Most probably there is an active reservation for all nodes due to an upcoming maintenance downtime and your job is not able to finish before the start of the downtime. Another reason why you should specify the duration of a job (\u2013time) as accurately as possible. Your job will start after the downtime has finished. You can list all active reservations using scontrol show reservation . Why can\u2019t I submit further jobs? sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user\u2019s size and/or time limits) \u2026 means that you have reached the maximum of allowed jobs to be submitted to a specific partition. Examples List all currently running jobs of user foo: squeue --user = foo --states = PD,R List all currently running jobs of user foo in partition bar : squeue --user = foo --partition = bar --states = R scontrol Use the scontrol command to show more detailed information about a job Syntax scontrol [ options ] [ command ] Examples Show detailed information about job with ID 500: scontrol show jobid 500 Show even more detailed information about job with ID 500 (including the jobscript): scontrol -dd show jobid 500 sacct Use the sacct command to query information about past jobs Syntax sacct [ options ] Common options --endtime = end_time Select jobs in any state before the specified time. --starttime = start_time Select jobs in any state after the specified time. --state = state [ ,state [ ,... ]] Select jobs based on their state during the time period given. By default, the start and end time will be the current time when the --state option is specified, and hence only currently running jobs will be displayed.","title":"Monitoring Jobs"},{"location":"lsf/monitoring-jobs.html#monitoring-jobs","text":"","title":"Monitoring Jobs"},{"location":"lsf/monitoring-jobs.html#description","text":"This page provides information about monitoring user jobs. Different lsf commands provide information about jobs/job steps on different levels. The command squeue provides high-level information about jobs in the lsf scheduling queue (state information, allocated resources, runtime, \u2026). The command sstat provides detailed usage information about running jobs, and sacct provides accounting information about active and completed (past) jobs. The command scontrol provides even more detailed information about jobs and job steps. The output format of most commands is highly configurable to your needs. Look for the \u2013format or \u2013Format options. Most command options support a short form as well as a long form (e.g. -u , and \u2013user= ). Because few options only support the long form, we will consistently use the long form throughout this documentation.","title":"Description"},{"location":"lsf/monitoring-jobs.html#squeue","text":"Use the squeue command to get a high-level overview of all active (running and pending) jobs in the cluster. Syntax squeue [ options ] Common options --user = <user [ ,user [ ,... ]] > Request jobs from a comma separated list of users. --jobs = <job_id [ ,job_id [ ,... ]] > Request specific jobs to be displayed --partition = <part [ ,part [ ,... ]] > Request jobs to be displayed from a comma separated list of partitions --states = <state [ ,state [ ,... ]] > Display jobs in specific states. Comma separated list or \"all\" . Default: \"PD,R,CG\" The default output format is as follows: JOBID PARTITION NAME USER ST TIME NODES NODELIST ( REASON ) where JOBID Job or step ID. For array jobs, the job ID format will be of the form <job_id>_<index> PARTITION Partition of the job/step NAME Name of the job/step USER Owner of the job/step ST State of the job/step. See below for a description of the most common states TIME Time used by the job/step. Format is days-hours:minutes:seconds ( days,hours only printed as needed ) NODES Number of nodes allocated to the job or the minimum amount of nodes required by a pending job NODELIST ( REASON ) For pending jobs: Reason why pending. For failed jobs: Reason why failed. For all other job states: List of allocated nodes. See below for a list of the most common reason codes You can easily tailor the output format of squeue to your own needs. Use the \u2013format (-o) or \u2013Format (-O) options to request a comma separated list of job information to be displayed. See the man page for more information: man squeue","title":"squeue"},{"location":"lsf/monitoring-jobs.html#job-states","text":"During its lifetime, a job passes through several states. The most common states are PENDING, RUNNING, SUSPENDED, COMPLETING, and COMPLETED. PD Pending. Job is waiting for resource allocation R Running. Job has an allocation and is running S Suspended. Execution has been suspended and resources have been released for other jobs CA Cancelled. Job was explicitly cancelled by the user or the system administrator CG Completing. Job is in the process of completing. Some processes on some nodes may still be active CD Completed. Job has terminated all processes on all nodes with an exit code of zero F Failed. Job has terminated with non-zero exit code or other failure condition","title":"Job States"},{"location":"lsf/monitoring-jobs.html#why-is-my-job-still-pending","text":"The REASON column of the squeue output gives you a hint why your job is not running. (Resources) The job is waiting for resources to become available so that the jobs resource request can be fulfilled. (Priority) The job is not allowed to run because at least one higher prioritized job is waiting for resources. (Dependency) The job is waiting for another job to finish first (\u2013dependency=\u2026 option). (DependencyNeverSatisfied) The job is waiting for a dependency that can never be satisfied. Such a job will remain pending forever. Please cancel such jobs. (QOSMaxCpuPerUserLimit) The job is not allowed to start because your currently running jobs consume all allowed CPU resources for your user in a specific partition. Wait for jobs to finish. (AssocGrpCpuLimit) dito. (AssocGrpJobsLimit) The job is not allowed to start because you have reached the maximum of allowed running jobs for your user in a specific partition. Wait for jobs to finish. (ReqNodeNotAvail, UnavailableNodes:\u2026) Some node required by the job is currently not available. The node may currently be in use, reserved for another job, in an advanced reservation, DOWN, DRAINED, or not responding. Most probably there is an active reservation for all nodes due to an upcoming maintenance downtime and your job is not able to finish before the start of the downtime. Another reason why you should specify the duration of a job (\u2013time) as accurately as possible. Your job will start after the downtime has finished. You can list all active reservations using scontrol show reservation .","title":"Why is my job still pending?"},{"location":"lsf/monitoring-jobs.html#why-cant-i-submit-further-jobs","text":"sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user\u2019s size and/or time limits) \u2026 means that you have reached the maximum of allowed jobs to be submitted to a specific partition.","title":"Why can't I submit further jobs?"},{"location":"lsf/monitoring-jobs.html#examples","text":"List all currently running jobs of user foo: squeue --user = foo --states = PD,R List all currently running jobs of user foo in partition bar : squeue --user = foo --partition = bar --states = R","title":"Examples"},{"location":"lsf/monitoring-jobs.html#scontrol","text":"Use the scontrol command to show more detailed information about a job Syntax scontrol [ options ] [ command ]","title":"scontrol"},{"location":"lsf/monitoring-jobs.html#examples_1","text":"Show detailed information about job with ID 500: scontrol show jobid 500 Show even more detailed information about job with ID 500 (including the jobscript): scontrol -dd show jobid 500","title":"Examples"},{"location":"lsf/monitoring-jobs.html#sacct","text":"Use the sacct command to query information about past jobs Syntax sacct [ options ] Common options --endtime = end_time Select jobs in any state before the specified time. --starttime = start_time Select jobs in any state after the specified time. --state = state [ ,state [ ,... ]] Select jobs based on their state during the time period given. By default, the start and end time will be the current time when the --state option is specified, and hence only currently running jobs will be displayed.","title":"sacct"},{"location":"lsf/submission.html","text":"Job Submission high level overview of how to submit a job especially for new users How to submit a job Batch scripts Job submission Checking the job What is LSF? On an HPC cluster, the scheduler manages which jobs run where and when. On our clusters, you control your jobs using a job scheduling system called IBM Spectrum Scale LSF that allocates and manages compute resources for you. A cluster 1 is a set of connected computers that work together to solve computational tasks (user jobs) and presents itself to the user as a single system. For the resources of a cluster (e.g. CPUs, GPUs, memory) to be used efficiently, a resource manager (also called workload manager or batch-queuing system) is vital; the resource manager of choice on our clusters is called IBM Spectrum Scale LSF . After submitting a job to the cluster, LSF will try to fulfill the job\u2019s resource request by allocating resources to the job. If the requested resources are already available, the job can start immediately. Otherwise, the start of the job is delayed (pending) until enough resources are available. By accurately requesting the resources you need, you can have your jobs execute as quickly as possible on nodes available to process them. LSF also allows you to monitor active jobs and to retrieve statistics about finished jobs. This page describes the job submission process with LSF. Basics of job submission using LSF The bsub command submits jobs to LSF It consists of two parts: resource requests and job steps. A resource request consists of the number of CPU cores, amount of memory per CPU core, wall time (expected duration), GPUs etc. You can find complete lists of the available resources on the cluster pages lilac and juno. Job steps specify tasks which must be done, software which must be run, etc. Upon submission, the job will advance in the queue until the requested resources are available. At this point LSF will allocate the requested CPU cores, GPUs, and memory, and execute it. You can submit your jobs in one of two ways. For testing and small jobs you may want to run a job interactively . This way you can directly interact with the compute node(s) in real time. However, the preferred way for multiple jobs or long-running jobs is to put all of your resource requests and executable into the command line or combining them into a bsub script and submitting that to the job scheduler. Resource Allocation / Requesting Resources Every job submission starts with a resource request. The typical resources that must be included are included in the table below: The usual procedure is to combine resource requests and task execution (job steps) in a single batch script (job script) and then submit the script using the bsub command. | Item | Memory | Wall Time | ------- ------- ----------- |Description| |Example| The Most command options support a short form as well as a long form (e.g. -u <username> , and --user=<username> ). Because few options only support the long form, we will consistently use the long form throughout this documentation. Some options have default values if not specified: The --time option has partition-specific default values (see scontrol show partition <partname> ). The --mem-per-cpu option has a global default value of 2048MB. The default partition is epyc2 . To select another partition one must use the --partition option, e.g. --partition=gpu . sbatch The sbatch command is used to submit a job script for later execution. It is the most common way to submit a job to the cluster due to its reusability. lsf options are usually embedded in a job script prefixed by #SBATCH directives. lsf options specified as command line options overwrite corresponding options embedded in the job script Syntax sbatch [ options ] script [ args... ] Simple Example Batch sbmission script, jobs.sh : #!/bin/bash #SBATCH --job-name=\"First example\" #SBATCH --time=00:10:00 #SBATCH --mem-per-cpu=1G # Your code below this line module load Python srun python3 script.py Submit the job script: sbatch job.sh Submitted batch job 30215045 See below for more examples Job Script Usually a job script consists of two parts. The first part is optional but highly recommended: lsf-specific options used by the scheduler to manage the resources (e.g. memory) and configure the job environment Job-specific shell commands The job script acts as a wrapper for your actual job. Command-line options can still be used to overwrite embedded options. Although you can specify all lsf options on the command-line, we encourage you, for clarity and reusability, to embed lsf options in the job script Options Option Description Example --job-name Specify a job name --job-name=\"Simple Matlab\" --time Expected runtime of the job. Format: dd-hh:mm:ss --time=12:00:00 --time=2-06:00:00 --ntasks Number of tasks (processes). Used for MPI jobs that may run distributed on multiple compute nodes --ntasks=4 --nodes Request a certain number of nodes --nodes=2 --ntasks-per-node Specifies how many tasks will run on each allocated node. Meant to be used with --nodes . If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. --ntasks-per-node=2 --cpus-per-task Number of CPUs per task (threads). Used for shared memory jobs that run locally on a single compute node. Default is 1 --cpus-per-task=4 --mem-per-cpu Minimum memory required per allocated CPU in megabytes. Different units can be specified using the suffix [K|M|G]. Default 2048 MB --mem-per-cpu=2G --output Redirect standard output . All directories specified in the path must exist before the job starts! By default stderr and stdout are merged into a file lsf-%j.out , where %j is the job allocation number. --output=myCal_%j.out --error Redirect standard error . All directories specified in the path must exist before the job starts! By default stderr and stdout are merged into a file lsf-%j.out , where %j is the job allocation number. --output=myCal_%j.err --partition Select a different partition with different hardware. See Partition/QoS page . Default: epyc2 --partition=bdw --partition=gpu --qos Specify \u201cQuality of Service\u201d. This can be used to change job limits, e.g. for long jobs or short jobs with large resources. See Partition/QoS page --tmp Specify the amount of disk space that must be available on the compute node(s). The local scratch space for the job is referenced by the variable $TMPDIR . Default units are megabytes. Different units can be specified using the suffix [K|M|G|T]. --tmp=8G --mail-user Mail address to contact job owner. Must be a valid email address, if used! --mail-user=foo.bar@unibe.ch --mail-type When to notify a job owner: none , all , begin , end , fail , requeue , array_tasks --mail-type=end,fail --array Submit an array job. Specify the used indices and use \u201c%\u201d to specify the max number of tasks allowed to run concurrently. --array=1,4,16-32:4 --array=1-100%20 --chdir Set the working directory of the batch script to directory before it is executed. The path can be specified as full path or relative path to the directory where the command is executed. Environment variables are not supported. --chdir=subdir1 --dependency Defer the start of this job until the specified dependencies have been satisfied. See man sbatch for a description of all valid dependency types --dependency=afterok:11908 --immediate Only submit the job if all requested resources are immediately available --exclusive Use the compute node(s) exclusively, i.e. do not share nodes with other jobs. CAUTION: Only use this option if you are an experienced user, and you really understand the implications of this feature. If used improperly, the use of this option can lead to a massive waste of computational resources --test-only Validate the batch script and return the estimated start time considering the current cluster state --account Specifies account to charge. Please use Workspace module to select Workspace account. Regular users don\u2019t need to specify this option. command to allocate resources The salloc command is used to allocate resources (e.g. nodes), possibly with a set of constraints (e.g. number of processor per node) for later utilization. It is typically used to allocate resources and spawn a shell, in which the srun command is used to launch parallel tasks. Syntax salloc [ options ] [ <command> [ args... ]] Example bash$ salloc -N 2 -t 10 salloc: Granted job allocation 247 bash$ module load foss bash$ srun ./mpi_hello_world Hello, World. I am 1 of 2 running on knlnode03.ubelix.unibe.ch Hello, World. I am 0 of 2 running on knlnode02.ubelix.unibe.ch bash$ exit salloc: Relinquishing job allocation 247 srun The srun command creates job steps. One or multiple srun invocations are usually used from within an existing resource allocation. Thereby, a job step can utilize all resources allocated to the job, or utilize only a subset of the resource allocation. Multiple job steps can run sequentially in the order defined in the batch script or run in parallel, but can together never utilize more resources than provided by the allocation. Do not submit a job script using srun . Embedded lsf options ( #SBATCH ) are not parsed by srun . Syntax srun [options] executable [args...] When do I use srun in my job script? Use srun in your job script for all main executables, especially if these are: MPI applications multiple job tasks (serial or parallel jobs) simultaneously within an allocation Example Run MPI task: #!/bin/bash #SBATCH --job-name=\"Open MPI example\" #SBATCH --nodes=2 #SBATCH --ntasks-per-node=20 #SBATCH --mem-per-cpu=2G #SBATCH --time=06:00:00 # Your code below this line module load foss srun ./mpi_app.exe Run two jobs simultaneously: #!/bin/bash #SBATCH --job-name=\"Open MPI example\" #SBATCH --ntasks=2 #SBATCH --cpus-per-task=4 # Your code below this line # run 2 threaded applications side-by-side srun --tasks = 1 --cpus-per-task = 4 ./app1 inp1.dat & srun --tasks = 1 --cpus-per-task = 4 ./app2 inp2.dat & wait # wait: Wait for both background commands to finish. This is important when running bash commands in the background (using &)! Otherwise, the job ends immediately. Please run series of similar tasks as job array. See Array Jobs Requesting a Partition / QoS (Queue) Per default jobs are submitted to the epyc2 partition and the default QoS job_epyc2 . The partition option can be used to request different hardware, e.b. gpu partition. And the QoS can be used to run in a specific queue, e.g. job_gpu_debug : #SBATCH --partition=gpu --qos=job_gpu_debug See Partitions / QoS for a list of available partitions and QoS and its specifications. Accounts By default a user has a \u201cprivate\u201d account. When belonging to a Workspace your private account gets deactivated and you can submit with the Workspace account. We strongly suggest to use the Workspace module ( module load Workspace ), which automatically sets the Workspace account for you. If really necessary, the can be selected by the --account option. If a wrong account/partition combination is requested, you will experience the following error message: sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified If you did not specified --account , and belong to a Workspace, please load the Workspace module fist. Parallel Jobs A parallel job requires multiple compute cores. These could be within one node or across the machine in multiple nodes. We distinguish following types: shared memory jobs : SMP, parallel jobs that run on a single compute node. The executable is called once. Within the execution (OMP) threads are spawned and merged. #SBATCH --ntasks=1 # default value #SBATCH --cpus-per-task=4 MPI jobs : parallel jobs that may be distributed over multiple compute nodes. Each task starts the executable. Within the application different workflows need to be defined for the different tasks. The tasks can communicate using Message Passing Interface (MPI). A job with 40 tasks: #SBATCH --nodes=2 #SBATCH --ntasks-per-node=20 hybrid : jobs using a combination of MPI tasks and (OMP) threads. #SBATCH --nodes=2 #SBATCH --ntasks-per-node=5 #SBATCH --cpus-per-task=4 The requested node,task, and CPU resources must match! For example, you cannot request one node ( --nodes=1 ) and more tasks ( --ntasks-per-node ) than CPU cores are available on a single node in the partition. In such a case you will experience an error message: sbatch: error: Batch job submission failed: Requested node configuration is not available. parallel launcher Parallel applications, esp. MPI, need a launcher to setup the environment. We strongly suggest to use srun instead of mpirun. Environment Variables lsf sets various environment variables available in the context of the job script. Some are set based on the requested resources for the job. Environment Variable Set By Option Description lsf_JOB_NAME --job-name Name of the job lsf_ARRAY_JOB_ID ID of your job lsf_ARRAY_TASK_ID --array ID of the current array task lsf_ARRAY_TASK_MAX --array Job array\u2019s maximum ID (index) number lsf_ARRAY_TASK_MIN --array Job array\u2019s minimum ID (index) number lsf_ARRAY_TASK_STEP --array Job array\u2019s index step size lsf_NTASKS --ntasks Same as -n , --ntasks lsf_NTASKS_PER_NODE --ntasks-per-node Number of tasks requested per node. Only set if the --ntasks-per-node option is specified lsf_CPUS_PER_TASK --cpus-per-task Number of cpus requested per task. Only set if the --cpus-per-task option is specified TMPDIR References the disk space for the job on the local scratch For the full list, see man sbatch Job Examples Sequential Job Running a serial job with email notification in case of error (1 task is default value): #!/bin/bash #SBATCH --mail-user=foo.bar@baz.unibe.ch #SBATCH --mail-type=end,fail #SBATCH --job-name=\"Serial Job\" #SBATCH --time=04:00:00 # Your code below this line echo \"I'm on host: $HOSTNAME \" Parallel Jobs Shared Memory Jobs (e.g. OpenMP) SMP parallelization is based upon dynamically created threads (fork and join) that share memory on a single node. The key request is --cpus-per-task . To run N threads in parallel, we request N CPUs on the node ( --cpus-per-task=N ). #!/bin/bash #SBATCH --mail-user=foo.bar@baz.unibe.ch #SBATCH --mail-type=end,fail #SBATCH --job-name=\"SMP Job\" #SBATCH --mem-per-cpu=2G #SBATCH --cpus-per-task=16 #SBATCH --time=04:00:00 # Your code below this line srun ./my_binary MPI Jobs (e.g. Open MPI) MPI parallelization is based upon processes (local or distributed) that communicate by passing messages. Since they don\u2019t rely on shared memory those processes can be distributed among several compute nodes. Use the option --ntasks to request a certain number of tasks (processes) that can be distributed over multiple nodes: #!/bin/bash #SBATCH --mail-user=foo.bar@baz.unibe.ch #SBATCH --mail-type=end #SBATCH --job-name=\"MPI Job\" #SBATCH --mem-per-cpu=2G #SBATCH --ntasks=8 #SBATCH --time=04:00:00 # Your code below this line # First set the environment for using Open MPI module load foss srun ./my_binary On the \u2018bdw\u2019 partition you must use all CPUs provided by a node (20 CPUs). For example to run an OMPI job on 80 CPUs, do: #!/bin/bash #SBATCH --mail-user=foo.bar@baz.unibe.ch #SBATCH --mail-type=end,fail #SBATCH --job-name=\"MPI Job\" #SBATCH --mem-per-cpu=2G #SBATCH --nodes=4 ## or --ntasks=80 #SBATCH --ntasks-per-node=20 #SBATCH --time=12:00:00 # Your code below this line module load foss srun ./my_binary Performance considerations Job Throughput It is crucial to specify a more or less accurate runtime for your job. Requesting too little will result in job abortion, while requesting too much will have a negative impact on job start time and job throughput: Firstly, jobs with a shorter runtime have a greater chance to benefit from being backfilled between long running jobs and may therefore start earlier if resources are scarce. Secondly, a short running job may still start when a scheduled downtime is getting closer while long running jobs won\u2019t start because they are not guaranteed to finish before the start of the downtime. It is crucial to request the correct amount of cores for your job. Requesting cores that your job cannot utilize is a waste of resources that could otherwise be allocated to other jobs. Hence, jobs that theoretically could run have to wait for the resources to become available. For potential consequences of requesting too less cores on job performance, see below. It is crucial to request the correct amount of memory for your job. Requesting too little memory will result in job abortion. Requesting too much memory is a waste of resources that could otherwise be allocated to other jobs. Job Performance/Runtime It is crucial to request the correct amount of cores for your job. For parallel jobs (shared memory, MPI, hybrid) requesting less cores than processes/threads are spawned by the job will lead to potentially overbooked compute nodes. This is because your job will nevertheless spawn the required number of processes/threads (use a certain number of cores) while to the scheduler it appears that some of the utilized resources are still available, and thus the scheduler will allocate those resources to other jobs. Although under certain circumstances it might make sense to share cores among multiple processes/threads, the above reasoning should be considered as a general guideline, especially for inexperienced user. Advanced settings EXPORT=NONE By default the environment from the session, where the job is submitted is forwarded into the job environment. As a result all loaded modules and environment variables present during submit time are also present during run time. To start from a clean environment the environment forwarding can be prevented. Therefore, we have to keep in mind the 2 stages. First, after submission the job script is launched on a compute node. Second, the parallel tasks are launched using srun. We want to preserve the environment forwarding from within the job script to the parallel tasks. Using just the option sbatch --export=none or the environment variable SBATCH_EXPORT=NONE will prevent the forwarding in both cases. Therewith, issues may occur, like dynamically linked binaries do not find libraries (e.g. executable.xyz: error while loading shared libraries: libgfortran.so.5: cannot open shared object file: No such file or directory ). Thus we suggest to set: export SBATCH_EXPORT=NONE export lsf_EXPORT_ENV=ALL This will provide you with a clean environment during job launch and forward the environment set in the job script to the parallel tasks. This is necessary to have e.g. LD_LIBRARY_PATH set correctly for dynamically linked binaries. keep output It is important to collect error/output messages either by writing such information to the default location or by specifying specific locations using the --error / -\u2013output option. Do not redirect the error/output stream to /dev/null unless you know what you are doing. Error and output messages are the starting point for investigating a job failure. job series Submit series of jobs (collection of similar jobs) as array jobs instead of one by one. This is crucial for backfilling performance and hence job throughput. instead of submitting the same job repeatedly. See Array jobs Reference the Glossary for more info on a cluster \u21a9","title":"LSF and Submitting jobs"},{"location":"lsf/submission.html#job-submission","text":"high level overview of how to submit a job especially for new users","title":"Job Submission"},{"location":"lsf/submission.html#how-to-submit-a-job","text":"","title":"How to submit a job"},{"location":"lsf/submission.html#batch-scripts","text":"","title":"Batch scripts"},{"location":"lsf/submission.html#job-submission_1","text":"","title":"Job submission"},{"location":"lsf/submission.html#checking-the-job","text":"","title":"Checking the job"},{"location":"lsf/submission.html#what-is-lsf","text":"On an HPC cluster, the scheduler manages which jobs run where and when. On our clusters, you control your jobs using a job scheduling system called IBM Spectrum Scale LSF that allocates and manages compute resources for you. A cluster 1 is a set of connected computers that work together to solve computational tasks (user jobs) and presents itself to the user as a single system. For the resources of a cluster (e.g. CPUs, GPUs, memory) to be used efficiently, a resource manager (also called workload manager or batch-queuing system) is vital; the resource manager of choice on our clusters is called IBM Spectrum Scale LSF . After submitting a job to the cluster, LSF will try to fulfill the job\u2019s resource request by allocating resources to the job. If the requested resources are already available, the job can start immediately. Otherwise, the start of the job is delayed (pending) until enough resources are available. By accurately requesting the resources you need, you can have your jobs execute as quickly as possible on nodes available to process them. LSF also allows you to monitor active jobs and to retrieve statistics about finished jobs. This page describes the job submission process with LSF.","title":"What is LSF?"},{"location":"lsf/submission.html#basics-of-job-submission-using-lsf","text":"The bsub command submits jobs to LSF It consists of two parts: resource requests and job steps. A resource request consists of the number of CPU cores, amount of memory per CPU core, wall time (expected duration), GPUs etc. You can find complete lists of the available resources on the cluster pages lilac and juno. Job steps specify tasks which must be done, software which must be run, etc. Upon submission, the job will advance in the queue until the requested resources are available. At this point LSF will allocate the requested CPU cores, GPUs, and memory, and execute it. You can submit your jobs in one of two ways. For testing and small jobs you may want to run a job interactively . This way you can directly interact with the compute node(s) in real time. However, the preferred way for multiple jobs or long-running jobs is to put all of your resource requests and executable into the command line or combining them into a bsub script and submitting that to the job scheduler.","title":"Basics of job submission using LSF"},{"location":"lsf/submission.html#resource-allocation-requesting-resources","text":"Every job submission starts with a resource request. The typical resources that must be included are included in the table below: The usual procedure is to combine resource requests and task execution (job steps) in a single batch script (job script) and then submit the script using the bsub command. | Item | Memory | Wall Time | ------- ------- ----------- |Description| |Example| The Most command options support a short form as well as a long form (e.g. -u <username> , and --user=<username> ). Because few options only support the long form, we will consistently use the long form throughout this documentation. Some options have default values if not specified: The --time option has partition-specific default values (see scontrol show partition <partname> ). The --mem-per-cpu option has a global default value of 2048MB. The default partition is epyc2 . To select another partition one must use the --partition option, e.g. --partition=gpu .","title":"Resource Allocation / Requesting Resources"},{"location":"lsf/submission.html#sbatch","text":"The sbatch command is used to submit a job script for later execution. It is the most common way to submit a job to the cluster due to its reusability. lsf options are usually embedded in a job script prefixed by #SBATCH directives. lsf options specified as command line options overwrite corresponding options embedded in the job script Syntax sbatch [ options ] script [ args... ]","title":"sbatch"},{"location":"lsf/submission.html#simple-example","text":"Batch sbmission script, jobs.sh : #!/bin/bash #SBATCH --job-name=\"First example\" #SBATCH --time=00:10:00 #SBATCH --mem-per-cpu=1G # Your code below this line module load Python srun python3 script.py Submit the job script: sbatch job.sh Submitted batch job 30215045 See below for more examples","title":"Simple Example"},{"location":"lsf/submission.html#job-script","text":"Usually a job script consists of two parts. The first part is optional but highly recommended: lsf-specific options used by the scheduler to manage the resources (e.g. memory) and configure the job environment Job-specific shell commands The job script acts as a wrapper for your actual job. Command-line options can still be used to overwrite embedded options. Although you can specify all lsf options on the command-line, we encourage you, for clarity and reusability, to embed lsf options in the job script","title":"Job Script"},{"location":"lsf/submission.html#options","text":"Option Description Example --job-name Specify a job name --job-name=\"Simple Matlab\" --time Expected runtime of the job. Format: dd-hh:mm:ss --time=12:00:00 --time=2-06:00:00 --ntasks Number of tasks (processes). Used for MPI jobs that may run distributed on multiple compute nodes --ntasks=4 --nodes Request a certain number of nodes --nodes=2 --ntasks-per-node Specifies how many tasks will run on each allocated node. Meant to be used with --nodes . If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. --ntasks-per-node=2 --cpus-per-task Number of CPUs per task (threads). Used for shared memory jobs that run locally on a single compute node. Default is 1 --cpus-per-task=4 --mem-per-cpu Minimum memory required per allocated CPU in megabytes. Different units can be specified using the suffix [K|M|G]. Default 2048 MB --mem-per-cpu=2G --output Redirect standard output . All directories specified in the path must exist before the job starts! By default stderr and stdout are merged into a file lsf-%j.out , where %j is the job allocation number. --output=myCal_%j.out --error Redirect standard error . All directories specified in the path must exist before the job starts! By default stderr and stdout are merged into a file lsf-%j.out , where %j is the job allocation number. --output=myCal_%j.err --partition Select a different partition with different hardware. See Partition/QoS page . Default: epyc2 --partition=bdw --partition=gpu --qos Specify \u201cQuality of Service\u201d. This can be used to change job limits, e.g. for long jobs or short jobs with large resources. See Partition/QoS page --tmp Specify the amount of disk space that must be available on the compute node(s). The local scratch space for the job is referenced by the variable $TMPDIR . Default units are megabytes. Different units can be specified using the suffix [K|M|G|T]. --tmp=8G --mail-user Mail address to contact job owner. Must be a valid email address, if used! --mail-user=foo.bar@unibe.ch --mail-type When to notify a job owner: none , all , begin , end , fail , requeue , array_tasks --mail-type=end,fail --array Submit an array job. Specify the used indices and use \u201c%\u201d to specify the max number of tasks allowed to run concurrently. --array=1,4,16-32:4 --array=1-100%20 --chdir Set the working directory of the batch script to directory before it is executed. The path can be specified as full path or relative path to the directory where the command is executed. Environment variables are not supported. --chdir=subdir1 --dependency Defer the start of this job until the specified dependencies have been satisfied. See man sbatch for a description of all valid dependency types --dependency=afterok:11908 --immediate Only submit the job if all requested resources are immediately available --exclusive Use the compute node(s) exclusively, i.e. do not share nodes with other jobs. CAUTION: Only use this option if you are an experienced user, and you really understand the implications of this feature. If used improperly, the use of this option can lead to a massive waste of computational resources --test-only Validate the batch script and return the estimated start time considering the current cluster state --account Specifies account to charge. Please use Workspace module to select Workspace account. Regular users don\u2019t need to specify this option.","title":"Options"},{"location":"lsf/submission.html#command-to-allocate-resources","text":"The salloc command is used to allocate resources (e.g. nodes), possibly with a set of constraints (e.g. number of processor per node) for later utilization. It is typically used to allocate resources and spawn a shell, in which the srun command is used to launch parallel tasks. Syntax salloc [ options ] [ <command> [ args... ]] Example bash$ salloc -N 2 -t 10 salloc: Granted job allocation 247 bash$ module load foss bash$ srun ./mpi_hello_world Hello, World. I am 1 of 2 running on knlnode03.ubelix.unibe.ch Hello, World. I am 0 of 2 running on knlnode02.ubelix.unibe.ch bash$ exit salloc: Relinquishing job allocation 247","title":"command to allocate resources"},{"location":"lsf/submission.html#srun","text":"The srun command creates job steps. One or multiple srun invocations are usually used from within an existing resource allocation. Thereby, a job step can utilize all resources allocated to the job, or utilize only a subset of the resource allocation. Multiple job steps can run sequentially in the order defined in the batch script or run in parallel, but can together never utilize more resources than provided by the allocation. Do not submit a job script using srun . Embedded lsf options ( #SBATCH ) are not parsed by srun . Syntax srun [options] executable [args...]","title":"srun"},{"location":"lsf/submission.html#when-do-i-use-srun-in-my-job-script","text":"Use srun in your job script for all main executables, especially if these are: MPI applications multiple job tasks (serial or parallel jobs) simultaneously within an allocation Example Run MPI task: #!/bin/bash #SBATCH --job-name=\"Open MPI example\" #SBATCH --nodes=2 #SBATCH --ntasks-per-node=20 #SBATCH --mem-per-cpu=2G #SBATCH --time=06:00:00 # Your code below this line module load foss srun ./mpi_app.exe Run two jobs simultaneously: #!/bin/bash #SBATCH --job-name=\"Open MPI example\" #SBATCH --ntasks=2 #SBATCH --cpus-per-task=4 # Your code below this line # run 2 threaded applications side-by-side srun --tasks = 1 --cpus-per-task = 4 ./app1 inp1.dat & srun --tasks = 1 --cpus-per-task = 4 ./app2 inp2.dat & wait # wait: Wait for both background commands to finish. This is important when running bash commands in the background (using &)! Otherwise, the job ends immediately. Please run series of similar tasks as job array. See Array Jobs","title":"When do I use srun in my job script?"},{"location":"lsf/submission.html#requesting-a-partition-qos-queue","text":"Per default jobs are submitted to the epyc2 partition and the default QoS job_epyc2 . The partition option can be used to request different hardware, e.b. gpu partition. And the QoS can be used to run in a specific queue, e.g. job_gpu_debug : #SBATCH --partition=gpu --qos=job_gpu_debug See Partitions / QoS for a list of available partitions and QoS and its specifications.","title":"Requesting a Partition / QoS (Queue)"},{"location":"lsf/submission.html#accounts","text":"By default a user has a \u201cprivate\u201d account. When belonging to a Workspace your private account gets deactivated and you can submit with the Workspace account. We strongly suggest to use the Workspace module ( module load Workspace ), which automatically sets the Workspace account for you. If really necessary, the can be selected by the --account option. If a wrong account/partition combination is requested, you will experience the following error message: sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified If you did not specified --account , and belong to a Workspace, please load the Workspace module fist.","title":"Accounts"},{"location":"lsf/submission.html#parallel-jobs","text":"A parallel job requires multiple compute cores. These could be within one node or across the machine in multiple nodes. We distinguish following types: shared memory jobs : SMP, parallel jobs that run on a single compute node. The executable is called once. Within the execution (OMP) threads are spawned and merged. #SBATCH --ntasks=1 # default value #SBATCH --cpus-per-task=4 MPI jobs : parallel jobs that may be distributed over multiple compute nodes. Each task starts the executable. Within the application different workflows need to be defined for the different tasks. The tasks can communicate using Message Passing Interface (MPI). A job with 40 tasks: #SBATCH --nodes=2 #SBATCH --ntasks-per-node=20 hybrid : jobs using a combination of MPI tasks and (OMP) threads. #SBATCH --nodes=2 #SBATCH --ntasks-per-node=5 #SBATCH --cpus-per-task=4 The requested node,task, and CPU resources must match! For example, you cannot request one node ( --nodes=1 ) and more tasks ( --ntasks-per-node ) than CPU cores are available on a single node in the partition. In such a case you will experience an error message: sbatch: error: Batch job submission failed: Requested node configuration is not available. parallel launcher Parallel applications, esp. MPI, need a launcher to setup the environment. We strongly suggest to use srun instead of mpirun.","title":"Parallel Jobs"},{"location":"lsf/submission.html#environment-variables","text":"lsf sets various environment variables available in the context of the job script. Some are set based on the requested resources for the job. Environment Variable Set By Option Description lsf_JOB_NAME --job-name Name of the job lsf_ARRAY_JOB_ID ID of your job lsf_ARRAY_TASK_ID --array ID of the current array task lsf_ARRAY_TASK_MAX --array Job array\u2019s maximum ID (index) number lsf_ARRAY_TASK_MIN --array Job array\u2019s minimum ID (index) number lsf_ARRAY_TASK_STEP --array Job array\u2019s index step size lsf_NTASKS --ntasks Same as -n , --ntasks lsf_NTASKS_PER_NODE --ntasks-per-node Number of tasks requested per node. Only set if the --ntasks-per-node option is specified lsf_CPUS_PER_TASK --cpus-per-task Number of cpus requested per task. Only set if the --cpus-per-task option is specified TMPDIR References the disk space for the job on the local scratch For the full list, see man sbatch","title":"Environment Variables"},{"location":"lsf/submission.html#job-examples","text":"","title":"Job Examples"},{"location":"lsf/submission.html#sequential-job","text":"Running a serial job with email notification in case of error (1 task is default value): #!/bin/bash #SBATCH --mail-user=foo.bar@baz.unibe.ch #SBATCH --mail-type=end,fail #SBATCH --job-name=\"Serial Job\" #SBATCH --time=04:00:00 # Your code below this line echo \"I'm on host: $HOSTNAME \"","title":"Sequential Job"},{"location":"lsf/submission.html#parallel-jobs_1","text":"Shared Memory Jobs (e.g. OpenMP) SMP parallelization is based upon dynamically created threads (fork and join) that share memory on a single node. The key request is --cpus-per-task . To run N threads in parallel, we request N CPUs on the node ( --cpus-per-task=N ). #!/bin/bash #SBATCH --mail-user=foo.bar@baz.unibe.ch #SBATCH --mail-type=end,fail #SBATCH --job-name=\"SMP Job\" #SBATCH --mem-per-cpu=2G #SBATCH --cpus-per-task=16 #SBATCH --time=04:00:00 # Your code below this line srun ./my_binary MPI Jobs (e.g. Open MPI) MPI parallelization is based upon processes (local or distributed) that communicate by passing messages. Since they don\u2019t rely on shared memory those processes can be distributed among several compute nodes. Use the option --ntasks to request a certain number of tasks (processes) that can be distributed over multiple nodes: #!/bin/bash #SBATCH --mail-user=foo.bar@baz.unibe.ch #SBATCH --mail-type=end #SBATCH --job-name=\"MPI Job\" #SBATCH --mem-per-cpu=2G #SBATCH --ntasks=8 #SBATCH --time=04:00:00 # Your code below this line # First set the environment for using Open MPI module load foss srun ./my_binary On the \u2018bdw\u2019 partition you must use all CPUs provided by a node (20 CPUs). For example to run an OMPI job on 80 CPUs, do: #!/bin/bash #SBATCH --mail-user=foo.bar@baz.unibe.ch #SBATCH --mail-type=end,fail #SBATCH --job-name=\"MPI Job\" #SBATCH --mem-per-cpu=2G #SBATCH --nodes=4 ## or --ntasks=80 #SBATCH --ntasks-per-node=20 #SBATCH --time=12:00:00 # Your code below this line module load foss srun ./my_binary","title":"Parallel Jobs"},{"location":"lsf/submission.html#performance-considerations","text":"","title":"Performance considerations"},{"location":"lsf/submission.html#job-throughput","text":"It is crucial to specify a more or less accurate runtime for your job. Requesting too little will result in job abortion, while requesting too much will have a negative impact on job start time and job throughput: Firstly, jobs with a shorter runtime have a greater chance to benefit from being backfilled between long running jobs and may therefore start earlier if resources are scarce. Secondly, a short running job may still start when a scheduled downtime is getting closer while long running jobs won\u2019t start because they are not guaranteed to finish before the start of the downtime. It is crucial to request the correct amount of cores for your job. Requesting cores that your job cannot utilize is a waste of resources that could otherwise be allocated to other jobs. Hence, jobs that theoretically could run have to wait for the resources to become available. For potential consequences of requesting too less cores on job performance, see below. It is crucial to request the correct amount of memory for your job. Requesting too little memory will result in job abortion. Requesting too much memory is a waste of resources that could otherwise be allocated to other jobs.","title":"Job Throughput"},{"location":"lsf/submission.html#job-performanceruntime","text":"It is crucial to request the correct amount of cores for your job. For parallel jobs (shared memory, MPI, hybrid) requesting less cores than processes/threads are spawned by the job will lead to potentially overbooked compute nodes. This is because your job will nevertheless spawn the required number of processes/threads (use a certain number of cores) while to the scheduler it appears that some of the utilized resources are still available, and thus the scheduler will allocate those resources to other jobs. Although under certain circumstances it might make sense to share cores among multiple processes/threads, the above reasoning should be considered as a general guideline, especially for inexperienced user.","title":"Job Performance/Runtime"},{"location":"lsf/submission.html#advanced-settings","text":"","title":"Advanced settings"},{"location":"lsf/submission.html#exportnone","text":"By default the environment from the session, where the job is submitted is forwarded into the job environment. As a result all loaded modules and environment variables present during submit time are also present during run time. To start from a clean environment the environment forwarding can be prevented. Therefore, we have to keep in mind the 2 stages. First, after submission the job script is launched on a compute node. Second, the parallel tasks are launched using srun. We want to preserve the environment forwarding from within the job script to the parallel tasks. Using just the option sbatch --export=none or the environment variable SBATCH_EXPORT=NONE will prevent the forwarding in both cases. Therewith, issues may occur, like dynamically linked binaries do not find libraries (e.g. executable.xyz: error while loading shared libraries: libgfortran.so.5: cannot open shared object file: No such file or directory ). Thus we suggest to set: export SBATCH_EXPORT=NONE export lsf_EXPORT_ENV=ALL This will provide you with a clean environment during job launch and forward the environment set in the job script to the parallel tasks. This is necessary to have e.g. LD_LIBRARY_PATH set correctly for dynamically linked binaries. keep output It is important to collect error/output messages either by writing such information to the default location or by specifying specific locations using the --error / -\u2013output option. Do not redirect the error/output stream to /dev/null unless you know what you are doing. Error and output messages are the starting point for investigating a job failure. job series Submit series of jobs (collection of similar jobs) as array jobs instead of one by one. This is crucial for backfilling performance and hence job throughput. instead of submitting the same job repeatedly. See Array jobs Reference the Glossary for more info on a cluster \u21a9","title":"EXPORT=NONE"},{"location":"optimization/scaling.html","text":"Job Scaling Description Seeking for performance improvements, applications are parallelized. The effective runtime should be decreased, by utilizing more compute resources. There are multiple ways of parallelization. Threading is used on shared memory architectures, implemented via OpenMP. Task parallel algorithms using MPI can run across multiple nodes. A so called hybrid application can use the advantages of both methods. Please read first the Parallization page, where basic concepts, and usage hints are provided. General Aspects Amdahl\u2019s law provides a theoretical upper limit of an application speedup, considering a fixed problem size. Depending on the ratio between time spend in parallel versus serial regions the applications speedup scales further. Even if almost the whole time is spend in parallel regions, practically the scaling is limited. At a certain point a parallelization overhead will dominate the application runtime, e.g. the communication in MPI. At a certain point, increasing resource requests may lead to decreasing performance. OpenMP In general, the amount of OpenMP threads are limited by the amount of CPU cores per node. In practice the efficiency is limited much earlier. Reasons could be: problem is not big enough blocking operations between different threads increased latency when distance between memory and CPU core are increasing (different sockets, etc.) MPI MPI applications can theoretically utilize the whole machine. In practice algorithms and problems often do not scale that far. Depending on the implementation, the communication increases drastically with the amount of tasks, especially for All-to-all communication patterns. Empirical Tests Especially for applications utilized many times, we may want to determine the sweet spot between performance improvement and resource usage. Therefore, a representative test case should be selected. Ideally it would be relatively short in runtime (few iterations, O (5min)), using the targeted algorithm and a representative problem size. Then the scaling would be tested separate for threading (if applicable), and MPI tasks.","title":"Scaling"},{"location":"optimization/scaling.html#job-scaling","text":"","title":"Job Scaling"},{"location":"optimization/scaling.html#description","text":"Seeking for performance improvements, applications are parallelized. The effective runtime should be decreased, by utilizing more compute resources. There are multiple ways of parallelization. Threading is used on shared memory architectures, implemented via OpenMP. Task parallel algorithms using MPI can run across multiple nodes. A so called hybrid application can use the advantages of both methods. Please read first the Parallization page, where basic concepts, and usage hints are provided.","title":"Description"},{"location":"optimization/scaling.html#general-aspects","text":"Amdahl\u2019s law provides a theoretical upper limit of an application speedup, considering a fixed problem size. Depending on the ratio between time spend in parallel versus serial regions the applications speedup scales further. Even if almost the whole time is spend in parallel regions, practically the scaling is limited. At a certain point a parallelization overhead will dominate the application runtime, e.g. the communication in MPI. At a certain point, increasing resource requests may lead to decreasing performance.","title":"General Aspects"},{"location":"optimization/scaling.html#openmp","text":"In general, the amount of OpenMP threads are limited by the amount of CPU cores per node. In practice the efficiency is limited much earlier. Reasons could be: problem is not big enough blocking operations between different threads increased latency when distance between memory and CPU core are increasing (different sockets, etc.)","title":"OpenMP"},{"location":"optimization/scaling.html#mpi","text":"MPI applications can theoretically utilize the whole machine. In practice algorithms and problems often do not scale that far. Depending on the implementation, the communication increases drastically with the amount of tasks, especially for All-to-all communication patterns.","title":"MPI"},{"location":"optimization/scaling.html#empirical-tests","text":"Especially for applications utilized many times, we may want to determine the sweet spot between performance improvement and resource usage. Therefore, a representative test case should be selected. Ideally it would be relatively short in runtime (few iterations, O (5min)), using the targeted algorithm and a representative problem size. Then the scaling would be tested separate for threading (if applicable), and MPI tasks.","title":"Empirical Tests"},{"location":"software/Anaconda.html","text":"Anaconda Description Anaconda provides Python and a long list of packages as well as Jupyter and environment and package manager conda and pip. Anaconda brings a long list of Python packages. You can list them using conda list Availability On our systems we provide Anaconda3, which gets update regularly. Usage module load Anaconda3 Additional Packages to install additional packages please see Additional Packages Jupyter For Jupyter information please see JupyterLab Managing Virtual Environments, Versions with Anaconda Anaconda is a high performance distribution of Python that includes the most popular packages for data science (numpy, scipy,\u2026). It also features conda, a package, dependency and environment manager. With Anaconda you can run multiple versions of Python in isolated environments. conda when using conda the system may complain about: CommandNotFoundError: Your shell has not been properly configured to use 'conda activate' . To initialize your shell, run $ conda init <SHELL_NAME> Currently supported shells are: - bash - fish - tcsh - xonsh - zsh - powershell See 'conda init --help' for more information and options. IMPORTANT: You may need to close and restart your shell after running 'conda init' . Please do not run conda init . This would add hard coded environment changes in your $HOME/.bashrc . Instead initialise the conda environment using: module load Anaconda3 eval \" $( conda shell.bash hook ) \" This should also be used in your batch submission scripts when working with conda environments. conda environments By default conda environments are located into the $HOME/.conda directory. This can be changed using $CONDA_ENVS_PATH . This variable is set in the Workspace module. Which enables you to share conda environments. Move / Migration of conda environments If conda environments need to be transfered on the system, e.g. from $HOME to $WORKSPACE you can use the conda pack (see official conda pack documentation ). If your environment is already moved file system locations, you can recreate a new environment with the specification of the old environment. Therefore, we specify the location of the old environment, load the Anaconda module, initialize conda, and get the specification of the old environment. Then importantly unset the CONDA_ENVS_PATH to install the new conda environment in the default location and create it. export CONDA_ENVS_PATH=${HOME}/anaconda3/envs ## or where you had your old envs module load Anaconda3 eval \"$(conda shell.bash hook)\" conda info --envs conda activate oldEnvName ## choose your old environment name conda list --explicit > spec-list.txt unset CONDA_ENVS_PATH conda create --name myEnvName --file spec-list.txt # select a name","title":"Anaconda"},{"location":"software/Anaconda.html#anaconda","text":"","title":"Anaconda"},{"location":"software/Anaconda.html#description","text":"Anaconda provides Python and a long list of packages as well as Jupyter and environment and package manager conda and pip. Anaconda brings a long list of Python packages. You can list them using conda list","title":"Description"},{"location":"software/Anaconda.html#availability","text":"On our systems we provide Anaconda3, which gets update regularly.","title":"Availability"},{"location":"software/Anaconda.html#usage","text":"module load Anaconda3","title":"Usage"},{"location":"software/Anaconda.html#additional-packages","text":"to install additional packages please see Additional Packages","title":"Additional Packages"},{"location":"software/Anaconda.html#jupyter","text":"For Jupyter information please see JupyterLab","title":"Jupyter"},{"location":"software/Anaconda.html#managing-virtual-environments-versions-with-anaconda","text":"Anaconda is a high performance distribution of Python that includes the most popular packages for data science (numpy, scipy,\u2026). It also features conda, a package, dependency and environment manager. With Anaconda you can run multiple versions of Python in isolated environments.","title":"Managing Virtual Environments, Versions with Anaconda"},{"location":"software/Anaconda.html#conda","text":"when using conda the system may complain about: CommandNotFoundError: Your shell has not been properly configured to use 'conda activate' . To initialize your shell, run $ conda init <SHELL_NAME> Currently supported shells are: - bash - fish - tcsh - xonsh - zsh - powershell See 'conda init --help' for more information and options. IMPORTANT: You may need to close and restart your shell after running 'conda init' . Please do not run conda init . This would add hard coded environment changes in your $HOME/.bashrc . Instead initialise the conda environment using: module load Anaconda3 eval \" $( conda shell.bash hook ) \" This should also be used in your batch submission scripts when working with conda environments.","title":"conda"},{"location":"software/Anaconda.html#conda-environments","text":"By default conda environments are located into the $HOME/.conda directory. This can be changed using $CONDA_ENVS_PATH . This variable is set in the Workspace module. Which enables you to share conda environments.","title":"conda environments"},{"location":"software/Anaconda.html#move-migration-of-conda-environments","text":"If conda environments need to be transfered on the system, e.g. from $HOME to $WORKSPACE you can use the conda pack (see official conda pack documentation ). If your environment is already moved file system locations, you can recreate a new environment with the specification of the old environment. Therefore, we specify the location of the old environment, load the Anaconda module, initialize conda, and get the specification of the old environment. Then importantly unset the CONDA_ENVS_PATH to install the new conda environment in the default location and create it. export CONDA_ENVS_PATH=${HOME}/anaconda3/envs ## or where you had your old envs module load Anaconda3 eval \"$(conda shell.bash hook)\" conda info --envs conda activate oldEnvName ## choose your old environment name conda list --explicit > spec-list.txt unset CONDA_ENVS_PATH conda create --name myEnvName --file spec-list.txt # select a name","title":"Move / Migration of conda environments"},{"location":"software/CUDA.html","text":"CUDA Description Libraries for parallel programm on NVIDIA GPUs. run only If you only want to use the CUDA with your already compiled application you only need to load: module load CUDA compile applications CUDA has restriction in supported compilers. E.g. CUDA/10.1.243 is not compatible with GCC/9.3.9 We suggest to load complete toolchains, e.g. module load fosscuda This provides beside CUDA and GCC also OpenMPI, OpenBLAS, FFTW, ScaLAPACK and others.","title":"CUDA"},{"location":"software/CUDA.html#cuda","text":"","title":"CUDA"},{"location":"software/CUDA.html#description","text":"Libraries for parallel programm on NVIDIA GPUs.","title":"Description"},{"location":"software/CUDA.html#run-only","text":"If you only want to use the CUDA with your already compiled application you only need to load: module load CUDA","title":"run only"},{"location":"software/CUDA.html#compile-applications","text":"CUDA has restriction in supported compilers. E.g. CUDA/10.1.243 is not compatible with GCC/9.3.9 We suggest to load complete toolchains, e.g. module load fosscuda This provides beside CUDA and GCC also OpenMPI, OpenBLAS, FFTW, ScaLAPACK and others.","title":"compile applications"},{"location":"software/EasyBuild.html","text":"EasyBuild Description EasyBuild can install software packages including the related modules. The location will be controlled using our modules, e.g. the Workspace module, see Installing Custom Software . On top of the usual EasyBuild framework we added some extensions which allows you to build for specific architectures or a generic software stack in your user/group space. Therefore, use the eb command to search and try and the eb-install-all or eb-install-generic command to install the package. The following steps need are necessary: load modules find the package specification decide the desired software stack run EasyBuild installation using eb-install-all or eb-install-generic Modules Depending if you want to install the package in user or a group space you need to load the related module and the EasyBuild module, e.g.: module load Workspace ### if you want to install into your HOME use Workspace_Home module load EasyBuild Therewith, our EasyBuild tools and EasyBuild itself are available. Note Specify the WorkspaceID if necessary when loading the Workspace module. See module instructions Package Specification EasyBuild has a large repository of available packages in different versions. You can use these specifications as is or copy/download and modify the EasyConfigs (see below). Available packages can be searched using the following command, here for the gatk package eb --search gatk [ ... ] eb --search gatk == found valid index for /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs, so using it... * /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs/g/GATK/GATK-1.0.5083.eb ... * /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs/g/GATK/GATK-4.0.1.2-Java-1.8.eb ... * /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs/g/GATK/GATK-4.0.12.0-foss-2018b-Python-3.6.6.eb ... * /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs/g/GATK/GATK-4.0.4.0-intel-2018a-Python-3.6.4.eb * /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs/g/GATK/GATK-4.0.5.1-foss-2018a-Python-3.6.4.eb ... * /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs/g/GATK/GATK-4.0.8.1-foss-2018b-Python-2.7.15.eb ... * /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs/g/GATK/GATK-4.1.8.1-GCCcore-9.3.0-Java-1.8.eb As shown above there are different versions of GATK and for different toolchains available ( foss , intel , GCCcore ). Select one , here GATK-4.1.8.1-GCCcore-9.3.0-Java-1.8.eb is chosen. Alternatively, the packages can be listed or selected using the package name and target toolchain and version: eb --software-name = GATK --toolchain-name = GCC --toolchain-version = 9 .3.0 You can list all dependencies using: eb -Dr /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs/g/GATK/GATK-4.1.8.1-GCCcore-9.3.0-Java-1.8.eb ... Dry run: printing build status of easyconfigs and dependencies CFGS = /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs * [ ] $CFGS /j/Java/Java-1.8.0_281.eb ( module: Java/1.8.0_281 ) ... * [ x ] $CFGS /p/Python/Python-2.7.18-GCCcore-9.3.0.eb ( module: Python/2.7.18-GCCcore-9.3.0 ) * [ ] $CFGS /g/GATK/GATK-4.1.8.1-GCCcore-9.3.0-Java-1.8.eb ( module: GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8 ) Dependencies marked with x are already installed, the other dependencies will be installed if using the robot option. Additional options, e.g. for selecting a specific software version can be found using eb --help . Using EasyConfig files You can use the directly selected EasyConfig or if necessary copy and adapt it. EasyConfig files are text files specifying the software version, toolchain version, dependencies, compile arguments and more. If you need more information see EasyBuild documentation , and if necessary ask our support team for assistance. Meta module and Toolchains Modules specify related dependencies, which gets loaded with that module. These dependencies may have further dependencies. The chain of dependencies is called toolchain. For example: GCC consists of GCCcore and binutils gompi consists of GCC and OpenMPI foss consists of gompi , OpenBLAS , FFTW and ScaLAPACK Within a toolchain the versions of the utilized libraries should be consistent. Thus, building a new package with foss/2020b and PyTorch should rely on a PyTorch version build with the same versions of the underlying libraries. Thus e.g. PyTorch-1.9.0-foss-2020b.eb is also build with foss/2020b as well as the Python/3.8.6 . The latter one is build with GCCcore/10.2.0 which is part of foss/2020b . Selecting a software stack Depending on the package and its target usage one or more software stacks should be selected. Therefore, the installation command starts with one for the following command: all architectural software stacks: eb-install-all a specific architectural software stack (e.g. only targeting Broadwell nodes): eb-install-all --archs='broadwell' OR generic software stack: eb-install-generic , CPU architecture independent, like git Installation After selecting the package installation recipe and the target software stack, the installation process can be submitted. With the following commands, lsf job files will be created, and submitted to the desired compute nodes. There the packages are build and module files created. The general syntax is: eb_install_ { all,generic } [ options ] [ easybuild options ] <easyconfig>.eb Additional lsf arguments can be selected using the --lsf-args option, e.g. --lsf-args='--account=xyz --time=00:10:00 --cpus-per-task' . If specific architectures should be selected use e.g. --arch='broadwell ivy' . After this options, EasyBuild arguments can be provided without prefix, e.g. --robot . Few examples: for a selected or custom EasyConfig and all missing dependencies in all architectural software stacks (here we go with the above selected GATK): eb-install-all --robot GATK-4.1.8.1-GCCcore-9.3.0-Java-1.8.eb only in the Broadwell and Login software stack installing FFTW in GCC toolchain (newest version): eb-install-all --robot --archs = 'login broadwell' --software-name = FFTW --toolchain-name = GCC for git in the generic software stack, with GCC toolchain of version 2021a: eb-install-generic --robot --software-name = git --toolchain-name = GCC --toolchain-version = 2021a This will need time to get scheduled and processed. The job output is presented in the eb_out.* files, one for each architecture. If the build could not be finished in the default time of 1h, the walltime can be extended using: eb-install-all --robot --lsf-args = '--time=05:00:00' ... Note Please check the end of the out file for the COMPLETED: Installation ended successfully statement. When finished you (and your collaborators) should be able to use use the software, by just loading the user/workspace related module and the module for the installed package. Adapting EasyConfigs in the following description and example we update an existing old EasyConfig for newer versions. In our case we want to update the version of Relion, the toolchain, and dependent libraries it is build with. setup EasyBuild environment module load EasyBuild module load Workspace ### OR Workspace_Home find a suitable easyconfig $ eb --search Relion alternatively you may find easyconfigs online, e.g. https://github.com/easybuilders/easybuild-easyconfigs copy the easyconfig into a working directory (here . ) $ cp $EBROOTEASYBUILD/easybuild/easyconfigs/r/RELION/RELION-3.0.4-foss-2017b.eb . rename to the targeted versions (here newer relion, newer toolchain) $ mv RELION-3.0.4-foss-2017b.eb RELION-3.1.2-foss-2020b.eb find the new versions of toolchain and libraries all installed version of a package can be listed using module avail package , e.g. module avail foss available easyconfigs of non-installed packages can be listed using eb --search package . If there is a targeted version available, you can just define that dependency version in the above easyconfig and EasyBuild will find and use it. update the versions settings in the file package version, the toolchain version, and all related libraries Keep in mind that toolchain versions need to match (see toolchains above) easyblock = 'CMakeMake' name = 'RELION' version = '3.1.2' #### The Relion version was '3.0.4' before homepage = 'http://www2.mrc-lmb.cam.ac.uk/relion/index.php/Main_Page' description = \"\"\"RELION (for REgularised LIkelihood OptimisatioN, pronounce rely-on) is a stand-alone computer program that employs an empirical Bayesian approach to refinement of (multiple) 3D reconstructions or 2D class averages in electron cryo-microscopy (cryo-EM).\"\"\" toolchain = { 'name' : 'foss' , 'version' : '2020b' } ### the foss toolchain version was 2020 b before toolchainopts = { 'openmp' : True } source_urls = [ 'https://github.com/3dem/relion/archive' ] sources = [ '%(version)s.tar.gz' ] checksums = [ '2580d66088923a644bc7d3b02efd154b775a3ec3d010426f382bb3be5db9c98b' ] builddependencies = [( 'CMake' , '3.18.4' )] ### was 3.9.5 dependencies = [ ( 'X11' , '20201008' ), ### was 20171023 ( 'FLTK' , '1.3.5' ), ### was 1.3.4 ( 'LibTIFF' , '4.1.0' ), ### 4.0.9 ( 'tbb' , '2020.3' ), ### 2018 _U5 ] configopts = \"-DCMAKE_SHARED_LINKER_FLAGS='-lpthread' -DMPI_INCLUDE_PATH=$EBROOTOPENMPI/include \" configopts += \"-DMPI_C_COMPILER=$EBROOTOPENMPI/bin/mpicc -DMPI_CXX_COMPILER=$EBROOTOPENMPI/bin/mpicxx \" configopts += \"-DCUDA=OFF -DCudaTexture=OFF \" configopts += \"-DALTCPU=ON -DFORCE_OWN_TBB=OFF \" sanity_check_paths = { 'files' : [ 'bin/relion' ], 'dirs' : [] } moduleclass = 'bio' update the checksum (if package version is changed) The downloaded source packages are typically checked with SHA256 checksums. When we change to a different source code versio, the checksum changes too. And need to be updated. $ eb --force --inject-checksums sha256 RELION-3.1.2-foss-2020b.eb build the new package as described in Installation above, e.g. $ eb-install-all --robot RELION-3.1.2-foss-2020b.eb Tips and tricks Even if EasyBuild tries to simplify the installation process, not always EasyConfigs are Build without issues. There can be several types of issues. Starting form issues in finding exiting packages up to compilation issues. More information In the EasyBuild output eb_out.* files are issues summarized. Often more details are required. There are more detailed log files created in the temporary directory. On the compute nodes they are deleted at the end of the job, but on the login node (ivy) they are kept. The location is mentioned near the end of the output and typically is after Results of the build can be found in the log file . Lock directories EasyBuild has a procedure to prevent building the same package (same version, same software stack) using lock files. If eb-install-* crashes due to time limit , the lock files are not removed properly. Therewith the next time you start eb-install-* for that package a message like will be presented at the end of the output: ERROR: Build of /path/to/easyconfig.eb failed ( err: 'build failed (first 300 chars): Lock /path/to/.locks/packageVersion.lock already exists, aborting!' ) In that moment the lock file should be already removed and the process can finally be started successfully again. Hidden Modules Sometimes packages are not defined consistently. On UBELIX many packages are provided as hidden modules. This keeps the list nice and tidy. Nevertheless, if a package (or worse one of its dependency) is looking for an existing packages, but it is not mentioned to be hidden, it will not find and need to rebuild again. Hidden packages can be searched using module --show-hidden avail <PackageXYZ> . If existing as hidden and the target package or dependency does not define it as hidden, EasyBuild can be advised to treat it as hidden using the --hide-deps option. E.g. for binutils, gettext and Mesa, the command would look like: $ eb-install-all --hide-deps = binutils,gettext,Mesa <PackageXYZ> Directly on the compute node The eb-install-all tool builds the packages directly on a compute node. The node type can be limited/specified by using the option --archs=<type> (see eb-install-all --help ). If this fails, an investigation step may be running directly on the node, without more control of the setup, e.g. build directories. Therefore, EasyBuild can be started directly in a session on the compute node. First, an interactive session is established on the compute node. For example building Relion in the $HOME on an epyc2 node using a local copy of the EasyConfig file: $ srun --pty --partition epyc2 bash $ module load Workspace_Home EasyBuild $ eb --tmpdir = $TMPDIR --robot --hide-deps = binutils,gettext,Mesa RELION-3.1.3-fosscuda-2020b.eb This may also be used when compiling on a specific GPU architecture.","title":"EasyBuild"},{"location":"software/EasyBuild.html#easybuild","text":"","title":"EasyBuild"},{"location":"software/EasyBuild.html#description","text":"EasyBuild can install software packages including the related modules. The location will be controlled using our modules, e.g. the Workspace module, see Installing Custom Software . On top of the usual EasyBuild framework we added some extensions which allows you to build for specific architectures or a generic software stack in your user/group space. Therefore, use the eb command to search and try and the eb-install-all or eb-install-generic command to install the package. The following steps need are necessary: load modules find the package specification decide the desired software stack run EasyBuild installation using eb-install-all or eb-install-generic","title":"Description"},{"location":"software/EasyBuild.html#modules","text":"Depending if you want to install the package in user or a group space you need to load the related module and the EasyBuild module, e.g.: module load Workspace ### if you want to install into your HOME use Workspace_Home module load EasyBuild Therewith, our EasyBuild tools and EasyBuild itself are available. Note Specify the WorkspaceID if necessary when loading the Workspace module. See module instructions","title":"Modules"},{"location":"software/EasyBuild.html#package-specification","text":"EasyBuild has a large repository of available packages in different versions. You can use these specifications as is or copy/download and modify the EasyConfigs (see below). Available packages can be searched using the following command, here for the gatk package eb --search gatk [ ... ] eb --search gatk == found valid index for /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs, so using it... * /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs/g/GATK/GATK-1.0.5083.eb ... * /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs/g/GATK/GATK-4.0.1.2-Java-1.8.eb ... * /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs/g/GATK/GATK-4.0.12.0-foss-2018b-Python-3.6.6.eb ... * /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs/g/GATK/GATK-4.0.4.0-intel-2018a-Python-3.6.4.eb * /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs/g/GATK/GATK-4.0.5.1-foss-2018a-Python-3.6.4.eb ... * /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs/g/GATK/GATK-4.0.8.1-foss-2018b-Python-2.7.15.eb ... * /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs/g/GATK/GATK-4.1.8.1-GCCcore-9.3.0-Java-1.8.eb As shown above there are different versions of GATK and for different toolchains available ( foss , intel , GCCcore ). Select one , here GATK-4.1.8.1-GCCcore-9.3.0-Java-1.8.eb is chosen. Alternatively, the packages can be listed or selected using the package name and target toolchain and version: eb --software-name = GATK --toolchain-name = GCC --toolchain-version = 9 .3.0 You can list all dependencies using: eb -Dr /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs/g/GATK/GATK-4.1.8.1-GCCcore-9.3.0-Java-1.8.eb ... Dry run: printing build status of easyconfigs and dependencies CFGS = /storage/software/generic.el7/software/EasyBuild/4.3.3/easybuild/easyconfigs * [ ] $CFGS /j/Java/Java-1.8.0_281.eb ( module: Java/1.8.0_281 ) ... * [ x ] $CFGS /p/Python/Python-2.7.18-GCCcore-9.3.0.eb ( module: Python/2.7.18-GCCcore-9.3.0 ) * [ ] $CFGS /g/GATK/GATK-4.1.8.1-GCCcore-9.3.0-Java-1.8.eb ( module: GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8 ) Dependencies marked with x are already installed, the other dependencies will be installed if using the robot option. Additional options, e.g. for selecting a specific software version can be found using eb --help .","title":"Package Specification"},{"location":"software/EasyBuild.html#using-easyconfig-files","text":"You can use the directly selected EasyConfig or if necessary copy and adapt it. EasyConfig files are text files specifying the software version, toolchain version, dependencies, compile arguments and more. If you need more information see EasyBuild documentation , and if necessary ask our support team for assistance.","title":"Using EasyConfig files"},{"location":"software/EasyBuild.html#meta-module-and-toolchains","text":"Modules specify related dependencies, which gets loaded with that module. These dependencies may have further dependencies. The chain of dependencies is called toolchain. For example: GCC consists of GCCcore and binutils gompi consists of GCC and OpenMPI foss consists of gompi , OpenBLAS , FFTW and ScaLAPACK Within a toolchain the versions of the utilized libraries should be consistent. Thus, building a new package with foss/2020b and PyTorch should rely on a PyTorch version build with the same versions of the underlying libraries. Thus e.g. PyTorch-1.9.0-foss-2020b.eb is also build with foss/2020b as well as the Python/3.8.6 . The latter one is build with GCCcore/10.2.0 which is part of foss/2020b .","title":"Meta module and Toolchains"},{"location":"software/EasyBuild.html#selecting-a-software-stack","text":"Depending on the package and its target usage one or more software stacks should be selected. Therefore, the installation command starts with one for the following command: all architectural software stacks: eb-install-all a specific architectural software stack (e.g. only targeting Broadwell nodes): eb-install-all --archs='broadwell' OR generic software stack: eb-install-generic , CPU architecture independent, like git","title":"Selecting a software stack"},{"location":"software/EasyBuild.html#installation","text":"After selecting the package installation recipe and the target software stack, the installation process can be submitted. With the following commands, lsf job files will be created, and submitted to the desired compute nodes. There the packages are build and module files created. The general syntax is: eb_install_ { all,generic } [ options ] [ easybuild options ] <easyconfig>.eb Additional lsf arguments can be selected using the --lsf-args option, e.g. --lsf-args='--account=xyz --time=00:10:00 --cpus-per-task' . If specific architectures should be selected use e.g. --arch='broadwell ivy' . After this options, EasyBuild arguments can be provided without prefix, e.g. --robot . Few examples: for a selected or custom EasyConfig and all missing dependencies in all architectural software stacks (here we go with the above selected GATK): eb-install-all --robot GATK-4.1.8.1-GCCcore-9.3.0-Java-1.8.eb only in the Broadwell and Login software stack installing FFTW in GCC toolchain (newest version): eb-install-all --robot --archs = 'login broadwell' --software-name = FFTW --toolchain-name = GCC for git in the generic software stack, with GCC toolchain of version 2021a: eb-install-generic --robot --software-name = git --toolchain-name = GCC --toolchain-version = 2021a This will need time to get scheduled and processed. The job output is presented in the eb_out.* files, one for each architecture. If the build could not be finished in the default time of 1h, the walltime can be extended using: eb-install-all --robot --lsf-args = '--time=05:00:00' ... Note Please check the end of the out file for the COMPLETED: Installation ended successfully statement. When finished you (and your collaborators) should be able to use use the software, by just loading the user/workspace related module and the module for the installed package.","title":"Installation"},{"location":"software/EasyBuild.html#adapting-easyconfigs","text":"in the following description and example we update an existing old EasyConfig for newer versions. In our case we want to update the version of Relion, the toolchain, and dependent libraries it is build with. setup EasyBuild environment module load EasyBuild module load Workspace ### OR Workspace_Home find a suitable easyconfig $ eb --search Relion alternatively you may find easyconfigs online, e.g. https://github.com/easybuilders/easybuild-easyconfigs copy the easyconfig into a working directory (here . ) $ cp $EBROOTEASYBUILD/easybuild/easyconfigs/r/RELION/RELION-3.0.4-foss-2017b.eb . rename to the targeted versions (here newer relion, newer toolchain) $ mv RELION-3.0.4-foss-2017b.eb RELION-3.1.2-foss-2020b.eb find the new versions of toolchain and libraries all installed version of a package can be listed using module avail package , e.g. module avail foss available easyconfigs of non-installed packages can be listed using eb --search package . If there is a targeted version available, you can just define that dependency version in the above easyconfig and EasyBuild will find and use it. update the versions settings in the file package version, the toolchain version, and all related libraries Keep in mind that toolchain versions need to match (see toolchains above) easyblock = 'CMakeMake' name = 'RELION' version = '3.1.2' #### The Relion version was '3.0.4' before homepage = 'http://www2.mrc-lmb.cam.ac.uk/relion/index.php/Main_Page' description = \"\"\"RELION (for REgularised LIkelihood OptimisatioN, pronounce rely-on) is a stand-alone computer program that employs an empirical Bayesian approach to refinement of (multiple) 3D reconstructions or 2D class averages in electron cryo-microscopy (cryo-EM).\"\"\" toolchain = { 'name' : 'foss' , 'version' : '2020b' } ### the foss toolchain version was 2020 b before toolchainopts = { 'openmp' : True } source_urls = [ 'https://github.com/3dem/relion/archive' ] sources = [ '%(version)s.tar.gz' ] checksums = [ '2580d66088923a644bc7d3b02efd154b775a3ec3d010426f382bb3be5db9c98b' ] builddependencies = [( 'CMake' , '3.18.4' )] ### was 3.9.5 dependencies = [ ( 'X11' , '20201008' ), ### was 20171023 ( 'FLTK' , '1.3.5' ), ### was 1.3.4 ( 'LibTIFF' , '4.1.0' ), ### 4.0.9 ( 'tbb' , '2020.3' ), ### 2018 _U5 ] configopts = \"-DCMAKE_SHARED_LINKER_FLAGS='-lpthread' -DMPI_INCLUDE_PATH=$EBROOTOPENMPI/include \" configopts += \"-DMPI_C_COMPILER=$EBROOTOPENMPI/bin/mpicc -DMPI_CXX_COMPILER=$EBROOTOPENMPI/bin/mpicxx \" configopts += \"-DCUDA=OFF -DCudaTexture=OFF \" configopts += \"-DALTCPU=ON -DFORCE_OWN_TBB=OFF \" sanity_check_paths = { 'files' : [ 'bin/relion' ], 'dirs' : [] } moduleclass = 'bio' update the checksum (if package version is changed) The downloaded source packages are typically checked with SHA256 checksums. When we change to a different source code versio, the checksum changes too. And need to be updated. $ eb --force --inject-checksums sha256 RELION-3.1.2-foss-2020b.eb build the new package as described in Installation above, e.g. $ eb-install-all --robot RELION-3.1.2-foss-2020b.eb","title":"Adapting EasyConfigs"},{"location":"software/EasyBuild.html#tips-and-tricks","text":"Even if EasyBuild tries to simplify the installation process, not always EasyConfigs are Build without issues. There can be several types of issues. Starting form issues in finding exiting packages up to compilation issues.","title":"Tips and tricks"},{"location":"software/EasyBuild.html#more-information","text":"In the EasyBuild output eb_out.* files are issues summarized. Often more details are required. There are more detailed log files created in the temporary directory. On the compute nodes they are deleted at the end of the job, but on the login node (ivy) they are kept. The location is mentioned near the end of the output and typically is after Results of the build can be found in the log file .","title":"More information"},{"location":"software/EasyBuild.html#lock-directories","text":"EasyBuild has a procedure to prevent building the same package (same version, same software stack) using lock files. If eb-install-* crashes due to time limit , the lock files are not removed properly. Therewith the next time you start eb-install-* for that package a message like will be presented at the end of the output: ERROR: Build of /path/to/easyconfig.eb failed ( err: 'build failed (first 300 chars): Lock /path/to/.locks/packageVersion.lock already exists, aborting!' ) In that moment the lock file should be already removed and the process can finally be started successfully again.","title":"Lock directories"},{"location":"software/EasyBuild.html#hidden-modules","text":"Sometimes packages are not defined consistently. On UBELIX many packages are provided as hidden modules. This keeps the list nice and tidy. Nevertheless, if a package (or worse one of its dependency) is looking for an existing packages, but it is not mentioned to be hidden, it will not find and need to rebuild again. Hidden packages can be searched using module --show-hidden avail <PackageXYZ> . If existing as hidden and the target package or dependency does not define it as hidden, EasyBuild can be advised to treat it as hidden using the --hide-deps option. E.g. for binutils, gettext and Mesa, the command would look like: $ eb-install-all --hide-deps = binutils,gettext,Mesa <PackageXYZ>","title":"Hidden Modules"},{"location":"software/EasyBuild.html#directly-on-the-compute-node","text":"The eb-install-all tool builds the packages directly on a compute node. The node type can be limited/specified by using the option --archs=<type> (see eb-install-all --help ). If this fails, an investigation step may be running directly on the node, without more control of the setup, e.g. build directories. Therefore, EasyBuild can be started directly in a session on the compute node. First, an interactive session is established on the compute node. For example building Relion in the $HOME on an epyc2 node using a local copy of the EasyConfig file: $ srun --pty --partition epyc2 bash $ module load Workspace_Home EasyBuild $ eb --tmpdir = $TMPDIR --robot --hide-deps = binutils,gettext,Mesa RELION-3.1.3-fosscuda-2020b.eb This may also be used when compiling on a specific GPU architecture.","title":"Directly on the compute node"},{"location":"software/JupyterLab.html","text":"Jupyter Lab Description Some useful information on using Jupyter Lab on UBELIX compute nodes. IMPORTANT: in the following we show how to start the server on a compute node. Please keep in mind that these resources will be dedicated for you, thus and idle session will waste resources. Please quit your session as soon as you don\u2019t use it anymore , even for a lunch break. Your notebook will maintain all you input/output. Overview On UBELIX we provide Jupyter Lab for working with Jupyter Notebooks. JupyterLab is a single-user web-based Notebook server, running in the user space. JupyterLab servers should be started preferably on a compute node, especially for compute intensive or memory intensive workloads. After starting the Jupyter Lab server your local browser can be connected using port forwarding. Therefore port forwarding needs to be enabled properly. On this page we describe: Launch JupyterLab Connect to UBELIX and establishing SSH port forwarding SSH with port forwarding Launch the JupyterLab server Launch JupyterLab in your local browser Kernels Packages Launch JupyterLab Since JupyterLab is a web based application, a port needs to be forwarded to your local machine, where your browser can connect to. This port numbers need to be between 2000 and 65000 and need to be unique on the present machine. The default port for JupyterLab is 8888, but only one user can use this at a time. To avoid the need for modifying the following procedure again and again, we suggest to (once) select a unique number (between 2000 and 65000). And then following commands can be hopefully reused without modification. The port needs to be specified while establishing the connection to UBELIX and while launching JupyterLab. In the following we use the port number 15051 ( please select another number ). Passwordless SSH within the HPCs Please verify that you created and registered a SSH key within UBLEIX. If you can perform the following command without entering your password your are ready to go: ssh localhost otherwise create and register a new key on a login node . ssh-keygen -t rsa -b 4096 # without passphrase cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys chmod 640 .ssh/authorized_keys This creates a ssh key pair on the login node, which than can be used for any ssh sessions within UBELIX. Setup SSH with port forwarding First, the port forwarding needs to be enabled between your local machine and UBELIX. Therewith a local port will be connected to the remote port on UBELIX. This ports are numbers between 2000 and 65000, which needs to be unique on the both sides. The default port for JupyterLab is 8888, but only one user can use this at a time. For simplicity, we kept both numbers the same (here 15051). This can be specified on the command line in the terminal. The ssh command from your local machine to the ubelix login node needs to be called with following arguments: ssh -Y -L 15051:localhost:15051 <username>@submit.unibe.ch If configured in your .ssh/config , you can also use the alias instead of the full name for UBELIX. Where <username> is you campus account name. Note: MobaXterm has an internal terminal which acts like a linux terminal and can be configured as described in the Standard Terminal Setup. Therewith, the SSH command line approach above can be used. Launch the JupyterLab server On UBELIX, the required Anaconda3 module needs to be loaded. If you want to use additional kernels (R) you need to load additional modules, e.g. IRkernel (for R kernels): module load Anaconda3 A script is provided, taking care of enabling the port forwarding to the compute node and launching JupyterLab. jupyter-compute 15051 --time=00:45:00 # please change port number This tool will lauch the server on a compute node, and establish the port forwarding. After general output, JupyterLab prints a URL with a unique key and the network port number where the web-server is listening, this should look similar to: ... [C 21:43:35.291 LabApp] To access the notebook, open this file in a browser: file:///gpfs/homefs/id/ms20e149/.local/share/jupyter/runtime/nbserver-30194-open.html Or copy and paste one of these URLs: http://anode001:15051/?token=69ba5d24acab5915f2520c008a57df51f3cc38b7050ea073 or http://127.0.0.1:15051/?token=69ba5d24acab5915f2520c008a57df51f3cc38b7050ea073 The last line needs to be copied in your local browser. Attention do not use Ctrl + C for copying the link, this will abort the server process and kill your job. QOS the jupyter-compute tool uses an special lsf Quality of Service (QoS), which should reduce queuing times for interactive jobs. Since interactive jobs are considered to be finished within less than a working day, the walltime limit cannot exceed 8h (default run time is 6h, afterwards you are expected to have a break ;) ). You can disable that qos using the option --no-qos , but please release the resources as soon as you are not actively working with the resources anymore. JupyterLab in your local browser The full address on the last line (starting with the 127.0.0.1) of the Jupyter Server statement including the token needs to be copied into your browser on your local machine. After initializing Jupyter Lab you should see a page similar to: Therewith the Notebook and its containing tasks are performed on a compute node, which can double check e.g. using using the following in Python: import socket print(socket.gethostname()) IMPORTANT: Please remember to stop your Jupyter Lab server and therewith your lsf job, when you do not need it anymore. Thus, the resource get available to other users again. Note: After stopping the JupyterLab server some sessions may get corrupted and do not take input correctly anymore. In this case just quit and re-establish your ssh session. JupyterLab with multiple CPU cores More resources can be requested, e.g. by using: jupyter-compute 15051 --ntasks 1 --time=01:00:00 --cpus-per-task 5 --mem 512MB Where 5 cores are requested for threading and a total memory of 3GB. Please do not use multiprocessing.cpu_count() since this is returning the total amount of cores on the node. Furthermore, if you use libraries, which implement threading: align the numbers of threads (often called jobs) to the selected number of cores (otherwise the performance will be affected). OR requesting GPU resources on a node with a NVIDIA graphics card: jupyter-compute 15051 --ntasks 1 --time=01:00:00 --partition=gpu --gres=gpu:gtx1080ti:1 Kernels The following JupyterLab kernel are installed: Python3 R R verify that the module IRkernel is loaded module load IRkernel Packages There are a long list of default packages provided by Anaconda3 (list all using !pip list ) and R (list using installed.packages(.Library) , note the list is shortened). Furthermore, you can install additional packages in Python using pip install --user or in R using install.packages(\"sampling\") .","title":"JupyterLab"},{"location":"software/JupyterLab.html#jupyter-lab","text":"","title":"Jupyter Lab"},{"location":"software/JupyterLab.html#description","text":"Some useful information on using Jupyter Lab on UBELIX compute nodes. IMPORTANT: in the following we show how to start the server on a compute node. Please keep in mind that these resources will be dedicated for you, thus and idle session will waste resources. Please quit your session as soon as you don\u2019t use it anymore , even for a lunch break. Your notebook will maintain all you input/output.","title":"Description"},{"location":"software/JupyterLab.html#overview","text":"On UBELIX we provide Jupyter Lab for working with Jupyter Notebooks. JupyterLab is a single-user web-based Notebook server, running in the user space. JupyterLab servers should be started preferably on a compute node, especially for compute intensive or memory intensive workloads. After starting the Jupyter Lab server your local browser can be connected using port forwarding. Therefore port forwarding needs to be enabled properly. On this page we describe: Launch JupyterLab Connect to UBELIX and establishing SSH port forwarding SSH with port forwarding Launch the JupyterLab server Launch JupyterLab in your local browser Kernels Packages","title":"Overview"},{"location":"software/JupyterLab.html#launch-jupyterlab","text":"Since JupyterLab is a web based application, a port needs to be forwarded to your local machine, where your browser can connect to. This port numbers need to be between 2000 and 65000 and need to be unique on the present machine. The default port for JupyterLab is 8888, but only one user can use this at a time. To avoid the need for modifying the following procedure again and again, we suggest to (once) select a unique number (between 2000 and 65000). And then following commands can be hopefully reused without modification. The port needs to be specified while establishing the connection to UBELIX and while launching JupyterLab. In the following we use the port number 15051 ( please select another number ).","title":"Launch JupyterLab"},{"location":"software/JupyterLab.html#passwordless-ssh-within-the-hpcs","text":"Please verify that you created and registered a SSH key within UBLEIX. If you can perform the following command without entering your password your are ready to go: ssh localhost otherwise create and register a new key on a login node . ssh-keygen -t rsa -b 4096 # without passphrase cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys chmod 640 .ssh/authorized_keys This creates a ssh key pair on the login node, which than can be used for any ssh sessions within UBELIX.","title":"Passwordless SSH within the HPCs"},{"location":"software/JupyterLab.html#setup-ssh-with-port-forwarding","text":"First, the port forwarding needs to be enabled between your local machine and UBELIX. Therewith a local port will be connected to the remote port on UBELIX. This ports are numbers between 2000 and 65000, which needs to be unique on the both sides. The default port for JupyterLab is 8888, but only one user can use this at a time. For simplicity, we kept both numbers the same (here 15051). This can be specified on the command line in the terminal. The ssh command from your local machine to the ubelix login node needs to be called with following arguments: ssh -Y -L 15051:localhost:15051 <username>@submit.unibe.ch If configured in your .ssh/config , you can also use the alias instead of the full name for UBELIX. Where <username> is you campus account name. Note: MobaXterm has an internal terminal which acts like a linux terminal and can be configured as described in the Standard Terminal Setup. Therewith, the SSH command line approach above can be used.","title":"Setup SSH with port forwarding"},{"location":"software/JupyterLab.html#launch-the-jupyterlab-server","text":"On UBELIX, the required Anaconda3 module needs to be loaded. If you want to use additional kernels (R) you need to load additional modules, e.g. IRkernel (for R kernels): module load Anaconda3 A script is provided, taking care of enabling the port forwarding to the compute node and launching JupyterLab. jupyter-compute 15051 --time=00:45:00 # please change port number This tool will lauch the server on a compute node, and establish the port forwarding. After general output, JupyterLab prints a URL with a unique key and the network port number where the web-server is listening, this should look similar to: ... [C 21:43:35.291 LabApp] To access the notebook, open this file in a browser: file:///gpfs/homefs/id/ms20e149/.local/share/jupyter/runtime/nbserver-30194-open.html Or copy and paste one of these URLs: http://anode001:15051/?token=69ba5d24acab5915f2520c008a57df51f3cc38b7050ea073 or http://127.0.0.1:15051/?token=69ba5d24acab5915f2520c008a57df51f3cc38b7050ea073 The last line needs to be copied in your local browser. Attention do not use Ctrl + C for copying the link, this will abort the server process and kill your job. QOS the jupyter-compute tool uses an special lsf Quality of Service (QoS), which should reduce queuing times for interactive jobs. Since interactive jobs are considered to be finished within less than a working day, the walltime limit cannot exceed 8h (default run time is 6h, afterwards you are expected to have a break ;) ). You can disable that qos using the option --no-qos , but please release the resources as soon as you are not actively working with the resources anymore.","title":"Launch the JupyterLab server"},{"location":"software/JupyterLab.html#jupyterlab-in-your-local-browser","text":"The full address on the last line (starting with the 127.0.0.1) of the Jupyter Server statement including the token needs to be copied into your browser on your local machine. After initializing Jupyter Lab you should see a page similar to: Therewith the Notebook and its containing tasks are performed on a compute node, which can double check e.g. using using the following in Python: import socket print(socket.gethostname()) IMPORTANT: Please remember to stop your Jupyter Lab server and therewith your lsf job, when you do not need it anymore. Thus, the resource get available to other users again. Note: After stopping the JupyterLab server some sessions may get corrupted and do not take input correctly anymore. In this case just quit and re-establish your ssh session.","title":"JupyterLab in your local browser"},{"location":"software/JupyterLab.html#jupyterlab-with-multiple-cpu-cores","text":"More resources can be requested, e.g. by using: jupyter-compute 15051 --ntasks 1 --time=01:00:00 --cpus-per-task 5 --mem 512MB Where 5 cores are requested for threading and a total memory of 3GB. Please do not use multiprocessing.cpu_count() since this is returning the total amount of cores on the node. Furthermore, if you use libraries, which implement threading: align the numbers of threads (often called jobs) to the selected number of cores (otherwise the performance will be affected). OR requesting GPU resources on a node with a NVIDIA graphics card: jupyter-compute 15051 --ntasks 1 --time=01:00:00 --partition=gpu --gres=gpu:gtx1080ti:1","title":"JupyterLab with multiple CPU cores"},{"location":"software/JupyterLab.html#kernels","text":"The following JupyterLab kernel are installed: Python3 R","title":"Kernels"},{"location":"software/JupyterLab.html#r","text":"verify that the module IRkernel is loaded module load IRkernel","title":"R"},{"location":"software/JupyterLab.html#packages","text":"There are a long list of default packages provided by Anaconda3 (list all using !pip list ) and R (list using installed.packages(.Library) , note the list is shortened). Furthermore, you can install additional packages in Python using pip install --user or in R using install.packages(\"sampling\") .","title":"Packages"},{"location":"software/ParaView.html","text":"ParaView Description This article note specific information for launching ParaView Server on compute nodes and connect local ParaView with it. Prerequisites Passwordless SSH need to be activated as well as connection established with Port forwarding . Furthermore, the local (on your local machine) ParaView version need to match the version loaded on the HPCs. Launch ParaView server First, as mentioned, establish a SSH session with Port forwarding , another port in the range [2000-65000] should be selected: ssh -Y -L 15051 :localhost:15051 submit.unibe.ch Then load the modules: module load ParaView The ParaView version can be displayed using: module list ParaView Currently Loaded Modules Matching: ParaView 1 ) ParaView/5.8.1-foss-2020b-mpi Thus, in this example ParaView 5.8.1 need to be used in the local machine. To start the ParaView server on a compute node you can use: pvserver-parallel 15051 ### use your selected port number This submits a job with 1 core for 1h in the epyc2 partition. The tool prints a reminder to stop the job if not required anymore and shows the queueing information regularly: ParaView remote Server submitted to compute nodes when finished please kill the server using: scancel 2394231 job 2394231 status: JOBID PARTITION STATE START_TIME 2394231 epyc2 PENDING N/A pvserver ready to connect on port 15051 . When finished, please stop ParaView Server using scancel 2394231 Please cancel your job with scancel $JOBID or all your running jobs using scancel -u $USER if not needed anymore. Additional resources can be requested by --lsf-args=\"\" option with the desired lsf options, e.g. 3 cores for 20 min : pvserver-parallel 15051 --lsf-args = \"--cpus-per-task=3 --time=00:20:00\" In addition ParaView arguments can be added without any prefix. Connect local client Finally, the client on your local machine can connect using localhost and the selected port, here 15051 . E.g. using pvpython : pvpython WARNING: Python 2 .7 is not recommended. This version is included in macOS for compatibility with legacy software. Future versions of macOS will not include Python 2 .7. Instead, it is recommended that you transition to using 'python3' from within Terminal. Python 2 .7.16 ( default, May 8 2021 , 11 :48:02 ) [ GCC Apple LLVM 12 .0.5 ( clang-1205.0.19.59.6 ) [ +internal-os, ptrauth-isa = deploy on darwin Type \"help\" , \"copyright\" , \"credits\" or \"license\" for more information. >>> from paraview.simple import * >>> Connect ( \"localhost\" , 15051 ) Connection ( cs://localhost:15051 ) [ 2 ]","title":"ParaView"},{"location":"software/ParaView.html#paraview","text":"","title":"ParaView"},{"location":"software/ParaView.html#description","text":"This article note specific information for launching ParaView Server on compute nodes and connect local ParaView with it.","title":"Description"},{"location":"software/ParaView.html#prerequisites","text":"Passwordless SSH need to be activated as well as connection established with Port forwarding . Furthermore, the local (on your local machine) ParaView version need to match the version loaded on the HPCs.","title":"Prerequisites"},{"location":"software/ParaView.html#launch-paraview-server","text":"First, as mentioned, establish a SSH session with Port forwarding , another port in the range [2000-65000] should be selected: ssh -Y -L 15051 :localhost:15051 submit.unibe.ch Then load the modules: module load ParaView The ParaView version can be displayed using: module list ParaView Currently Loaded Modules Matching: ParaView 1 ) ParaView/5.8.1-foss-2020b-mpi Thus, in this example ParaView 5.8.1 need to be used in the local machine. To start the ParaView server on a compute node you can use: pvserver-parallel 15051 ### use your selected port number This submits a job with 1 core for 1h in the epyc2 partition. The tool prints a reminder to stop the job if not required anymore and shows the queueing information regularly: ParaView remote Server submitted to compute nodes when finished please kill the server using: scancel 2394231 job 2394231 status: JOBID PARTITION STATE START_TIME 2394231 epyc2 PENDING N/A pvserver ready to connect on port 15051 . When finished, please stop ParaView Server using scancel 2394231 Please cancel your job with scancel $JOBID or all your running jobs using scancel -u $USER if not needed anymore. Additional resources can be requested by --lsf-args=\"\" option with the desired lsf options, e.g. 3 cores for 20 min : pvserver-parallel 15051 --lsf-args = \"--cpus-per-task=3 --time=00:20:00\" In addition ParaView arguments can be added without any prefix.","title":"Launch ParaView server"},{"location":"software/ParaView.html#connect-local-client","text":"Finally, the client on your local machine can connect using localhost and the selected port, here 15051 . E.g. using pvpython : pvpython WARNING: Python 2 .7 is not recommended. This version is included in macOS for compatibility with legacy software. Future versions of macOS will not include Python 2 .7. Instead, it is recommended that you transition to using 'python3' from within Terminal. Python 2 .7.16 ( default, May 8 2021 , 11 :48:02 ) [ GCC Apple LLVM 12 .0.5 ( clang-1205.0.19.59.6 ) [ +internal-os, ptrauth-isa = deploy on darwin Type \"help\" , \"copyright\" , \"credits\" or \"license\" for more information. >>> from paraview.simple import * >>> Connect ( \"localhost\" , 15051 ) Connection ( cs://localhost:15051 ) [ 2 ]","title":"Connect local client"},{"location":"software/bzip2.html","text":"Parallel BZIP2 Description Data need to be packed and compressed for archiveing or transfer. There are multiple tools available like tar and gzip, bzip. Pbzip2 is a paeallel implementation of bzip2. For general information see bzip2 and pbzip2 Availability The tool is available on all nodes without loading any module. Usage Parallel packing and compressing can be performed on a compute node using tar with a specified number of threads As an example, a file or directory /data/to/pack can be packed and compressed into a file /packed/file.tar.bz2 using the job script: #SBATCH --job-name=\"pbzip2\" #SBATCH --time=01:00:00 #SBATCH --mem-per-cpu=2G ## For parallel jobs with 8 cores #SBATCH --cpus-per-task=8 ## select the amount of cores required source = \"data/to/pack\" ## specify your data to compress target = \"/packed/file.tar.bz2\" ## specify directory and filename # archive dir data_unibe to a tar file and compress it using pbzip2 srun tar -cS $source | pbzip2 -p $lsf_CPUS_PER_TASK > $target # Generate a sha256 fingerprint, to later check the integrity sha256sum $target > ${ target } .sha256sum","title":"Parallel BZIP2"},{"location":"software/bzip2.html#parallel-bzip2","text":"","title":"Parallel BZIP2"},{"location":"software/bzip2.html#description","text":"Data need to be packed and compressed for archiveing or transfer. There are multiple tools available like tar and gzip, bzip. Pbzip2 is a paeallel implementation of bzip2. For general information see bzip2 and pbzip2","title":"Description"},{"location":"software/bzip2.html#availability","text":"The tool is available on all nodes without loading any module.","title":"Availability"},{"location":"software/bzip2.html#usage","text":"Parallel packing and compressing can be performed on a compute node using tar with a specified number of threads As an example, a file or directory /data/to/pack can be packed and compressed into a file /packed/file.tar.bz2 using the job script: #SBATCH --job-name=\"pbzip2\" #SBATCH --time=01:00:00 #SBATCH --mem-per-cpu=2G ## For parallel jobs with 8 cores #SBATCH --cpus-per-task=8 ## select the amount of cores required source = \"data/to/pack\" ## specify your data to compress target = \"/packed/file.tar.bz2\" ## specify directory and filename # archive dir data_unibe to a tar file and compress it using pbzip2 srun tar -cS $source | pbzip2 -p $lsf_CPUS_PER_TASK > $target # Generate a sha256 fingerprint, to later check the integrity sha256sum $target > ${ target } .sha256sum","title":"Usage"},{"location":"software/hpc-modules.html","text":"HPC software environment Description On UBELIX the default shell is Bash. With the operation system, a list of basic tools (mainly command line tools) are provided, including editors, file analyzing and manipulation tools, packing and transfer tools etc. This commands are accessible all the time. Other software packages (libraries and applications) are available via the LMOD (lua modules) modules. By the help of this tool a lot of different packages even in different versions can be provided, without unwanted influences. Furthermore, software stacks are provided one for each CPU architecture. These are loaded automatically on the related architecture, transparent to the user. Additionally to our software stack, VITAL-IT provides a software stack targeting mainly bioinformatics users, see Bioinformatics Software . Basic concept Many Linux settings are in environment variables. These include search paths for applications ( $PATH ) and libraries ( $LD_LIBRARY_PATH ). Adding or removing a directory to these lists, provides access or remove access to additional software. The LMOD modules are an user friendly way to search and manage software packages without dealing with complicated directory names. In general every software package has its related module. When loading the module the software package and its dependencies get accessible. But let\u2019s do it step by step. List available Modules There are various ways to search for a software package. You can list all currently available packages using: module avail You can search for an packages starting with a specific string, e.g. all version of GCC: module avail GCC Furthermore, the following command lists you all the modules containing a certain sub-string in the name, even in other software stacks, e.g.: module spider Assembler In the example above all modules with the sub-string Assembler will be listed, in this case the ones from the Vital-It software stack. Load/Add a Modules Loading a module will provide access to the software package and it will additionally load all required dependencies. module load OpenMPI/3.1.3-GCC-8.2.0-2.31.1 or equivalently: $ module add OpenMPI/3.1.3-GCC-8.2.0-2.31.1 This will provide access to OpenMPI, but also to GCC and other libraries. With this principle it is verified that the library versions are loaded, which were used to build the package. List all Loaded Modules You can list the currently loaded modules using $ module list Currently Loaded Modules: 1 ) GCCcore/8.2.0 2 ) zlib/.1.2.11-GCCcore-8.2.0 ( H ) 3 ) binutils/.2.31.1-GCCcore-8.2.0 ( H ) 4 ) GCC/8.2.0-2.31.1 5 ) numactl/2.0.12-GCCcore-8.2.0 6 ) XZ/.5.2.4-GCCcore-8.2.0 ( H ) 7 ) libxml2/.2.9.8-GCCcore-8.2.0 ( H ) 8 ) libpciaccess/.0.14-GCCcore-8.2.0 ( H ) 9 ) hwloc/1.11.11-GCCcore-8.2.0 10 ) OpenMPI/3.1.3-GCC-8.2.0-2.31.1 Where: H: Hidden Module Toolchains / version consistency When loading multiple modules it is strongly suggested to stay within one toolchain version . A toolchain is a set of modules all building on top of each other. The related packages and versions can be listed with the command above. There are two basic toolchains which are build up on top of GCC and Intel: Toolchain packages GCC GCC compiler gompi GCC, OpenMPI gompic GCC, OpenMPI, CUDA foss GCC, OpenMPI, OpenBLAS, FFTW, ScaLAPACK fosscuda GCC, OpenMPI, OpenBLAS, FFTW, ScaLAPACK, CUDA intel Intel compiler, (GCC required), MKL, Intel MPI iompi Intel compiler, OpenMPI iomkl Intel compiler, OpenMPI, MKL Furthermore, toolchains are provided in different versions and updated regularly. When loading multiple packages, they should be based on the same toolchain and the same version . In the following are two examples where netCDF and FFTW should be loaded, but the based toolchains and versions do not match. Problematic example: different toolchains module load netCDF/4.7.3-gompi-2019b module load FFTW/3.3.8-intel-2019b NetCDF is loaded in the gompi toolchain, including OpenMPI. FFTW is loaded in the intel toolchain, including iimpi (IntelMPI). Beside other, now two different MPI implementation are loaded. We cannot verify that each package uses the MPI library it is build with. In best case this leads to errors during run time. In worse case results are incorrect. Problematic example: toolchain versions $ module load netCDF/4.7.4-gompi-2020b $ module load FFTW/3.3.7-gompi-2018a The following have been reloaded with a version change: 1) GCC/10.2.0 => GCC/6.4.0-2.28 5) gompi/2020b => gompi/2018a 2) GCCcore/10.2.0 => GCCcore/6.4.0 6) hwloc/2.2.0-GCCcore-10.2.0 => hwloc/1.11.8-GCCcore-6.4.0 3) OpenMPI/4.0.5-GCC-10.2.0 => OpenMPI/2.1.2-GCC-6.4.0-2.28 7) numactl/2.0.13-GCCcore-10.2.0 => numactl/2.0.11-GCCcore-6.4.0 4) binutils/.2.35-GCCcore-10.2.0 => binutils/.2.28-GCCcore-6.4.0 LMOD already notes the version changes. In this case, netCDF build with 2020a version will utilize libraries of 2018a. If interfaces have changed, errors may occur . Unload/remove Modules To prevent unwanted influences between software packages, it is advisable to keep the loaded software stack small and clean. Certain modules can be unloaded using: $ module unload OpenMPI/3.1.3-GCC-8.2.0-2.31.1 or equivalently: $ module rm OpenMPI/3.1.3-GCC-8.2.0-2.31.1 This will only unload the specified module. Dependencies stay loaded, which were automatically loaded when loading the specified modulefile. A clean environment can be obtained with purge (see below). Purge all Modules All currently loaded modules an be unloaded using: $ module purge Show information Most modules provide a short description which software package they contain and a link to the homepage, as well as information about the changes of environment undertaken. From short to full detail: $ module whatis OpenMPI $ module help OpenMPI $ module show OpenMPI Environment definitions Working on different projects or with different types of task may require to load different sets of modules. There are two ways of providing a user environment setups, e.g. for development, production, post processing etc., a custom module (also for Workspaces) or a module user collections (per user). Adding module load into .bashrc may lead to issues. If you diverge from this \u201cdefault\u201d environment and additionally load conflicting modules, e.g. form another toolchain. Custom Modules A so called \u201cMeta Module\u201d can be used to specify a set of modules. Additionally, environment variables can be defined. These custom modules can be placed in the custom software stack, e.g. in a Workspace. Thus default working environments could be defined for the users that workspace. You may want to decide if you want to specify the environment with all versions of the modules (advisable), or always the latest versions (no version specified). The modules can be placed into $WORKSPACE/modulefiles/$NAME/$VERSION.lua . Example: Lua module for development environment Here an environment is defined using foss and netCDF of version 2021a. Additionally an environment variable WS_ENV is set to devel . Therefore, a file $WORKSPACE/modulefiles/WS_devel/2021a.lua is created with the following content: whatis ( [==[Description: Workspace XXX development environment]==] ) if not ( isloaded ( \"foss/2021a\" ) ) then load ( \"foss/2021a\" ) end if not ( isloaded ( \"netCDF/4.8.0-gompi-2021a\" ) ) then load ( \"netCDF/4.8.0-gompi-2021a\" ) end setenv ( \"WS_ENV\" , \"devel\" ) setenv ( \"CFLAGS\" , \"-DNDEBUG\" ) The all workspace members can load this environment using: module purge ### better start with a clean environment module load Workspace WS_devel Module User Collections Sets of modules can be stored and reloaded in LMOD using the \u201cuser collection\u201d feature. As an example, a set of module for development consiting of SciPy-bundle and netCDF should be stored under the name devel . Further module lists can be managed in the same way (here lists for test and prod already exist). $ module load SciPy-bundle netCDF $ module save devel Saved current collection of modules to: \"devel\" $ module savelist Named collection list : 1 ) devel 2 ) test 3 ) prod Therewith the set of modules can be loaded using: $ module restore devel This will unload all other previously loaded modules beforehand and then load the set specified in the collection. This method is preferred against defining/loading a set of modules in Bash configuration like .bashrc. More information can be found in the LMOD documentation Bioinformatics Software In co-operation with the Vital-IT Group of the SIB Swiss Institute of Bioinformatics , a large set of bioinformatics software tools and databases is available to the life science community. To list all modulefiles provided by Vital-IT, you have to first load the vital-it module: Loading the vital-it modulefile automatically configures the environment to use specific versions of selected software, e.g. python v2.7.5, and gcc v4.9.1 $ module load vital-it && module avail Modules background Architectural software stacks On our HPCs we use LMOD (Lua modules) to provide access to different software packages and different versions. Beside different packages and versions, we provide software stacks build for the different CPU architectures. This enables us to have the packages build e.g. with AVX2 for Broadwell CPUs, but also a version with only SSE4 for Ivybridge CPUs. These software stacks are completely transparent to the user and will be used automatically when loading a module on the related architecture. If you want to build your own software build for specific Hardware, we provide tools which help you, see Installing Custom Software Scientific Software Management Our scientific software stack, available via module files are mainly build with EasyBuild. This tool helps us to install and maintain software packages and recycle existing installation procedures. There are plenty of install instructions available EasyBuild/Easyconfigs , which can be installed also in the user space with low effort, see Installing Custom Software Custom modules Modules are able to define the users environment. This includes accessibility to software packages, including settings for libraries and setting environment variables. On UBELIX we use LMOD. Therewith, lua as well as TCL modules can be used.","title":"HPC software environment"},{"location":"software/hpc-modules.html#hpc-software-environment","text":"","title":"HPC software environment"},{"location":"software/hpc-modules.html#description","text":"On UBELIX the default shell is Bash. With the operation system, a list of basic tools (mainly command line tools) are provided, including editors, file analyzing and manipulation tools, packing and transfer tools etc. This commands are accessible all the time. Other software packages (libraries and applications) are available via the LMOD (lua modules) modules. By the help of this tool a lot of different packages even in different versions can be provided, without unwanted influences. Furthermore, software stacks are provided one for each CPU architecture. These are loaded automatically on the related architecture, transparent to the user. Additionally to our software stack, VITAL-IT provides a software stack targeting mainly bioinformatics users, see Bioinformatics Software .","title":"Description"},{"location":"software/hpc-modules.html#basic-concept","text":"Many Linux settings are in environment variables. These include search paths for applications ( $PATH ) and libraries ( $LD_LIBRARY_PATH ). Adding or removing a directory to these lists, provides access or remove access to additional software. The LMOD modules are an user friendly way to search and manage software packages without dealing with complicated directory names. In general every software package has its related module. When loading the module the software package and its dependencies get accessible. But let\u2019s do it step by step.","title":"Basic concept"},{"location":"software/hpc-modules.html#list-available-modules","text":"There are various ways to search for a software package. You can list all currently available packages using: module avail You can search for an packages starting with a specific string, e.g. all version of GCC: module avail GCC Furthermore, the following command lists you all the modules containing a certain sub-string in the name, even in other software stacks, e.g.: module spider Assembler In the example above all modules with the sub-string Assembler will be listed, in this case the ones from the Vital-It software stack.","title":"List available Modules"},{"location":"software/hpc-modules.html#loadadd-a-modules","text":"Loading a module will provide access to the software package and it will additionally load all required dependencies. module load OpenMPI/3.1.3-GCC-8.2.0-2.31.1 or equivalently: $ module add OpenMPI/3.1.3-GCC-8.2.0-2.31.1 This will provide access to OpenMPI, but also to GCC and other libraries. With this principle it is verified that the library versions are loaded, which were used to build the package.","title":"Load/Add a Modules"},{"location":"software/hpc-modules.html#list-all-loaded-modules","text":"You can list the currently loaded modules using $ module list Currently Loaded Modules: 1 ) GCCcore/8.2.0 2 ) zlib/.1.2.11-GCCcore-8.2.0 ( H ) 3 ) binutils/.2.31.1-GCCcore-8.2.0 ( H ) 4 ) GCC/8.2.0-2.31.1 5 ) numactl/2.0.12-GCCcore-8.2.0 6 ) XZ/.5.2.4-GCCcore-8.2.0 ( H ) 7 ) libxml2/.2.9.8-GCCcore-8.2.0 ( H ) 8 ) libpciaccess/.0.14-GCCcore-8.2.0 ( H ) 9 ) hwloc/1.11.11-GCCcore-8.2.0 10 ) OpenMPI/3.1.3-GCC-8.2.0-2.31.1 Where: H: Hidden Module","title":"List all Loaded Modules"},{"location":"software/hpc-modules.html#toolchains-version-consistency","text":"When loading multiple modules it is strongly suggested to stay within one toolchain version . A toolchain is a set of modules all building on top of each other. The related packages and versions can be listed with the command above. There are two basic toolchains which are build up on top of GCC and Intel: Toolchain packages GCC GCC compiler gompi GCC, OpenMPI gompic GCC, OpenMPI, CUDA foss GCC, OpenMPI, OpenBLAS, FFTW, ScaLAPACK fosscuda GCC, OpenMPI, OpenBLAS, FFTW, ScaLAPACK, CUDA intel Intel compiler, (GCC required), MKL, Intel MPI iompi Intel compiler, OpenMPI iomkl Intel compiler, OpenMPI, MKL Furthermore, toolchains are provided in different versions and updated regularly. When loading multiple packages, they should be based on the same toolchain and the same version . In the following are two examples where netCDF and FFTW should be loaded, but the based toolchains and versions do not match.","title":"Toolchains / version consistency"},{"location":"software/hpc-modules.html#problematic-example-different-toolchains","text":"module load netCDF/4.7.3-gompi-2019b module load FFTW/3.3.8-intel-2019b NetCDF is loaded in the gompi toolchain, including OpenMPI. FFTW is loaded in the intel toolchain, including iimpi (IntelMPI). Beside other, now two different MPI implementation are loaded. We cannot verify that each package uses the MPI library it is build with. In best case this leads to errors during run time. In worse case results are incorrect.","title":"Problematic example: different toolchains"},{"location":"software/hpc-modules.html#problematic-example-toolchain-versions","text":"$ module load netCDF/4.7.4-gompi-2020b $ module load FFTW/3.3.7-gompi-2018a The following have been reloaded with a version change: 1) GCC/10.2.0 => GCC/6.4.0-2.28 5) gompi/2020b => gompi/2018a 2) GCCcore/10.2.0 => GCCcore/6.4.0 6) hwloc/2.2.0-GCCcore-10.2.0 => hwloc/1.11.8-GCCcore-6.4.0 3) OpenMPI/4.0.5-GCC-10.2.0 => OpenMPI/2.1.2-GCC-6.4.0-2.28 7) numactl/2.0.13-GCCcore-10.2.0 => numactl/2.0.11-GCCcore-6.4.0 4) binutils/.2.35-GCCcore-10.2.0 => binutils/.2.28-GCCcore-6.4.0 LMOD already notes the version changes. In this case, netCDF build with 2020a version will utilize libraries of 2018a. If interfaces have changed, errors may occur .","title":"Problematic example: toolchain versions"},{"location":"software/hpc-modules.html#unloadremove-modules","text":"To prevent unwanted influences between software packages, it is advisable to keep the loaded software stack small and clean. Certain modules can be unloaded using: $ module unload OpenMPI/3.1.3-GCC-8.2.0-2.31.1 or equivalently: $ module rm OpenMPI/3.1.3-GCC-8.2.0-2.31.1 This will only unload the specified module. Dependencies stay loaded, which were automatically loaded when loading the specified modulefile. A clean environment can be obtained with purge (see below).","title":"Unload/remove Modules"},{"location":"software/hpc-modules.html#purge-all-modules","text":"All currently loaded modules an be unloaded using: $ module purge","title":"Purge all Modules"},{"location":"software/hpc-modules.html#show-information","text":"Most modules provide a short description which software package they contain and a link to the homepage, as well as information about the changes of environment undertaken. From short to full detail: $ module whatis OpenMPI $ module help OpenMPI $ module show OpenMPI","title":"Show information"},{"location":"software/hpc-modules.html#environment-definitions","text":"Working on different projects or with different types of task may require to load different sets of modules. There are two ways of providing a user environment setups, e.g. for development, production, post processing etc., a custom module (also for Workspaces) or a module user collections (per user). Adding module load into .bashrc may lead to issues. If you diverge from this \u201cdefault\u201d environment and additionally load conflicting modules, e.g. form another toolchain.","title":"Environment definitions"},{"location":"software/hpc-modules.html#custom-modules","text":"A so called \u201cMeta Module\u201d can be used to specify a set of modules. Additionally, environment variables can be defined. These custom modules can be placed in the custom software stack, e.g. in a Workspace. Thus default working environments could be defined for the users that workspace. You may want to decide if you want to specify the environment with all versions of the modules (advisable), or always the latest versions (no version specified). The modules can be placed into $WORKSPACE/modulefiles/$NAME/$VERSION.lua .","title":"Custom Modules"},{"location":"software/hpc-modules.html#example-lua-module-for-development-environment","text":"Here an environment is defined using foss and netCDF of version 2021a. Additionally an environment variable WS_ENV is set to devel . Therefore, a file $WORKSPACE/modulefiles/WS_devel/2021a.lua is created with the following content: whatis ( [==[Description: Workspace XXX development environment]==] ) if not ( isloaded ( \"foss/2021a\" ) ) then load ( \"foss/2021a\" ) end if not ( isloaded ( \"netCDF/4.8.0-gompi-2021a\" ) ) then load ( \"netCDF/4.8.0-gompi-2021a\" ) end setenv ( \"WS_ENV\" , \"devel\" ) setenv ( \"CFLAGS\" , \"-DNDEBUG\" ) The all workspace members can load this environment using: module purge ### better start with a clean environment module load Workspace WS_devel","title":"Example: Lua module for development environment"},{"location":"software/hpc-modules.html#module-user-collections","text":"Sets of modules can be stored and reloaded in LMOD using the \u201cuser collection\u201d feature. As an example, a set of module for development consiting of SciPy-bundle and netCDF should be stored under the name devel . Further module lists can be managed in the same way (here lists for test and prod already exist). $ module load SciPy-bundle netCDF $ module save devel Saved current collection of modules to: \"devel\" $ module savelist Named collection list : 1 ) devel 2 ) test 3 ) prod Therewith the set of modules can be loaded using: $ module restore devel This will unload all other previously loaded modules beforehand and then load the set specified in the collection. This method is preferred against defining/loading a set of modules in Bash configuration like .bashrc. More information can be found in the LMOD documentation","title":"Module User Collections"},{"location":"software/hpc-modules.html#bioinformatics-software","text":"In co-operation with the Vital-IT Group of the SIB Swiss Institute of Bioinformatics , a large set of bioinformatics software tools and databases is available to the life science community. To list all modulefiles provided by Vital-IT, you have to first load the vital-it module: Loading the vital-it modulefile automatically configures the environment to use specific versions of selected software, e.g. python v2.7.5, and gcc v4.9.1 $ module load vital-it && module avail","title":"Bioinformatics Software"},{"location":"software/hpc-modules.html#modules-background","text":"","title":"Modules background"},{"location":"software/hpc-modules.html#architectural-software-stacks","text":"On our HPCs we use LMOD (Lua modules) to provide access to different software packages and different versions. Beside different packages and versions, we provide software stacks build for the different CPU architectures. This enables us to have the packages build e.g. with AVX2 for Broadwell CPUs, but also a version with only SSE4 for Ivybridge CPUs. These software stacks are completely transparent to the user and will be used automatically when loading a module on the related architecture. If you want to build your own software build for specific Hardware, we provide tools which help you, see Installing Custom Software","title":"Architectural software stacks"},{"location":"software/hpc-modules.html#scientific-software-management","text":"Our scientific software stack, available via module files are mainly build with EasyBuild. This tool helps us to install and maintain software packages and recycle existing installation procedures. There are plenty of install instructions available EasyBuild/Easyconfigs , which can be installed also in the user space with low effort, see Installing Custom Software","title":"Scientific Software Management"},{"location":"software/hpc-modules.html#custom-modules_1","text":"Modules are able to define the users environment. This includes accessibility to software packages, including settings for libraries and setting environment variables. On UBELIX we use LMOD. Therewith, lua as well as TCL modules can be used.","title":"Custom modules"},{"location":"software/installing-custom-software.html","text":"Installing Custom Software Description UBELIX comes with a plethora of software pre-installed. And there are tools provided installing additional packages in the user/group space. The present CustomRepo and Workspace modules provide easy access even for multiple versions of the same Software package. The command module avail lists the available packages and module spider FFTW searches for all modules which have FFTW in their name. This article describes a procedure for installing custom software stacks in your user/group space. An EasyBuild and a manual approach is presented. Note You cannot use the packet management utility yum for this, since this command requires root privileges to install software system wide. Instead you have to compile and install the software yourself. Note If you know that some missing software could be of general interest for a wide community on our machines, you can ask us to install the software system wide. Bioinformatic packages are managed by Vital-IT Note If you need further assistance in installing your software packages or optimizing for our machine architecture, get in touch with our support team. The LMOD module system allows to enable software package by package. Thus, influences between different packages can be minimized. It also allows to have multiple versions of the same software product installed side by side. See HPC software environment . There are modules providing access to your user/group software stacks and assisting you with building packages into them. When possible we use EasyBuild to provision software packages. EasyBuild is a software installation framework. Installation procedures are defined in so called EasyConfigs, including the location of the sources, dependencies, its versions, used environments, compile arguments, and more. These EasyConfigs are publicly available on EasyBuild github repository and can be downloaded used and if necessary adapted, e.g. for new versions. Building Software packages There are mainly two options to build a software package and its module: using EasyBuild , with an existing, an modified or a newly created EasyConfig performing manual installation , and creating a module file In the following, both methods are described in more details. In general we consider: Is there already and EasyBuild recipe available, which can be used or modified? Which software stack we want to build into, a specific CPU architecture, OR all CPU architectures, OR should it be a generic one (see Software stacks ) Software stacks On UBELIX a software stack for each CPU architecture is provided. Applications are build on and for this specific architecture. Therewith, application can use different optimizations on different architectures, e.g. using AVX2 instruction set on Broadwell). Furthermore, a generic software stack is provided, where architecture independent applications are installed, e.g. Python scripts. Our generic software stack is build on Ivybridge nodes, which have the lowest instruction set. Therewith runtime conflicts are prevented. For EasyBuild additional tools are provided, which install automatically in all architectural or the generic software stack, see below. Additionally, with the Workspace and Workspace_Home module such software stacks can be created in your user/group space. EasyBuild For detailed instructions read the EasyBuild article . If you are installing your own application you may want to consider to create an EasyConfig for it. Have a look in the EasyBuild documentation , examples on the EasyBuild github . And if necessary ask our support team for assistance. Python and R For many python and R packages EasyConfig exist. These can be used to install the package like all other EasyBuild packages. See EasyBuild article . Alternatively, you can use the Python/R package manager and advice them to install into your HOME/Workspace directory. Please see the Python or R pages. Manually compiling There are very different ways of manually installing software packages, starting from just using a compiler, having a makefile, up to complex build systems. A few considerations need to kept in mind while building for our systems: Compilers: different compilers are available and can be loaded by modules. Toolchains bundle compiler with additionally libraries and tools, like MPI, FFTW, MKL, see Toolchains . Furthermore, complex algorithms are optimised differently in the compilers. It is worthwhile to try and compare multiple compilers. CPU architectures: since there are different CPU architectures available, applications should be build for the targeted architecture. Often significant performance improvements can be obtained compiling for the correct instruction sets. Therefore, launch your build processes on the targeted architecture. Accessibility: On the one hand probably different versions, e.g. for compiler and CPU architecture should be provided. On the other hand the access to it should be as easy as possible for all users of that package. Therefore, modules provide a user-friendly. These modules can be organized e.g. in software stacks, one for each architecture. One and probably the most used procedure is the GNU configure / make: tar xzvf some-software-0.1.tar.gz cd some-software-0.1 ./configure --prefix = /path/to/target/some-software/0.1 make make install make clean Note Consider creating an Easyconfig if you already have a well tested procedure, see EasyBuild . configure is usually a complex shell script that gathers information about the system and prepares the compile process. With the --prefix option you can specify a base installation directory, where make install will install the files into subdirectories like bin , lib , include , etc. The make utility is what does the actual compiling and linking. If, for example, some additional libraries are missing on the system or not found in the expected location, the command will exit immediately. Detailed documentation can be found on the GNU make documentation page Software Stacks with Modules The Workspace module module provide a pre-defined setup where software stacks for the different CPU architectures as well as a generic one is accessible by default. After loading the module you will always see all the generic software stack and the software stack for the CPU architecture you are located on. If you install your packages into this structure, your modules (for the correct architecture) can be accessed without additional effort. In general you find a structure like: /path/to/workspace/ +-- modulefiles # e.g. for self defined Meta Modules +-- Software +-- epyc2.el7 +-- ... +-- broadwell.el7 +-- modulefiles +-- all # place modulefiles here with structure Name/version +-- ProdXY +-- 0.1.lua # a modulefile example +-- easybuild # the EasyBuild software directory, could be used OR +-- software # you could install under this directory +-- generic.el7 +-- modulefiles +-- all # place modulefiles here with structure Name/version +-- ProdABC +-- 15.1 # another modulefile example, also TCL modules are accepted +-- easybuild # the EasyBuild software directory, could be used OR +-- sources The example shows detailed structure for Broadwell and generic software stack. But the same structure can be found also for the other stacks. The most important is the location of the modulefiles. These should be located in: EASYBUILD_PREFIX/../modulefiles/all for the architectural software stack AND CUSTOM_GENERIC_EASYBUILD_PREFIX/../modulefiles/all for the generic software stack The prefix (set in the Workspace and CustomRepo module) contains architectural information, here for example for Broadwell: EASYBUILD_PREFIX=/storage/workspaces/hpc-group/project1/Software/broadwell.el7/easybuild Modulefiles A modulefile describes location and environment setting for the targeted application, e.g. setting the PATH , LD_LIBRARY_PATH and other variables. The present Lmod system searches these Modulefiles in subdirectories of all directories registered in MODULEPATH . The above described architectural software stacks as well as the generic one are registered in the Workspace module by default. There are, two types of modules, the default Linux modules, written in TCL (described below) and Lua modules (created by our EasyBuild). Lua modules are more powerful, but for simplicity we present TCL modules here. Using the Workspace or Workspace_Home module, there are multiple locations for modules: $WORKSPACE/Software/<architecture>/modulefiles/all/ architecture dependent software stacks, where <architecture> are directories for the different architectures. $WORKSPACE/Software/generic.el7/modulefiles/ architecture independent modules, e.g. generic tools like p7zip, git or Python scripts, can be located at OR $WORKSPACE/modulefiles for generic modules like Meta modules (environment definitions) can be placed Assuming an application ProdXY , build with foss/2021a and netCDF, a lua module file maybe created at $WORKSPACE/Software/generic.el7/modulefiles/ProdABC as the following: -- comments start with \"--\" -- at least a short description, best with URL whatis ( [==[Description: ProdABC, a tool for something]==] ) -- conflicting modules, e.g. other versions of this package conflict ( \"ProdABC\" ) -- location of actual installation, for later reference local root = \"/path/to/software/ProdABC/installation\" -- dependencies required to be loaded during runtime if not ( isloaded ( \"foss/2021a\" ) ) then load ( \"foss/2021a\" ) end if not ( isloaded ( \"netCDF/4.8.0-gompi-2021a\" ) ) then load ( \"netCDF/4.8.0-gompi-2021a\" ) end -- setting environment variables, e.g. PATH,... prepend_path ( \"PATH\" , pathJoin ( root , \"bin\" )) prepend_path ( \"LD_LIBRARY_PATH\" , pathJoin ( root , \"lib\" )) setenv ( \"PRODABC_DATA_DIR\" , pathJoin ( root , \"share\" )) In the first lines, we can set conflicts with other modules (here named ProdABC). Then we load some dependency modules and provide some description. The additional lines depend on your requirements for the application. With set you can define internal variables (within this modulefile). The command setenv defines a environment variable, set in your environment after loading the module. The commands prepend-path and append-path extend an environment variable at the front or end. There are common environment variables like: PATH for providing executables, LD_LIBRARY_PATH location of libraries, e.g. prodXY.so , PYTHONPATH providing Python modules, CONDA_ENVS_PATH for providing Conda environments, etc. And others which are very application specific. If the module is in a registered location, it can be loaded by: module load ProdXY","title":"Installing Custom Software"},{"location":"software/installing-custom-software.html#installing-custom-software","text":"","title":"Installing Custom Software"},{"location":"software/installing-custom-software.html#description","text":"UBELIX comes with a plethora of software pre-installed. And there are tools provided installing additional packages in the user/group space. The present CustomRepo and Workspace modules provide easy access even for multiple versions of the same Software package. The command module avail lists the available packages and module spider FFTW searches for all modules which have FFTW in their name. This article describes a procedure for installing custom software stacks in your user/group space. An EasyBuild and a manual approach is presented. Note You cannot use the packet management utility yum for this, since this command requires root privileges to install software system wide. Instead you have to compile and install the software yourself. Note If you know that some missing software could be of general interest for a wide community on our machines, you can ask us to install the software system wide. Bioinformatic packages are managed by Vital-IT Note If you need further assistance in installing your software packages or optimizing for our machine architecture, get in touch with our support team. The LMOD module system allows to enable software package by package. Thus, influences between different packages can be minimized. It also allows to have multiple versions of the same software product installed side by side. See HPC software environment . There are modules providing access to your user/group software stacks and assisting you with building packages into them. When possible we use EasyBuild to provision software packages. EasyBuild is a software installation framework. Installation procedures are defined in so called EasyConfigs, including the location of the sources, dependencies, its versions, used environments, compile arguments, and more. These EasyConfigs are publicly available on EasyBuild github repository and can be downloaded used and if necessary adapted, e.g. for new versions.","title":"Description"},{"location":"software/installing-custom-software.html#building-software-packages","text":"There are mainly two options to build a software package and its module: using EasyBuild , with an existing, an modified or a newly created EasyConfig performing manual installation , and creating a module file In the following, both methods are described in more details. In general we consider: Is there already and EasyBuild recipe available, which can be used or modified? Which software stack we want to build into, a specific CPU architecture, OR all CPU architectures, OR should it be a generic one (see Software stacks )","title":"Building Software packages"},{"location":"software/installing-custom-software.html#software-stacks","text":"On UBELIX a software stack for each CPU architecture is provided. Applications are build on and for this specific architecture. Therewith, application can use different optimizations on different architectures, e.g. using AVX2 instruction set on Broadwell). Furthermore, a generic software stack is provided, where architecture independent applications are installed, e.g. Python scripts. Our generic software stack is build on Ivybridge nodes, which have the lowest instruction set. Therewith runtime conflicts are prevented. For EasyBuild additional tools are provided, which install automatically in all architectural or the generic software stack, see below. Additionally, with the Workspace and Workspace_Home module such software stacks can be created in your user/group space.","title":"Software stacks"},{"location":"software/installing-custom-software.html#easybuild","text":"For detailed instructions read the EasyBuild article . If you are installing your own application you may want to consider to create an EasyConfig for it. Have a look in the EasyBuild documentation , examples on the EasyBuild github . And if necessary ask our support team for assistance.","title":"EasyBuild"},{"location":"software/installing-custom-software.html#python-and-r","text":"For many python and R packages EasyConfig exist. These can be used to install the package like all other EasyBuild packages. See EasyBuild article . Alternatively, you can use the Python/R package manager and advice them to install into your HOME/Workspace directory. Please see the Python or R pages.","title":"Python and R"},{"location":"software/installing-custom-software.html#manually-compiling","text":"There are very different ways of manually installing software packages, starting from just using a compiler, having a makefile, up to complex build systems. A few considerations need to kept in mind while building for our systems: Compilers: different compilers are available and can be loaded by modules. Toolchains bundle compiler with additionally libraries and tools, like MPI, FFTW, MKL, see Toolchains . Furthermore, complex algorithms are optimised differently in the compilers. It is worthwhile to try and compare multiple compilers. CPU architectures: since there are different CPU architectures available, applications should be build for the targeted architecture. Often significant performance improvements can be obtained compiling for the correct instruction sets. Therefore, launch your build processes on the targeted architecture. Accessibility: On the one hand probably different versions, e.g. for compiler and CPU architecture should be provided. On the other hand the access to it should be as easy as possible for all users of that package. Therefore, modules provide a user-friendly. These modules can be organized e.g. in software stacks, one for each architecture. One and probably the most used procedure is the GNU configure / make: tar xzvf some-software-0.1.tar.gz cd some-software-0.1 ./configure --prefix = /path/to/target/some-software/0.1 make make install make clean Note Consider creating an Easyconfig if you already have a well tested procedure, see EasyBuild . configure is usually a complex shell script that gathers information about the system and prepares the compile process. With the --prefix option you can specify a base installation directory, where make install will install the files into subdirectories like bin , lib , include , etc. The make utility is what does the actual compiling and linking. If, for example, some additional libraries are missing on the system or not found in the expected location, the command will exit immediately. Detailed documentation can be found on the GNU make documentation page","title":"Manually compiling"},{"location":"software/installing-custom-software.html#software-stacks-with-modules","text":"The Workspace module module provide a pre-defined setup where software stacks for the different CPU architectures as well as a generic one is accessible by default. After loading the module you will always see all the generic software stack and the software stack for the CPU architecture you are located on. If you install your packages into this structure, your modules (for the correct architecture) can be accessed without additional effort. In general you find a structure like: /path/to/workspace/ +-- modulefiles # e.g. for self defined Meta Modules +-- Software +-- epyc2.el7 +-- ... +-- broadwell.el7 +-- modulefiles +-- all # place modulefiles here with structure Name/version +-- ProdXY +-- 0.1.lua # a modulefile example +-- easybuild # the EasyBuild software directory, could be used OR +-- software # you could install under this directory +-- generic.el7 +-- modulefiles +-- all # place modulefiles here with structure Name/version +-- ProdABC +-- 15.1 # another modulefile example, also TCL modules are accepted +-- easybuild # the EasyBuild software directory, could be used OR +-- sources The example shows detailed structure for Broadwell and generic software stack. But the same structure can be found also for the other stacks. The most important is the location of the modulefiles. These should be located in: EASYBUILD_PREFIX/../modulefiles/all for the architectural software stack AND CUSTOM_GENERIC_EASYBUILD_PREFIX/../modulefiles/all for the generic software stack The prefix (set in the Workspace and CustomRepo module) contains architectural information, here for example for Broadwell: EASYBUILD_PREFIX=/storage/workspaces/hpc-group/project1/Software/broadwell.el7/easybuild","title":"Software Stacks with Modules"},{"location":"software/installing-custom-software.html#modulefiles","text":"A modulefile describes location and environment setting for the targeted application, e.g. setting the PATH , LD_LIBRARY_PATH and other variables. The present Lmod system searches these Modulefiles in subdirectories of all directories registered in MODULEPATH . The above described architectural software stacks as well as the generic one are registered in the Workspace module by default. There are, two types of modules, the default Linux modules, written in TCL (described below) and Lua modules (created by our EasyBuild). Lua modules are more powerful, but for simplicity we present TCL modules here. Using the Workspace or Workspace_Home module, there are multiple locations for modules: $WORKSPACE/Software/<architecture>/modulefiles/all/ architecture dependent software stacks, where <architecture> are directories for the different architectures. $WORKSPACE/Software/generic.el7/modulefiles/ architecture independent modules, e.g. generic tools like p7zip, git or Python scripts, can be located at OR $WORKSPACE/modulefiles for generic modules like Meta modules (environment definitions) can be placed Assuming an application ProdXY , build with foss/2021a and netCDF, a lua module file maybe created at $WORKSPACE/Software/generic.el7/modulefiles/ProdABC as the following: -- comments start with \"--\" -- at least a short description, best with URL whatis ( [==[Description: ProdABC, a tool for something]==] ) -- conflicting modules, e.g. other versions of this package conflict ( \"ProdABC\" ) -- location of actual installation, for later reference local root = \"/path/to/software/ProdABC/installation\" -- dependencies required to be loaded during runtime if not ( isloaded ( \"foss/2021a\" ) ) then load ( \"foss/2021a\" ) end if not ( isloaded ( \"netCDF/4.8.0-gompi-2021a\" ) ) then load ( \"netCDF/4.8.0-gompi-2021a\" ) end -- setting environment variables, e.g. PATH,... prepend_path ( \"PATH\" , pathJoin ( root , \"bin\" )) prepend_path ( \"LD_LIBRARY_PATH\" , pathJoin ( root , \"lib\" )) setenv ( \"PRODABC_DATA_DIR\" , pathJoin ( root , \"share\" )) In the first lines, we can set conflicts with other modules (here named ProdABC). Then we load some dependency modules and provide some description. The additional lines depend on your requirements for the application. With set you can define internal variables (within this modulefile). The command setenv defines a environment variable, set in your environment after loading the module. The commands prepend-path and append-path extend an environment variable at the front or end. There are common environment variables like: PATH for providing executables, LD_LIBRARY_PATH location of libraries, e.g. prodXY.so , PYTHONPATH providing Python modules, CONDA_ENVS_PATH for providing Conda environments, etc. And others which are very application specific. If the module is in a registered location, it can be loaded by: module load ProdXY","title":"Modulefiles"},{"location":"software/matlab.html","text":"Matlab Description UBELIX is always featuring the latest two (b)-releases of Matlab. Facts about Matlab on UBELIX It can run in parallel on one node , thanks to the Parallel Computing ToolBox It can take advantage of GPUs It cannot run on more than one node as we do not have the Distributed Computing Toolbox. Matlab is NOT FREE to use! Every user using Matlab on UBELIX must have at least one valid license. You can buy licenses at our software shop . MATLAB Version: 9.3.0.713579 (R2017b) contains: MATLAB Version: 9.1.0.441655 (R2016b) contains: Simulink Version 9.0 (R2017b) Simulink Version 8.8 (R2016b) Bioinformatics Toolbox Version 4.9 (R2017b) Communications System Toolbox Version 6.3 (R2016b) Communications System Toolbox Version 6.5 (R2017b) Computer Vision System Toolbox Version 7.2 (R2016b) Computer Vision System Toolbox Version 8.0 (R2017b) Computer Vision System Toolbox Version 7.2 (R2016b) Control System Toolbox Version 10.3 (R2017b) Curve Fitting Toolbox Version 3.5.4 (R2016b) Curve Fitting Toolbox Version 3.5.6 (R2017b) DSP System Toolbox Version 9.3 (R2016b) DSP System Toolbox Version 9.5 (R2017b) Database Toolbox Version 7.0 (R2016b) Database Toolbox Version 8.0 (R2017b) Financial Toolbox Version 5.8 (R2016b) Financial Toolbox Version 5.10 (R2017b) Fixed-Point Designer Version 5.3 (R2016b) Fixed-Point Designer Version 6.0 (R2017b) Fuzzy Logic Toolbox Version 2.2.24 (R2016b) Fuzzy Logic Toolbox Version 2.3 (R2017b) Image Acquisition Toolbox Version 5.1 (R2016b) Global Optimization Toolbox Version 3.4.3 (R2017b) Image Processing Toolbox Version 9.5 (R2016b) Image Acquisition Toolbox Version 5.3 (R2017b) MATLAB Coder Version 3.2 (R2016b) Image Processing Toolbox Version 10.1 (R2017b) MATLAB Compiler Version 6.3 (R2016b) Instrument Control Toolbox Version 3.12 (R2017b) MATLAB Compiler SDK Version 6.3 (R2016b) MATLAB Coder Version 3.4 (R2017b) Mapping Toolbox Version 4.4 (R2016b) MATLAB Compiler Version 6.5 (R2017b) Neural Network Toolbox Version 9.1 (R2016b) MATLAB Compiler SDK Version 6.4 (R2017b) Optimization Toolbox Version 7.5 (R2016b) Mapping Toolbox Version 4.5.1 (R2017b) Parallel Computing Toolbox Version 6.9 (R2016b) Model Predictive Control Toolbox Version 6.0 (R2017b) Partial Differential Equation Toolbox Version 2.3 (R2016b) Neural Network Toolbox Version 11.0 (R2017b) Robust Control Toolbox Version 6.2 (R2016b) Optimization Toolbox Version 8.0 (R2017b) Signal Processing Toolbox Version 7.3 (R2016b) Parallel Computing Toolbox Version 6.11 (R2017b) Simscape Version 4.1 (R2016b) Partial Differential Equation Toolbox Version 2.5 (R2017b) Simscape Multibody Version 4.9 (R2016b) Robust Control Toolbox Version 6.4 (R2017b) Simscape Power Systems Version 6.6 (R2016b) Signal Processing Toolbox Version 7.5 (R2017b) Simulink Coder Version 8.11 (R2016b) Simscape Version 4.3 (R2017b) Simulink Control Design Version 4.4 (R2016b) Simscape Multibody Version 5.1 (R2017b) Simulink Design Optimization Version 3.1 (R2016b) Simscape Power Systems Version 6.8 (R2017b) Simulink Verification and Validation Version 3.12 (R2016b) Simulink Check Version 4.0 (R2017b) Stateflow Version 8.8 (R2016b) Simulink Coder Version 8.13 (R2017b) Statistics and Machine Learning Toolbox Version 11.0 (R2016b) Simulink Control Design Version 5.0 (R2017b) Symbolic Math Toolbox Version 7.1 (R2016b) Simulink Coverage Version 4.0 (R2017b) System Identification Toolbox Version 9.5 (R2016b) Simulink Design Optimization Version 3.3 (R2017b) Wavelet Toolbox Version 4.17 (R2016b) Simulink Requirements Version 1.0 (R2017b) Stateflow Version 9.0 (R2017b) Statistics and Machine Learning Toolbox Version 11.2 (R2017b) Symbolic Math Toolbox Version 8.0 (R2017b) System Identification Toolbox Version 9.7 (R2017b) Wavelet Toolbox Version 4.19 (R2017b) Running Matlab on the Compute Nodes Submitting a Matlab job to the cluster is very similar to submitting any other serial job. Lets try to run a simple Matlab script which we will put in a file boxfilter.m boxfilter.m % Compute a local mean filter over a neighborhood of 11x11 pixels % Read image into workspace: original = imread ( 'girlface.png' ) ; % Perform the mean filtering: filtered = imboxfilt ( original, 11 ) ; % Save the original and the filtered image side-by-side: imwrite ([ original, filtered ] , 'comparison.png' ) ; Now we need a submission script boxfilter.qsub !#/bin/bash #SBATCH -mail-user=foo@bar.unibe.ch #SBATCH --mail-type=end,fail #SBATCH --job-name=boxfilter #SBATCH --time=00:10:00 #SBATCH --mem-per-cpu=2G # Load Matlab form the environment modules module load matlab/R2015b # Tell Matlab to run our box filter.m file and exit matlab -nodisplay -r \"boxfilter, exit\" Passing Arguments to a m-File There are several ways to provide input arguments in Matlab. Define the Variables Before Running the Script Lets take the box filter.m example from above. The script is not universal because the name of the input image and the box size is hardcoded in the script. We make the script more generally usable by: boxfilter.m % Compute a local mean filter over a neighborhood of 11x11 pixels % Read image into workspace: original = imread ( inputImg ) ; % Perform the mean filtering: filtered = imboxfilt ( original, x ) ; % Save the original and the filtered image side-by-side: imwrite ([ original, filtered ] , 'comparison.png' ) ; and then: boxfilter.qsub !#/bin/bash ( ... ) # Load Matlab form the environment modules module load matlab/R2015b # Tell Matlab to run our box filter.m file and exit matlab -nodisplay -r \"inputImg='girlface.png'; x=11; boxfilter, exit\" Advanced Topics Multithreading By default, MATLAB makes use of the multithreading capabilities of the node on which it is running. It is crucial that you allocate the same number of slots for your job as your job utilizes cores. Disable Computational Multithreading If you do not need multithreading for your application consider to disable computational multithreading by setting the -singleCompThread option when starting MATLAB: matlab -nodisplay -singleCompThread -r \"boxfilter('girlface.png', 'comparison.png', 11); exit\" Disable Computational Multithreading If you do not need multithreading for your application consider to disable computational multithreading by setting the -singleCompThread option when starting MATLAB: matlab -nodisplay -singleCompThread -r \"boxfilter('girlface.png', 'comparison.png', 11); exit\" Running MATLAB in Multithreaded Mode Most of the time, running MATLAB in single-threaded mode will meet your needs. If you have mathematically intense computations that might benefit from multi-threading capabilities provided by MATLAB\u2019s BLAS implementation, then you should limit MATLAB to a well defined number of threads, so that you can allocate the correct number of slots for your job. Use the maxNumCompThreads(N) function to control the number of computational threads:","title":"Matlab"},{"location":"software/matlab.html#matlab","text":"","title":"Matlab"},{"location":"software/matlab.html#description","text":"UBELIX is always featuring the latest two (b)-releases of Matlab.","title":"Description"},{"location":"software/matlab.html#facts-about-matlab-on-ubelix","text":"It can run in parallel on one node , thanks to the Parallel Computing ToolBox It can take advantage of GPUs It cannot run on more than one node as we do not have the Distributed Computing Toolbox. Matlab is NOT FREE to use! Every user using Matlab on UBELIX must have at least one valid license. You can buy licenses at our software shop . MATLAB Version: 9.3.0.713579 (R2017b) contains: MATLAB Version: 9.1.0.441655 (R2016b) contains: Simulink Version 9.0 (R2017b) Simulink Version 8.8 (R2016b) Bioinformatics Toolbox Version 4.9 (R2017b) Communications System Toolbox Version 6.3 (R2016b) Communications System Toolbox Version 6.5 (R2017b) Computer Vision System Toolbox Version 7.2 (R2016b) Computer Vision System Toolbox Version 8.0 (R2017b) Computer Vision System Toolbox Version 7.2 (R2016b) Control System Toolbox Version 10.3 (R2017b) Curve Fitting Toolbox Version 3.5.4 (R2016b) Curve Fitting Toolbox Version 3.5.6 (R2017b) DSP System Toolbox Version 9.3 (R2016b) DSP System Toolbox Version 9.5 (R2017b) Database Toolbox Version 7.0 (R2016b) Database Toolbox Version 8.0 (R2017b) Financial Toolbox Version 5.8 (R2016b) Financial Toolbox Version 5.10 (R2017b) Fixed-Point Designer Version 5.3 (R2016b) Fixed-Point Designer Version 6.0 (R2017b) Fuzzy Logic Toolbox Version 2.2.24 (R2016b) Fuzzy Logic Toolbox Version 2.3 (R2017b) Image Acquisition Toolbox Version 5.1 (R2016b) Global Optimization Toolbox Version 3.4.3 (R2017b) Image Processing Toolbox Version 9.5 (R2016b) Image Acquisition Toolbox Version 5.3 (R2017b) MATLAB Coder Version 3.2 (R2016b) Image Processing Toolbox Version 10.1 (R2017b) MATLAB Compiler Version 6.3 (R2016b) Instrument Control Toolbox Version 3.12 (R2017b) MATLAB Compiler SDK Version 6.3 (R2016b) MATLAB Coder Version 3.4 (R2017b) Mapping Toolbox Version 4.4 (R2016b) MATLAB Compiler Version 6.5 (R2017b) Neural Network Toolbox Version 9.1 (R2016b) MATLAB Compiler SDK Version 6.4 (R2017b) Optimization Toolbox Version 7.5 (R2016b) Mapping Toolbox Version 4.5.1 (R2017b) Parallel Computing Toolbox Version 6.9 (R2016b) Model Predictive Control Toolbox Version 6.0 (R2017b) Partial Differential Equation Toolbox Version 2.3 (R2016b) Neural Network Toolbox Version 11.0 (R2017b) Robust Control Toolbox Version 6.2 (R2016b) Optimization Toolbox Version 8.0 (R2017b) Signal Processing Toolbox Version 7.3 (R2016b) Parallel Computing Toolbox Version 6.11 (R2017b) Simscape Version 4.1 (R2016b) Partial Differential Equation Toolbox Version 2.5 (R2017b) Simscape Multibody Version 4.9 (R2016b) Robust Control Toolbox Version 6.4 (R2017b) Simscape Power Systems Version 6.6 (R2016b) Signal Processing Toolbox Version 7.5 (R2017b) Simulink Coder Version 8.11 (R2016b) Simscape Version 4.3 (R2017b) Simulink Control Design Version 4.4 (R2016b) Simscape Multibody Version 5.1 (R2017b) Simulink Design Optimization Version 3.1 (R2016b) Simscape Power Systems Version 6.8 (R2017b) Simulink Verification and Validation Version 3.12 (R2016b) Simulink Check Version 4.0 (R2017b) Stateflow Version 8.8 (R2016b) Simulink Coder Version 8.13 (R2017b) Statistics and Machine Learning Toolbox Version 11.0 (R2016b) Simulink Control Design Version 5.0 (R2017b) Symbolic Math Toolbox Version 7.1 (R2016b) Simulink Coverage Version 4.0 (R2017b) System Identification Toolbox Version 9.5 (R2016b) Simulink Design Optimization Version 3.3 (R2017b) Wavelet Toolbox Version 4.17 (R2016b) Simulink Requirements Version 1.0 (R2017b) Stateflow Version 9.0 (R2017b) Statistics and Machine Learning Toolbox Version 11.2 (R2017b) Symbolic Math Toolbox Version 8.0 (R2017b) System Identification Toolbox Version 9.7 (R2017b) Wavelet Toolbox Version 4.19 (R2017b)","title":"Facts about Matlab on UBELIX"},{"location":"software/matlab.html#running-matlab-on-the-compute-nodes","text":"Submitting a Matlab job to the cluster is very similar to submitting any other serial job. Lets try to run a simple Matlab script which we will put in a file boxfilter.m boxfilter.m % Compute a local mean filter over a neighborhood of 11x11 pixels % Read image into workspace: original = imread ( 'girlface.png' ) ; % Perform the mean filtering: filtered = imboxfilt ( original, 11 ) ; % Save the original and the filtered image side-by-side: imwrite ([ original, filtered ] , 'comparison.png' ) ; Now we need a submission script boxfilter.qsub !#/bin/bash #SBATCH -mail-user=foo@bar.unibe.ch #SBATCH --mail-type=end,fail #SBATCH --job-name=boxfilter #SBATCH --time=00:10:00 #SBATCH --mem-per-cpu=2G # Load Matlab form the environment modules module load matlab/R2015b # Tell Matlab to run our box filter.m file and exit matlab -nodisplay -r \"boxfilter, exit\"","title":"Running Matlab on the Compute Nodes"},{"location":"software/matlab.html#passing-arguments-to-a-m-file","text":"There are several ways to provide input arguments in Matlab.","title":"Passing Arguments to a m-File"},{"location":"software/matlab.html#define-the-variables-before-running-the-script","text":"Lets take the box filter.m example from above. The script is not universal because the name of the input image and the box size is hardcoded in the script. We make the script more generally usable by: boxfilter.m % Compute a local mean filter over a neighborhood of 11x11 pixels % Read image into workspace: original = imread ( inputImg ) ; % Perform the mean filtering: filtered = imboxfilt ( original, x ) ; % Save the original and the filtered image side-by-side: imwrite ([ original, filtered ] , 'comparison.png' ) ; and then: boxfilter.qsub !#/bin/bash ( ... ) # Load Matlab form the environment modules module load matlab/R2015b # Tell Matlab to run our box filter.m file and exit matlab -nodisplay -r \"inputImg='girlface.png'; x=11; boxfilter, exit\"","title":"Define the Variables Before Running the Script"},{"location":"software/matlab.html#advanced-topics","text":"","title":"Advanced Topics"},{"location":"software/matlab.html#multithreading","text":"By default, MATLAB makes use of the multithreading capabilities of the node on which it is running. It is crucial that you allocate the same number of slots for your job as your job utilizes cores. Disable Computational Multithreading If you do not need multithreading for your application consider to disable computational multithreading by setting the -singleCompThread option when starting MATLAB: matlab -nodisplay -singleCompThread -r \"boxfilter('girlface.png', 'comparison.png', 11); exit\" Disable Computational Multithreading If you do not need multithreading for your application consider to disable computational multithreading by setting the -singleCompThread option when starting MATLAB: matlab -nodisplay -singleCompThread -r \"boxfilter('girlface.png', 'comparison.png', 11); exit\" Running MATLAB in Multithreaded Mode Most of the time, running MATLAB in single-threaded mode will meet your needs. If you have mathematically intense computations that might benefit from multi-threading capabilities provided by MATLAB\u2019s BLAS implementation, then you should limit MATLAB to a well defined number of threads, so that you can allocate the correct number of slots for your job. Use the maxNumCompThreads(N) function to control the number of computational threads:","title":"Multithreading"},{"location":"software/python.html","text":"Python Description There are multiple versions of Python available on our HPCs. On the one hand there are Python modules for Python 3 and 2. Which already has a longer list of additional packages installed, including pip3 respectively pip . On the other hand there is Anaconda installed, which brings an even longer list of packages with it. For Anaconda see Anaconda page Additional Packages There are additional modules which build on top of Python and provide additional Python packages. E.g. the SciPy-bundle provides: numpy scipy mpi4py numexpr Bottleneck pandas mpmath and deap Another provided Python package is TensorFlow . If you need additional packages we suggest to install them using either pip for Python2 and pip3 for Python3. You can install into your private HOME using the (pip or pip3) install --user option or share the packages with your colleges using the Workspace module, e.g. for installing a package matplotlib : ## load Python first, this can also be `module load Anaconda3` module load Python ## maybe you need to specify the Workspace name first OR use `Workspace_Home` module load Workspace ## pip install in the Workspace or HOME location ## the variable PYTHONPACKAGEPATH is set in the Workspace module pip install --prefix $PYTHONPACKAGEPATH matplotlib Python module need to be loaded before loading Workspace, because some settings require the Python version information. Therewith the Python packages are automatically available when module load Python ## OR module load Anaconda3 module load Workspace ## maybe you need to specify the Workspace name first python -c \"import matplotlib\" since $PYTHONPATH and $PATH are set to the above specified location. Type if you get the error: ERROR: You must give at least one requirement to install (see \"pip help install\") you need to reload the Workspace module to properly set the variables. The Workspace module need to have Anaconda3/Python loaded first to read the proper Python Version. module load Python ## OR module load Anaconda3","title":"Python"},{"location":"software/python.html#python","text":"","title":"Python"},{"location":"software/python.html#description","text":"There are multiple versions of Python available on our HPCs. On the one hand there are Python modules for Python 3 and 2. Which already has a longer list of additional packages installed, including pip3 respectively pip . On the other hand there is Anaconda installed, which brings an even longer list of packages with it. For Anaconda see Anaconda page","title":"Description"},{"location":"software/python.html#additional-packages","text":"There are additional modules which build on top of Python and provide additional Python packages. E.g. the SciPy-bundle provides: numpy scipy mpi4py numexpr Bottleneck pandas mpmath and deap Another provided Python package is TensorFlow . If you need additional packages we suggest to install them using either pip for Python2 and pip3 for Python3. You can install into your private HOME using the (pip or pip3) install --user option or share the packages with your colleges using the Workspace module, e.g. for installing a package matplotlib : ## load Python first, this can also be `module load Anaconda3` module load Python ## maybe you need to specify the Workspace name first OR use `Workspace_Home` module load Workspace ## pip install in the Workspace or HOME location ## the variable PYTHONPACKAGEPATH is set in the Workspace module pip install --prefix $PYTHONPACKAGEPATH matplotlib Python module need to be loaded before loading Workspace, because some settings require the Python version information. Therewith the Python packages are automatically available when module load Python ## OR module load Anaconda3 module load Workspace ## maybe you need to specify the Workspace name first python -c \"import matplotlib\" since $PYTHONPATH and $PATH are set to the above specified location. Type if you get the error: ERROR: You must give at least one requirement to install (see \"pip help install\") you need to reload the Workspace module to properly set the variables. The Workspace module need to have Anaconda3/Python loaded first to read the proper Python Version. module load Python ## OR module load Anaconda3","title":"Additional Packages"},{"location":"software/r.html","text":"R Description R is provided by an environment module and must be loaded explicitly: module load R ##OR## module load R/3.4.4-foss-2018a-X11-20180131 R --version R version 4 .0.0 ( 2020 -04-24 ) -- \"Arbor Day\" ... The Vital-IT project is also providing some versions. The following commands will list the available versions: module load vital-it module avail 2 > & 1 | grep \" R\\/\" R/3.4.2 R/latest To use one of these version, you have to load the respective module, which then masks the system\u2019s version, i.e. module load vital-it module load R/3.4.2 Do not forget to put those two lines into your job script as well in order to use the same version from within the job later on a compute node! Basic Topics Customizing the R Workspace At startup, unless \u2013no-init-file, or \u2013vanilla was given, R searches for a user profile in the current directory (from where R was started), or in the user\u2019s home directory (in that order). A different path of the user profile file can be specified by the R_PROFILE_USER environment variable. The found user profile is then sourced into the workspace. You can use this file to customize your workspace, i.e., to set specific options, define functions, load libraries, and so on. Consider the following example: .Rprofile # Set some options options ( stringsAsFactors = FALSE ) options ( max.print = 100 ) options ( scipen = 10 ) # Load class library library ( class ) # Don't save workspace by default q <- function ( save = \"no\" , ... ) { quit ( save = save, ... ) } # User-defined function for setting standard seed mySeed <- function () set.seed ( 5450 ) # User-defined function for calculating L1/L2-norm, returns euclidean distance (L2-norm) by default myDistance <- function ( x, y, type = c ( \"Euclidean\" , \"L2\" , \"Manhattan\" , \"L1\" )) { type <- match.arg ( type ) if (( type == \"Manhattan\" ) | ( type == \"L1\" )) { d <- sum ( abs ( x - y ) ) } else { d <- sqrt ( sum ( ( x - y ) ^ 2 ) ) } return ( d ) } Installing Packages R is installed as global Module in various versions. There are already a longer list of pre-installed packages available. If you need additional packages you can install them by yourself. The default location would be the R installation directory, which is not writeable for users. Nevertheless, in the following is shown how to install into a shared HPC Workspace or into your private HOME. A) Into a shared Workspace With the Workspace tools we provide short-cuts to install R packages in the shared Workspace location. Therefore, the environment variable $R_LIBS is set to $WORKSPACE/RPackages . Initially this directory need to be created, using: module load Workspace mkdir $R_LIBS If you get the error mkdir: cannot create directory ... verify that you just loaded one Workspace while installing the package. Then R packages can be installed using the install.packages() routine in an interactive R shell, e.g. for doParallel : module load R R ... > install.packages(\"doParallel\") Please follow the procedure as shown below at installation routine . Then the installed packaged will be available to you and all other Workspace members by simply loading the Workspace module. Please remember to add the Workspace and the R module to your job scripts: module load Workspace module load R B) Into your HOME Note you can also use procedure A) and load Workspace_Home to install into your HOME directory. If you are not using a Workspace module and try to install a package, at the first time R tries to install the package into a global/generic location, which is not writeable by users. You can then select to install in a \u201cpersonal library\u201d into your HOME: module load R R > install.packages ( \"doParallel\" ) Installing package into \u2018/usr/lib64/R/library\u2019 ( as \u2018lib\u2019 is unspecified ) Warnung in install.packages ( \"doParallel\" ) ' lib = \"/usr/lib64/R/library\" ist nicht schreibbar Would you like to use a personal library instead? ( y/n ) Next, type \u201cy\u201d to create your personal library at the default location within your HOME directory: Would you like to create a personal library ~/R/x86_64-redhat-linux-gnu-library/4.0 Installation Routine Next, select a CRAN mirror to download from. The mirror list will be not the same as below. The mirror list is constantly changing, but will look like it. Pick any country nearby, i.e. Switzerland. If https makes problems, pick \u201c(HTTP mirrors)\u201d and then select something nearby as shown below --- Bitte einen CRAN Spiegel f\u00fcr diese Sitzung ausw\u00e4hlen --- Error in download.file ( url, destfile = f, quiet = TRUE ) : nicht unterst\u00fctztes URL Schema HTTPS CRAN mirror 1 : 0 -Cloud [ https ] 2 : Austria [ https ] 3 : Chile [ https ] 4 : China ( Beijing 4 ) [ https ] 5 : Colombia ( Cali ) [ https ] 6 : France ( Lyon 2 ) [ https ] 7 : France ( Paris 2 ) [ https ] 8 : Germany ( M\u00fcnster ) [ https ] 9 : Iceland [ https ] 10 : Mexico ( Mexico City ) [ https ] 11 : Russia ( Moscow ) [ https ] 12 : Spain ( A Coru\u00f1a ) [ https ] 13 : Switzerland [ https ] 14 : UK ( Bristol ) [ https ] 15 : UK ( Cambridge ) [ https ] 16 : USA ( CA 1 ) [ https ] 17 : USA ( KS ) [ https ] 18 : USA ( MI 1 ) [ https ] 19 : USA ( TN ) [ https ] 20 : USA ( TX ) [ https ] 21 : USA ( WA ) [ https ] 22 : ( HTTP mirrors ) Selection: 22 HTTP CRAN mirror 1 : 0 -Cloud 2 : Algeria 3 : Argentina ( La Plata ) 4 : Australia ( Canberra ) 5 : Australia ( Melbourne ) 6 : Austria 7 : Belgium ( Antwerp ) 8 : Belgium ( Ghent ) ( ... ) 65 : Slovakia 66 : South Africa ( Cape Town ) 67 : South Africa ( Johannesburg ) 68 : Spain ( A Coru\u00f1a ) 69 : Spain ( Madrid ) 70 : Sweden 71 : Switzerland 72 : Taiwan ( Chungli ) 73 : Taiwan ( Taipei ) 74 : Thailand 75 : Turkey ( Denizli ) 76 : Turkey ( Mersin ) ( ... ) 93 : USA ( OH 2 ) 94 : USA ( OR ) 95 : USA ( PA 2 ) 96 : USA ( TN ) 97 : USA ( TX ) 98 : USA ( WA ) 99 : Venezuela Selection: 71 Finally, the package gets installed. After installing the package you can close the interactive session by typing q(). Do not forget to load the corresponding library (for each R session) before using functions provided by the package: > library ( doParallel ) Batch Execution of R The syntax for running R non-interactively with input read from infile and output send to outfile is: R CMD BATCH [ options ] infile [ outfile ] Suppose you placed your R code in a file called foo.R: foo.R set.seed ( 3000 ) valx<-seq ( -2,2,0.01 ) valy<-2*valx+rnorm ( length ( valx ) ,0,4 ) # Save plot to pdf pdf ( 'histplot.pdf' ) hist ( valy,prob = TRUE,breaks = 20 , main = \"Histogram and PDF\" ,xlab = \"y\" , ylim = c ( 0 ,0.15 )) curve ( dnorm ( x,mean ( valy ) ,sd ( valy )) ,add = T,col = \"red\" ) dev.off () To execute foo.R on the cluster, add the R call to your job script\u2026 Rbatch.sh #! /bin/bash #SBATCH --mail-user=<put your valid email address here!> #SBATCH --mail-type=end,fail #SBATCH --time=01:00:00 #SBATCH --mem-per-cpu=2G # Put your code below this line module load vital-it module load R/3.4.2 R CMD BATCH --no-save --no-restore foo.R \u2026and submit your job script to the cluster: sbatch Rbatch.sh Advanced Topics Parallel R By default, R will not make use of multiple cores available on compute nodes to parallelize computations. Parallel processing functionality is provided by add-on packages. Consider the following contrived example to get you started. To follow the example, you need the following packages installed, and the corresponding libraries loaded: > library ( doParallel ) > library ( foreach ) The foreach package provides a looping construct for executing R statements repeatedly, either sequentially (similar to a for loop) or in parallel. While the binary operator %do% is used for executing the statements sequentially, the %dopar% operator is used to execute code in parallel using the currently registered backend. The getDoParWorkers() function returns the number of execution workers (cores) available in the currently registered doPar backend, by default this corresponds to one worker: > getDoParWorkers () [ 1 ] 1 Hence, the following R code will execute on a single core (even with the %dopar% operator): > start.time <- Sys.time () > foreach ( i = 4 :1, .combine = 'c' , .inorder = FALSE ) %dopar% { + Sys.sleep ( 3 *i ) + i + } end.time <- Sys.time () exec.time <- end.time - start.time [ 1 ] 4 3 2 1 Let\u2019s measure the runtime of the sequentiall execution: > start.time <- Sys.time () ; foreach ( i = 4 :1, .combine = 'c' , .inorder = TRUE ) %dopar% { Sys.sleep ( 3 *i ) ; i } ; end.time <- Sys.time () ; exec.time <- end.time - start.time ; exec.time [ 1 ] 4 3 2 1 Time difference of 30 .04088 secs Now, we will register a parallel backend to allow the %dopar% operator to execute in parallel. The doParallel package provides a parallel backend for the %dopar% operator. Let\u2019s find out the number of cores available on the current node > detectCores () [ 1 ] 24 To register the doPar backend call the function registerDoParallel(). With no arguments provided, the number of cores assigned to the backend matches the value of options(\u201ccores\u201d) , or if not set, to half of the cores detected by the parallel package. registerDoParallel () > getDoParWorkers () [ 1 ] 12 To assign 4 cores to the parallel backend: > registerDoParallel ( cores = 4 ) > getDoParWorkers () [ 1 ] 4 Request the correct number of slots Because it is crucial to request the correct number of slots for a parallel job, we propose to set the number of cores for the doPar backend to the number of slots allocated to your job: registerDoParallel(cores=Sys.getenv(\"lsf_CPUS_PER_TASK\")) Now, run the example again: > foreach ( i = 4 :1, .combine = 'c' , .inorder = FALSE ) %dopar% { + Sys.sleep ( 3 *i ) + i + } [ 1 ] 4 3 2 1 Well, the output is basically the same (the results are combined in the same order!). Let\u2019s again measure the runtime of the parallel execution on 4 cores: The binary operator %do% will always execute a foreach-loop sequentially even if registerDoParallel was called before! To correctly run a foreach in parallel, two conditions must be met: registerDoParallel() must be called with a certain number of cores The %dopar% operator must be used in the foreach-loop to have it run in parallel! Installing DESeq2 from Bioconductor packages DESeq2 1 installed from Bioconductor 2 has many dependencies. Two odd facts are hindering a succesful build of DESeq2 in first place: data.table is needed by Hmisc, which in turn is needed by DESeq2. While Hmisc is automatically installed prior to DESeq2, data.table is not and has to be installed manually first. https://bioconductor.org/packages/release/bioc/html/DESeq2.html \u21a9 https://bioconductor.org/ \u21a9","title":"R"},{"location":"software/r.html#r","text":"","title":"R"},{"location":"software/r.html#description","text":"R is provided by an environment module and must be loaded explicitly: module load R ##OR## module load R/3.4.4-foss-2018a-X11-20180131 R --version R version 4 .0.0 ( 2020 -04-24 ) -- \"Arbor Day\" ... The Vital-IT project is also providing some versions. The following commands will list the available versions: module load vital-it module avail 2 > & 1 | grep \" R\\/\" R/3.4.2 R/latest To use one of these version, you have to load the respective module, which then masks the system\u2019s version, i.e. module load vital-it module load R/3.4.2 Do not forget to put those two lines into your job script as well in order to use the same version from within the job later on a compute node!","title":"Description"},{"location":"software/r.html#basic-topics","text":"","title":"Basic Topics"},{"location":"software/r.html#customizing-the-r-workspace","text":"At startup, unless \u2013no-init-file, or \u2013vanilla was given, R searches for a user profile in the current directory (from where R was started), or in the user\u2019s home directory (in that order). A different path of the user profile file can be specified by the R_PROFILE_USER environment variable. The found user profile is then sourced into the workspace. You can use this file to customize your workspace, i.e., to set specific options, define functions, load libraries, and so on. Consider the following example: .Rprofile # Set some options options ( stringsAsFactors = FALSE ) options ( max.print = 100 ) options ( scipen = 10 ) # Load class library library ( class ) # Don't save workspace by default q <- function ( save = \"no\" , ... ) { quit ( save = save, ... ) } # User-defined function for setting standard seed mySeed <- function () set.seed ( 5450 ) # User-defined function for calculating L1/L2-norm, returns euclidean distance (L2-norm) by default myDistance <- function ( x, y, type = c ( \"Euclidean\" , \"L2\" , \"Manhattan\" , \"L1\" )) { type <- match.arg ( type ) if (( type == \"Manhattan\" ) | ( type == \"L1\" )) { d <- sum ( abs ( x - y ) ) } else { d <- sqrt ( sum ( ( x - y ) ^ 2 ) ) } return ( d ) }","title":"Customizing the R Workspace"},{"location":"software/r.html#installing-packages","text":"R is installed as global Module in various versions. There are already a longer list of pre-installed packages available. If you need additional packages you can install them by yourself. The default location would be the R installation directory, which is not writeable for users. Nevertheless, in the following is shown how to install into a shared HPC Workspace or into your private HOME.","title":"Installing Packages"},{"location":"software/r.html#a-into-a-shared-workspace","text":"With the Workspace tools we provide short-cuts to install R packages in the shared Workspace location. Therefore, the environment variable $R_LIBS is set to $WORKSPACE/RPackages . Initially this directory need to be created, using: module load Workspace mkdir $R_LIBS If you get the error mkdir: cannot create directory ... verify that you just loaded one Workspace while installing the package. Then R packages can be installed using the install.packages() routine in an interactive R shell, e.g. for doParallel : module load R R ... > install.packages(\"doParallel\") Please follow the procedure as shown below at installation routine . Then the installed packaged will be available to you and all other Workspace members by simply loading the Workspace module. Please remember to add the Workspace and the R module to your job scripts: module load Workspace module load R","title":"A) Into a shared Workspace"},{"location":"software/r.html#b-into-your-home","text":"Note you can also use procedure A) and load Workspace_Home to install into your HOME directory. If you are not using a Workspace module and try to install a package, at the first time R tries to install the package into a global/generic location, which is not writeable by users. You can then select to install in a \u201cpersonal library\u201d into your HOME: module load R R > install.packages ( \"doParallel\" ) Installing package into \u2018/usr/lib64/R/library\u2019 ( as \u2018lib\u2019 is unspecified ) Warnung in install.packages ( \"doParallel\" ) ' lib = \"/usr/lib64/R/library\" ist nicht schreibbar Would you like to use a personal library instead? ( y/n ) Next, type \u201cy\u201d to create your personal library at the default location within your HOME directory: Would you like to create a personal library ~/R/x86_64-redhat-linux-gnu-library/4.0","title":"B) Into your HOME"},{"location":"software/r.html#installation-routine","text":"Next, select a CRAN mirror to download from. The mirror list will be not the same as below. The mirror list is constantly changing, but will look like it. Pick any country nearby, i.e. Switzerland. If https makes problems, pick \u201c(HTTP mirrors)\u201d and then select something nearby as shown below --- Bitte einen CRAN Spiegel f\u00fcr diese Sitzung ausw\u00e4hlen --- Error in download.file ( url, destfile = f, quiet = TRUE ) : nicht unterst\u00fctztes URL Schema HTTPS CRAN mirror 1 : 0 -Cloud [ https ] 2 : Austria [ https ] 3 : Chile [ https ] 4 : China ( Beijing 4 ) [ https ] 5 : Colombia ( Cali ) [ https ] 6 : France ( Lyon 2 ) [ https ] 7 : France ( Paris 2 ) [ https ] 8 : Germany ( M\u00fcnster ) [ https ] 9 : Iceland [ https ] 10 : Mexico ( Mexico City ) [ https ] 11 : Russia ( Moscow ) [ https ] 12 : Spain ( A Coru\u00f1a ) [ https ] 13 : Switzerland [ https ] 14 : UK ( Bristol ) [ https ] 15 : UK ( Cambridge ) [ https ] 16 : USA ( CA 1 ) [ https ] 17 : USA ( KS ) [ https ] 18 : USA ( MI 1 ) [ https ] 19 : USA ( TN ) [ https ] 20 : USA ( TX ) [ https ] 21 : USA ( WA ) [ https ] 22 : ( HTTP mirrors ) Selection: 22 HTTP CRAN mirror 1 : 0 -Cloud 2 : Algeria 3 : Argentina ( La Plata ) 4 : Australia ( Canberra ) 5 : Australia ( Melbourne ) 6 : Austria 7 : Belgium ( Antwerp ) 8 : Belgium ( Ghent ) ( ... ) 65 : Slovakia 66 : South Africa ( Cape Town ) 67 : South Africa ( Johannesburg ) 68 : Spain ( A Coru\u00f1a ) 69 : Spain ( Madrid ) 70 : Sweden 71 : Switzerland 72 : Taiwan ( Chungli ) 73 : Taiwan ( Taipei ) 74 : Thailand 75 : Turkey ( Denizli ) 76 : Turkey ( Mersin ) ( ... ) 93 : USA ( OH 2 ) 94 : USA ( OR ) 95 : USA ( PA 2 ) 96 : USA ( TN ) 97 : USA ( TX ) 98 : USA ( WA ) 99 : Venezuela Selection: 71 Finally, the package gets installed. After installing the package you can close the interactive session by typing q(). Do not forget to load the corresponding library (for each R session) before using functions provided by the package: > library ( doParallel )","title":"Installation Routine"},{"location":"software/r.html#batch-execution-of-r","text":"The syntax for running R non-interactively with input read from infile and output send to outfile is: R CMD BATCH [ options ] infile [ outfile ] Suppose you placed your R code in a file called foo.R: foo.R set.seed ( 3000 ) valx<-seq ( -2,2,0.01 ) valy<-2*valx+rnorm ( length ( valx ) ,0,4 ) # Save plot to pdf pdf ( 'histplot.pdf' ) hist ( valy,prob = TRUE,breaks = 20 , main = \"Histogram and PDF\" ,xlab = \"y\" , ylim = c ( 0 ,0.15 )) curve ( dnorm ( x,mean ( valy ) ,sd ( valy )) ,add = T,col = \"red\" ) dev.off () To execute foo.R on the cluster, add the R call to your job script\u2026 Rbatch.sh #! /bin/bash #SBATCH --mail-user=<put your valid email address here!> #SBATCH --mail-type=end,fail #SBATCH --time=01:00:00 #SBATCH --mem-per-cpu=2G # Put your code below this line module load vital-it module load R/3.4.2 R CMD BATCH --no-save --no-restore foo.R \u2026and submit your job script to the cluster: sbatch Rbatch.sh","title":"Batch Execution of R"},{"location":"software/r.html#advanced-topics","text":"","title":"Advanced Topics"},{"location":"software/r.html#parallel-r","text":"By default, R will not make use of multiple cores available on compute nodes to parallelize computations. Parallel processing functionality is provided by add-on packages. Consider the following contrived example to get you started. To follow the example, you need the following packages installed, and the corresponding libraries loaded: > library ( doParallel ) > library ( foreach ) The foreach package provides a looping construct for executing R statements repeatedly, either sequentially (similar to a for loop) or in parallel. While the binary operator %do% is used for executing the statements sequentially, the %dopar% operator is used to execute code in parallel using the currently registered backend. The getDoParWorkers() function returns the number of execution workers (cores) available in the currently registered doPar backend, by default this corresponds to one worker: > getDoParWorkers () [ 1 ] 1 Hence, the following R code will execute on a single core (even with the %dopar% operator): > start.time <- Sys.time () > foreach ( i = 4 :1, .combine = 'c' , .inorder = FALSE ) %dopar% { + Sys.sleep ( 3 *i ) + i + } end.time <- Sys.time () exec.time <- end.time - start.time [ 1 ] 4 3 2 1 Let\u2019s measure the runtime of the sequentiall execution: > start.time <- Sys.time () ; foreach ( i = 4 :1, .combine = 'c' , .inorder = TRUE ) %dopar% { Sys.sleep ( 3 *i ) ; i } ; end.time <- Sys.time () ; exec.time <- end.time - start.time ; exec.time [ 1 ] 4 3 2 1 Time difference of 30 .04088 secs Now, we will register a parallel backend to allow the %dopar% operator to execute in parallel. The doParallel package provides a parallel backend for the %dopar% operator. Let\u2019s find out the number of cores available on the current node > detectCores () [ 1 ] 24 To register the doPar backend call the function registerDoParallel(). With no arguments provided, the number of cores assigned to the backend matches the value of options(\u201ccores\u201d) , or if not set, to half of the cores detected by the parallel package. registerDoParallel () > getDoParWorkers () [ 1 ] 12 To assign 4 cores to the parallel backend: > registerDoParallel ( cores = 4 ) > getDoParWorkers () [ 1 ] 4 Request the correct number of slots Because it is crucial to request the correct number of slots for a parallel job, we propose to set the number of cores for the doPar backend to the number of slots allocated to your job: registerDoParallel(cores=Sys.getenv(\"lsf_CPUS_PER_TASK\")) Now, run the example again: > foreach ( i = 4 :1, .combine = 'c' , .inorder = FALSE ) %dopar% { + Sys.sleep ( 3 *i ) + i + } [ 1 ] 4 3 2 1 Well, the output is basically the same (the results are combined in the same order!). Let\u2019s again measure the runtime of the parallel execution on 4 cores: The binary operator %do% will always execute a foreach-loop sequentially even if registerDoParallel was called before! To correctly run a foreach in parallel, two conditions must be met: registerDoParallel() must be called with a certain number of cores The %dopar% operator must be used in the foreach-loop to have it run in parallel!","title":"Parallel R"},{"location":"software/r.html#installing-deseq2-from-bioconductor-packages","text":"DESeq2 1 installed from Bioconductor 2 has many dependencies. Two odd facts are hindering a succesful build of DESeq2 in first place: data.table is needed by Hmisc, which in turn is needed by DESeq2. While Hmisc is automatically installed prior to DESeq2, data.table is not and has to be installed manually first. https://bioconductor.org/packages/release/bioc/html/DESeq2.html \u21a9 https://bioconductor.org/ \u21a9","title":"Installing DESeq2 from Bioconductor packages"},{"location":"software/relion.html","text":"Relion Description Some useful information on using Relion. Running Relion A standard submission script serves as a template for your Relion jobs. Create a file with the following content within your home directory: qsub.sh #!/bin/bash #SBATCH --mail-user=<put your valid email address> #SBATCH --mail-type=end,fail #SBATCH --ntasks=XXXmpinodesXXX #SBATCH --time=XXXextra1XXX #SBATCH --mem-per-cpu=XXXextra2XXX #SBATCH --partition=XXXqueueXXX #SBATCH --error=XXXerrfileXXX #SBATCH --output=XXXoutfileXXX module load relion/1.4 mpiexec XXXcommandXXX ####the end Substitute your own email address! Keywords starting and finishing with \u201cXXX\u201d are recognized by Relion and should not be edited. To select a specific processor family you can edit the -pe option and subsitute \u201corte-sandy\u201d, \u201corte-ivy\u201d or \u201corte-broadwell\u201d for \u201corte\u201d. Now, you can set up tasks that will run on the cluster as follows: Start the Relion GUI Click on the \u201cRunning\u201d tab Add appropriate values for each option: Number of MPI procs: The number of processes the job should use. Number of threads: Currently only 1 thread is supported on Ubelix. Available RAM per thread: Relion jobs can be quite eager but it is impossible to precisely predict how much RAM each process will need. 4 is usually a good place to start. This option here is only indicative and puts no limit on the RAM that Relion can use. Nonetheless to prevent stupid mistakes, you should always enter the same amount of RAM here as in the option \u201cMaximum RAM per process\u201d (see below). Submit to queue: Must be set to yes if the aim is to run on Ubelix queuing system. Queue name: In general set it to \u00ab all \u00bb. If you want to use a specific queue, please refer to https://docs.id.unibe.ch/ubelix/advanced-topics/parallel-jobs Queue submit command: Set it to \u201csbatch\u201d. Maximum CPU time: The maximum allowed running time. See https://docs.id.unibe.ch/ubelix/ubelix-101/the-job-script (Mandatory options) for details on the meaning of this option for Ubelix usage. Maximum RAM process: The maximum allowed RAM per process allowed by Ubelix. If you ask for too much RAM your job is less likely to start fast. If you ask for too little RAM your job will crash. The error output by Relion and Ubelix in such case is not always explicit. Nevertheless, too little RAM is the most common cause of crash. Therefore if you experience an unexpected crash, try increasing the available RAM per thread. See https://docs.id.unibe.ch/ubelix/ubelix-101/the-job-script (Mandatory options) for details on the meaning of this option for Ubelix usage. Note that unlike in \u201cAvailable RAM per thread\u201d option, you must append a \u201cG\u201d to the desired number of Gigabytes (for example, 4G). To prevent stupid mistake, you should always enter the same amount of RAM here as in the option \u201cAvailable RAM per thread\u201d. Standard submission script: Path to the standard submission script described above. Minimum dedicated core per node: Set to 1. Further Information Relion wiki: http://www2.mrc-lmb.cam.ac.uk/relion/index.php/Main_Page Tutorial: http://www2.mrc-lmb.cam.ac.uk/groups/scheres/relion13_tutorial.pdf","title":"Relion"},{"location":"software/relion.html#relion","text":"","title":"Relion"},{"location":"software/relion.html#description","text":"Some useful information on using Relion.","title":"Description"},{"location":"software/relion.html#running-relion","text":"A standard submission script serves as a template for your Relion jobs. Create a file with the following content within your home directory: qsub.sh #!/bin/bash #SBATCH --mail-user=<put your valid email address> #SBATCH --mail-type=end,fail #SBATCH --ntasks=XXXmpinodesXXX #SBATCH --time=XXXextra1XXX #SBATCH --mem-per-cpu=XXXextra2XXX #SBATCH --partition=XXXqueueXXX #SBATCH --error=XXXerrfileXXX #SBATCH --output=XXXoutfileXXX module load relion/1.4 mpiexec XXXcommandXXX ####the end Substitute your own email address! Keywords starting and finishing with \u201cXXX\u201d are recognized by Relion and should not be edited. To select a specific processor family you can edit the -pe option and subsitute \u201corte-sandy\u201d, \u201corte-ivy\u201d or \u201corte-broadwell\u201d for \u201corte\u201d. Now, you can set up tasks that will run on the cluster as follows: Start the Relion GUI Click on the \u201cRunning\u201d tab Add appropriate values for each option: Number of MPI procs: The number of processes the job should use. Number of threads: Currently only 1 thread is supported on Ubelix. Available RAM per thread: Relion jobs can be quite eager but it is impossible to precisely predict how much RAM each process will need. 4 is usually a good place to start. This option here is only indicative and puts no limit on the RAM that Relion can use. Nonetheless to prevent stupid mistakes, you should always enter the same amount of RAM here as in the option \u201cMaximum RAM per process\u201d (see below). Submit to queue: Must be set to yes if the aim is to run on Ubelix queuing system. Queue name: In general set it to \u00ab all \u00bb. If you want to use a specific queue, please refer to https://docs.id.unibe.ch/ubelix/advanced-topics/parallel-jobs Queue submit command: Set it to \u201csbatch\u201d. Maximum CPU time: The maximum allowed running time. See https://docs.id.unibe.ch/ubelix/ubelix-101/the-job-script (Mandatory options) for details on the meaning of this option for Ubelix usage. Maximum RAM process: The maximum allowed RAM per process allowed by Ubelix. If you ask for too much RAM your job is less likely to start fast. If you ask for too little RAM your job will crash. The error output by Relion and Ubelix in such case is not always explicit. Nevertheless, too little RAM is the most common cause of crash. Therefore if you experience an unexpected crash, try increasing the available RAM per thread. See https://docs.id.unibe.ch/ubelix/ubelix-101/the-job-script (Mandatory options) for details on the meaning of this option for Ubelix usage. Note that unlike in \u201cAvailable RAM per thread\u201d option, you must append a \u201cG\u201d to the desired number of Gigabytes (for example, 4G). To prevent stupid mistake, you should always enter the same amount of RAM here as in the option \u201cAvailable RAM per thread\u201d. Standard submission script: Path to the standard submission script described above. Minimum dedicated core per node: Set to 1.","title":"Running Relion"},{"location":"software/relion.html#further-information","text":"Relion wiki: http://www2.mrc-lmb.cam.ac.uk/relion/index.php/Main_Page Tutorial: http://www2.mrc-lmb.cam.ac.uk/groups/scheres/relion13_tutorial.pdf","title":"Further Information"},{"location":"software/singularity.html","text":"Singularity Description Put your scientific workflows, software and libraries in a Singularity container and run it on UBELIX Examples Work interactively Submit an interactive lsf job and then use the shell command to spawn an interactive shell within the Singularity container: srun --time = 01 :00:00 --mem-per-cpu = 2G --pty bash singularity shell <image> Execute the containers \u201crunscript\u201d #!/bin/bash #SBATCH --partition=all #SBATCH --mem-per-cpu=2G singularity run <image> #or ./<image> Run a command within your container image singularity exec <image> <command> e.g: singularity exec container.img cat /etc/os-release Bind directories Per default the started application (e.g. cat in the last example) runs withing the container. The container works like a seperate machine with own operation system etc. Thus, per default you have no access to files and directories outside the container. This can be changed using binding paths. If files are needed outside the container, e.g. in your HOME you can add the a path to SINGULARITY_BINDPATH=\"src1[:dest1],src2[:dest2] . All subdirectories and files will be accessible. Thus you could bind your HOME directory as: export SINGULARITY_BINDPATH = \" $HOME /: $HOME /\" # or simply export SINGULARITY_BINDPATH = \" $HOME \" Further Information Official Singularity Documentation can be found at https://sylabs.io/docs/","title":"Singularity"},{"location":"software/singularity.html#singularity","text":"","title":"Singularity"},{"location":"software/singularity.html#description","text":"Put your scientific workflows, software and libraries in a Singularity container and run it on UBELIX","title":"Description"},{"location":"software/singularity.html#examples","text":"","title":"Examples"},{"location":"software/singularity.html#work-interactively","text":"Submit an interactive lsf job and then use the shell command to spawn an interactive shell within the Singularity container: srun --time = 01 :00:00 --mem-per-cpu = 2G --pty bash singularity shell <image>","title":"Work interactively"},{"location":"software/singularity.html#execute-the-containers-runscript","text":"#!/bin/bash #SBATCH --partition=all #SBATCH --mem-per-cpu=2G singularity run <image> #or ./<image>","title":"Execute the containers \"runscript\""},{"location":"software/singularity.html#run-a-command-within-your-container-image","text":"singularity exec <image> <command> e.g: singularity exec container.img cat /etc/os-release","title":"Run a command within your container image"},{"location":"software/singularity.html#bind-directories","text":"Per default the started application (e.g. cat in the last example) runs withing the container. The container works like a seperate machine with own operation system etc. Thus, per default you have no access to files and directories outside the container. This can be changed using binding paths. If files are needed outside the container, e.g. in your HOME you can add the a path to SINGULARITY_BINDPATH=\"src1[:dest1],src2[:dest2] . All subdirectories and files will be accessible. Thus you could bind your HOME directory as: export SINGULARITY_BINDPATH = \" $HOME /: $HOME /\" # or simply export SINGULARITY_BINDPATH = \" $HOME \"","title":"Bind directories"},{"location":"software/singularity.html#further-information","text":"Official Singularity Documentation can be found at https://sylabs.io/docs/","title":"Further Information"},{"location":"software/terminal-multiplexer-tmux.html","text":"Terminal Multiplexer (tmux) Description Frequently, people want to run programs on the submit host independently from an SSH session. Besides allowing a user to access multiple terminal sessions inside a single terminal window, tmux also lets you separate a program from the Unix shell that started the program. Tmux allows you detach from your running tmux session (the session will keep running in the background) and attach to the same session later on. Because the tmux session is running on the remote server, your session persists even on logout. Working Example Start a new tmux session on the submit host: $ tmux new -s first_session This will automatically attach you to a tmux session named first_session. Do your work within your tmux session. Detach from the session: Ctrl-b d Now you cloud disconnect from the server and reconnect later on. List all your existing tmux session: $ tmux ls first_session: 1 windows ( created Wed Jan 14 15 :23:11 2016 ) [ 80x85 ] ``` Bash Reattach to an existing tmux session: ``` Bash $ tumb attach -t first_session Further Information A tmux primer: https://danielmiessler.com/study/tmux","title":"Terminal Multiplexer (tmux)"},{"location":"software/terminal-multiplexer-tmux.html#terminal-multiplexer-tmux","text":"","title":"Terminal Multiplexer (tmux)"},{"location":"software/terminal-multiplexer-tmux.html#description","text":"Frequently, people want to run programs on the submit host independently from an SSH session. Besides allowing a user to access multiple terminal sessions inside a single terminal window, tmux also lets you separate a program from the Unix shell that started the program. Tmux allows you detach from your running tmux session (the session will keep running in the background) and attach to the same session later on. Because the tmux session is running on the remote server, your session persists even on logout.","title":"Description"},{"location":"software/terminal-multiplexer-tmux.html#working-example","text":"Start a new tmux session on the submit host: $ tmux new -s first_session This will automatically attach you to a tmux session named first_session. Do your work within your tmux session. Detach from the session: Ctrl-b d Now you cloud disconnect from the server and reconnect later on. List all your existing tmux session: $ tmux ls first_session: 1 windows ( created Wed Jan 14 15 :23:11 2016 ) [ 80x85 ] ``` Bash Reattach to an existing tmux session: ``` Bash $ tumb attach -t first_session","title":"Working Example"},{"location":"software/terminal-multiplexer-tmux.html#further-information","text":"A tmux primer: https://danielmiessler.com/study/tmux","title":"Further Information"}]}